{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "# %matplotlib widget\n",
    "import matplotlib\n",
    "import librosa\n",
    "import numpy as np\n",
    "matplotlib.use('QT5Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_dict(loaded_dict, row_indices=[0, 4], col_size=512, output_format=\"channels_first\"):\n",
    "    processed_data = {}\n",
    "\n",
    "    for key, (test_x, test_y, fund_freq_lst, distances_lst, file_names_lst, orig_signal_lst) in loaded_dict.items():\n",
    "        test_x = np.array(test_x)\n",
    "        test_y = np.array(test_y)\n",
    "        distances_lst = np.array(distances_lst)\n",
    "        fund_freq_lst = np.array(fund_freq_lst)\n",
    "        orig_signal_lst = np.array(orig_signal_lst)\n",
    "\n",
    "        # Select rows and columns size (preserve original order - no sorting)\n",
    "        X = test_x[:, row_indices, :col_size]\n",
    "        y = test_y\n",
    "\n",
    "        # Reshape based on desired output format\n",
    "        if output_format == \"channels_first\":\n",
    "            X = X[:, :, np.newaxis, :]  # [N, num_channels, 1, col_size]\n",
    "        elif output_format == \"channels_last\":\n",
    "\n",
    "            X = X[:, np.newaxis, :, :]  # [N, 1, num_channels, col_size]\n",
    "        else:\n",
    "            raise ValueError(\"output_format must be 'channels_first' or 'channels_last'\")\n",
    "\n",
    "        # Return all data in original order (no train/val split)\n",
    "        processed_data[key] = (X, y, fund_freq_lst, distances_lst, file_names_lst, orig_signal_lst)\n",
    "\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# testing only ppsp\n",
    "# \"\"\"\n",
    "# import warnings, pickle\n",
    "# import os\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "# mode = \"block\"\n",
    "# # all_combs_lists = [[0], [3], [0, 1, 2, 3]]\n",
    "# all_combs_lists = [[0]]\n",
    "# import torch\n",
    "# from models import fpn_2\n",
    "# import matplotlib.pyplot as plt\n",
    "#\n",
    "# device = 'cpu'\n",
    "#\n",
    "#\n",
    "# with open(f\"../conv2d_data/conv2d_psd_scaled_down_1up_{mode}_test.pkl\", \"rb\") as f:\n",
    "#     loaded_dict_test = pickle.load(f)\n",
    "#\n",
    "# for ind, comb_lst in enumerate(all_combs_lists):\n",
    "#\n",
    "#     dir_path = f\"./conv2d_data/pred_plots/{comb_lst}/\"\n",
    "#     os.makedirs(dir_path, exist_ok=True)\n",
    "#\n",
    "#     trained_model = fpn_2.PPSP(in_channels=len(comb_lst),out_channels=32)\n",
    "#     model_name = f\"../best_fpn2_1up_model_{mode}_{comb_lst}.pth\"\n",
    "#     trained_model.load_state_dict(torch.load(f\"{model_name}\", map_location=torch.device('cpu')))\n",
    "#     trained_model.eval()\n",
    "#\n",
    "#     processed_test = process_test_dict(\n",
    "#         loaded_dict_test,\n",
    "#         row_indices=comb_lst,\n",
    "#         col_size=1024,\n",
    "#         output_format=\"channels_last\"  # or \"channels_first\"\n",
    "#     )\n",
    "#     # device = torch.device('mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#     print(f\"Using device: {device}\")\n",
    "#\n",
    "#     for key, (X_test, y_test, fund_freq, distances, file_names, orig_sig) in processed_test.items():\n",
    "#         print(f\"Key: {key}\")\n",
    "#         prediction_lst = []\n",
    "#         freq_prediction_lst, fund_freq_lst = [], []\n",
    "#         if key == key:\n",
    "#             for ind in range(len(distances)):\n",
    "#                 if ind == ind:\n",
    "#                     cur_fund_freq = fund_freq[ind]\n",
    "#                     cur_fil_name = file_names[ind]\n",
    "#\n",
    "#                     # cur_x = np.array(X_test[ind])[np.newaxis,:,:,:]\n",
    "#                     cur_x = np.array(X_test[ind])[:, :, :]\n",
    "#                     torch_x = torch.FloatTensor(cur_x).to('cpu')\n",
    "#                     cur_y = np.array(y_test[ind])\n",
    "#\n",
    "#                     cur_prediction = trained_model(torch_x)\n",
    "#\n",
    "#                     fund_pred = torch.sigmoid(cur_prediction).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "#                     # all_harmonic_pred1 = torch.sigmoid(cur_prediction[1]).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "#\n",
    "#\n",
    "#                     cur_fund_prediction_norm = (fund_pred - np.min(fund_pred)) / (np.max(fund_pred) - np.min(fund_pred) + 1e-12)\n",
    "#                     # cur_harmonic_prediction_norm1 = (all_harmonic_pred1 - np.min(all_harmonic_pred1)) / (np.max(all_harmonic_pred1) - np.min(all_harmonic_pred1) + 1e-12)\n",
    "#\n",
    "#\n",
    "#                     binary_cur_truth=cur_y\n",
    "#\n",
    "#\n",
    "#                     plt_fil_name = f\"{cur_fund_freq}-{cur_fil_name}_{comb_lst}\"\n",
    "#\n",
    "#                     plt.title(f\"{cur_fund_freq} - {cur_fil_name}_{comb_lst}\")\n",
    "#                     for ind_x in range(cur_x.squeeze(0).shape[0]):\n",
    "#                         plt.plot(cur_x.squeeze(0)[ind_x],linewidth=1.2)\n",
    "#\n",
    "#                     plt.plot(binary_cur_truth, linewidth=1.1, label=\"True\",alpha=0.8)\n",
    "#\n",
    "#\n",
    "#                     plt.plot(cur_fund_prediction_norm, linewidth=0.8, label=\" f0\",alpha=0.8)\n",
    "#                     # plt.plot(cur_harmonic_prediction_norm1, '--', linewidth=0.7, label=\"raw all_harmonics\",alpha=0.8)\n",
    "#\n",
    "#                     plt.legend(loc='lower right')\n",
    "#\n",
    "#                     # plt.savefig(os.path.join(dir_path, f\"{plt_fil_name}.png\"), dpi=150)\n",
    "#                     # plt.close()\n",
    "#\n",
    "#                     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "testing only ppsp_1up head\n",
    "\"\"\"\n",
    "import warnings, pickle\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "mode = \"block\"\n",
    "# all_combs_lists = [[0], [3], [0, 1, 2, 3]]\n",
    "all_combs_lists = [[0],[3]]\n",
    "import torch\n",
    "from models import fpn_2\n",
    "import matplotlib.pyplot as plt\n",
    "from models import ppsp_1up_head\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "\n",
    "with open(f\"../conv2d_data/conv2d_psd_scaled_down_1up_{mode}_test.pkl\", \"rb\") as f:\n",
    "    loaded_dict_test = pickle.load(f)\n",
    "\n",
    "for ind, comb_lst in enumerate(all_combs_lists):\n",
    "\n",
    "    dir_path = f\"./conv2d_data/pred_plots/{comb_lst}/\"\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "    ## load pretrained ppsp\n",
    "    trained_model = fpn_2.PPSP(in_channels=len(comb_lst),out_channels=32)\n",
    "    model_name = f\"./model_weights/ppsp_weights.pth\"\n",
    "    trained_model.load_state_dict(torch.load(f\"{model_name}\", map_location=torch.device('cpu')))\n",
    "\n",
    "    ### load the ppsp_1up head\n",
    "    ppsp_1up = ppsp_1up_head.PPSP_withFundamental(pretrained_ppsp=trained_model, freeze=True, hidden=256)\n",
    "    ppsp1up_model_name=f\"../best_fpn2_1up_model_{mode}_{comb_lst}.pth\"\n",
    "    ppsp_1up.load_state_dict((torch.load(f\"{ppsp1up_model_name}\", map_location=torch.device('cpu'))))\n",
    "    ppsp_1up.eval()\n",
    "\n",
    "    processed_test = process_test_dict(\n",
    "        loaded_dict_test,\n",
    "        row_indices=comb_lst,\n",
    "        col_size=1024,\n",
    "        output_format=\"channels_last\"  # or \"channels_first\"\n",
    "    )\n",
    "    # device = torch.device('mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    for key, (X_test, y_test, fund_freq, distances, file_names, orig_sig) in processed_test.items():\n",
    "        print(f\"Key: {key}\")\n",
    "        prediction_lst = []\n",
    "        freq_prediction_lst, fund_freq_lst = [], []\n",
    "        if key == key:\n",
    "            for ind in range(len(distances)):\n",
    "                if ind == ind:\n",
    "                    cur_fund_freq = fund_freq[ind]\n",
    "                    cur_fil_name = file_names[ind]\n",
    "\n",
    "                    # cur_x = np.array(X_test[ind])[np.newaxis,:,:,:]\n",
    "                    cur_x = np.array(X_test[ind])[:, :, :]\n",
    "                    torch_x = torch.FloatTensor(cur_x).to('cpu')\n",
    "                    cur_y = np.array(y_test[ind])\n",
    "\n",
    "                    cur_prediction = ppsp_1up(torch_x)\n",
    "\n",
    "                    fund_pred = torch.sigmoid(cur_prediction[0]).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "                    harmonic_pred = torch.sigmoid(cur_prediction[1]).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "                    # all_harmonic_pred1 = torch.sigmoid(cur_prediction[1]).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "\n",
    "\n",
    "                    cur_fund_prediction_norm = (fund_pred - np.min(fund_pred)) / (np.max(fund_pred) - np.min(fund_pred) + 1e-12)\n",
    "                    # cur_harmonic_prediction_norm1 = (all_harmonic_pred1 - np.min(all_harmonic_pred1)) / (np.max(all_harmonic_pred1) - np.min(all_harmonic_pred1) + 1e-12)\n",
    "\n",
    "\n",
    "                    binary_cur_truth=cur_y\n",
    "\n",
    "\n",
    "                    plt_fil_name = f\"{cur_fund_freq}-{cur_fil_name}_{comb_lst}\"\n",
    "\n",
    "                    plt.title(f\"{cur_fund_freq} - {cur_fil_name}_{comb_lst}\")\n",
    "                    for ind_x in range(cur_x.squeeze(0).shape[0]):\n",
    "                        plt.plot(cur_x.squeeze(0)[ind_x],linewidth=1.2)\n",
    "\n",
    "                    plt.plot(binary_cur_truth, linewidth=1.1, label=\"True\",alpha=0.8)\n",
    "\n",
    "\n",
    "                    plt.plot(cur_fund_prediction_norm, linewidth=0.8, label=\" f0\",alpha=0.8)\n",
    "                    plt.plot(harmonic_pred, '--', linewidth=0.8, label=\"raw all_harmonics\",alpha=0.8)\n",
    "\n",
    "                    plt.legend(loc='lower right')\n",
    "\n",
    "                    plt.savefig(os.path.join(dir_path, f\"{plt_fil_name}.png\"), dpi=150)\n",
    "                    plt.close()\n",
    "\n",
    "                    # plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
