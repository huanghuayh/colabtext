{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "# %matplotlib widget\n",
    "import matplotlib\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "matplotlib.use('QT5Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_dict(loaded_dict, row_indices=[0, 4], col_size=512, output_format=\"channels_first\"):\n",
    "    processed_data = {}\n",
    "\n",
    "    for key, (test_x, test_y, fund_freq_lst, distances_lst, file_names_lst, orig_signal_lst) in loaded_dict.items():\n",
    "        test_x = np.array(test_x)\n",
    "        test_y = np.array(test_y)\n",
    "        distances_lst = np.array(distances_lst)\n",
    "        fund_freq_lst = np.array(fund_freq_lst)\n",
    "        orig_signal_lst = np.array(orig_signal_lst)\n",
    "\n",
    "        # Select rows and columns size (preserve original order - no sorting)\n",
    "        X = test_x[:, row_indices, :col_size]\n",
    "        y = test_y\n",
    "\n",
    "        # Reshape based on desired output format\n",
    "        if output_format == \"channels_first\":\n",
    "            X = X[:, :, np.newaxis, :]  # [N, num_channels, 1, col_size]\n",
    "        elif output_format == \"channels_last\":\n",
    "\n",
    "            X = X[:, np.newaxis, :, :]  # [N, 1, num_channels, col_size]\n",
    "        else:\n",
    "            raise ValueError(\"output_format must be 'channels_first' or 'channels_last'\")\n",
    "\n",
    "        # Return all data in original order (no train/val split)\n",
    "        processed_data[key] = (X, y, fund_freq_lst, distances_lst, file_names_lst, orig_signal_lst)\n",
    "\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### GradCAM class\n",
    "class GradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "\n",
    "        ### Register hooks\n",
    "        self.target_layer.register_forward_hook(self.save_activation)\n",
    "        self.target_layer.register_backward_hook(self.save_gradient)\n",
    "\n",
    "    def save_activation(self, module, input, output):\n",
    "        self.activations = output.detach()\n",
    "\n",
    "    def save_gradient(self, module, grad_input, grad_output):\n",
    "        self.gradients = grad_output[0].detach()\n",
    "\n",
    "    def __call__(self, x, target_category=None):\n",
    "        ### Forward pass\n",
    "        output = self.model(x)\n",
    "\n",
    "        if target_category is None:\n",
    "            ### Use the fundamental prediction [batch_size, 1, 1024] for Grad-CAM\n",
    "            target = output[0]\n",
    "        else:\n",
    "            target = output[target_category]\n",
    "\n",
    "        ### Zero gradients\n",
    "        self.model.zero_grad()\n",
    "\n",
    "        ### For Grad-CAM, we need a scalar value (mean)\n",
    "        target_scalar = target.mean()\n",
    "\n",
    "        ### Backward pass for target\n",
    "        target_scalar.backward(retain_graph=True)\n",
    "\n",
    "        #### Get gradients and activations\n",
    "        # [batch_size, channels, length]\n",
    "        gradients = self.gradients\n",
    "        activations = self.activations\n",
    "\n",
    "        ### Global average pooling of gradients across spatial dimension (length)\n",
    "        weights = torch.mean(gradients, dim=2)\n",
    "\n",
    "        # Weight the activations\n",
    "        batch_size, channels, length = activations.shape\n",
    "        cam = torch.zeros(batch_size, length, device=activations.device)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            for j in range(channels):\n",
    "                cam[i] += weights[i, j] * activations[i, j, :]\n",
    "\n",
    "        # Apply ReLU\n",
    "        cam = F.relu(cam)\n",
    "\n",
    "        # Normalize\n",
    "        cam = cam - cam.min(dim=1, keepdim=True)[0]\n",
    "        cam = cam / (cam.max(dim=1, keepdim=True)[0] + 1e-8)\n",
    "\n",
    "        return cam.detach().cpu().numpy(), output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "testing only ppsp mtl\n",
    "\"\"\"\n",
    "import warnings, pickle\n",
    "import os, csv\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "mode = \"block\"\n",
    "# all_combs_lists = [[0], [3], [0, 1, 2, 3]]\n",
    "all_combs_lists = [[3]]\n",
    "import torch\n",
    "from models import fpn_2\n",
    "from models import ppsp_1up\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import fuzzy_logic as fl\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "with open(f\"../conv2d_data/conv2d_psd_scaled_sfnds_1up_{mode}_test.pkl\", \"rb\") as f:\n",
    "    loaded_dict_test = pickle.load(f)\n",
    "\n",
    "for ind, comb_lst in enumerate(all_combs_lists):\n",
    "\n",
    "    dir_path = f\"./conv2d_data/pred_plots/{comb_lst}/\"\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "    ppsp_backbone = fpn_2.PPSP(in_channels=len(comb_lst), out_channels=32)\n",
    "    ppsp_1up_model = ppsp_1up.PPSP_1up(ppsp_backbone=ppsp_backbone, hidden_nodes=256)\n",
    "\n",
    "    model_name = f\"../best_fpn2_1up_model_{mode}_{comb_lst}.pth\"\n",
    "    ppsp_1up_model.load_state_dict(torch.load(f\"{model_name}\", map_location=torch.device('cpu')))\n",
    "    ppsp_1up_model.eval()\n",
    "\n",
    "    ### Initialize Grad-CAM for the model\n",
    "    target_layer = ppsp_1up_model.ppsp_backbone.conv_output1.c\n",
    "    grad_cam = GradCAM(ppsp_1up_model, target_layer)\n",
    "\n",
    "    processed_test = process_test_dict(\n",
    "        loaded_dict_test,\n",
    "        row_indices=comb_lst,\n",
    "        col_size=1024,\n",
    "        output_format=\"channels_last\"\n",
    "    )\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    for key, (X_test, y_test, fund_freq, distances, file_names, orig_sig) in processed_test.items():\n",
    "        print(f\"Key: {key}\")\n",
    "        cam_res_dict={}\n",
    "        cur_res_dict = {}\n",
    "        if key == key:\n",
    "            # Initialize CSV file for this key (no extra indent)\n",
    "            # cur_results = []\n",
    "            # csv_path = os.path.join(dir_path, f\"{key}_results.csv\")\n",
    "            # csv_file = open(csv_path, mode=\"w\", newline=\"\")\n",
    "            # writer = csv.writer(csv_file)\n",
    "            # writer.writerow([\"filename\", \"gtruth_fund_freq\", \"predicted_fund_freq\", \"predicted_fund_freq_lst\",\"clusters\"])\n",
    "\n",
    "            for sample_ind in range(len(distances)):\n",
    "                cur_original_sig = orig_sig[sample_ind]\n",
    "                cur_fund_freq = fund_freq[sample_ind]\n",
    "                cur_fil_name = file_names[sample_ind]\n",
    "\n",
    "                cur_x = np.array(X_test[sample_ind])[:, :, :]\n",
    "                torch_x = torch.FloatTensor(cur_x).to('cpu')\n",
    "                cur_y = np.array(y_test[sample_ind])\n",
    "\n",
    "                ### Enable gradients for input\n",
    "                torch_x.requires_grad_()\n",
    "\n",
    "                with torch.enable_grad():\n",
    "                    cur_prediction = ppsp_1up_model(torch_x)\n",
    "\n",
    "                fund_pred = torch.sigmoid(cur_prediction[0]).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "                harmonic_pred = torch.sigmoid(cur_prediction[1]).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "\n",
    "                cur_fund_prediction_norm = (fund_pred - np.min(fund_pred)) / (\n",
    "                        np.max(fund_pred) - np.min(fund_pred) + 1e-12)\n",
    "                cur_harm_prediction_norm = (harmonic_pred - np.min(harmonic_pred)) / (\n",
    "                        np.max(harmonic_pred) - np.min(harmonic_pred) + 1e-12)\n",
    "                binary_cur_truth = cur_y\n",
    "\n",
    "                # if cur_fil_name in [\"fan_1721415536_7910_35cm_0\"]:\n",
    "                # print(cur_fil_name)\n",
    "                ### apply thresholding\n",
    "                bin_harmonic_pred = np.where(cur_harm_prediction_norm <= 0.5, 0, 1)\n",
    "                bin_fund_pred = np.where(cur_fund_prediction_norm > 0.01, 1, 0)\n",
    "\n",
    "                # ###\n",
    "                # fund_regions_lst, fund_central_freq_lst = fl.find_windows(bin_fund_pred)\n",
    "                # harm_regions_lst, harm_central_freq_lst = fl.find_windows(bin_harmonic_pred)\n",
    "                # ###\n",
    "                # clusters = fl.harmonic_clustering(fund_central_freq_lst, harm_central_freq_lst, tolerance=5,\n",
    "                #                                   max_harmonic=15, max_freq=1024)\n",
    "                # # if cur_fil_name in [\"fan_1721413988_2795_90cm_2\"]:\n",
    "                # if len(clusters) > 0:\n",
    "                #\n",
    "                #     fine_pred_freq_lst = []\n",
    "                #     ### find the region (start and end of these f0 candidates) for finer speed estimation\n",
    "                #     for cur_ind in range(len(clusters)):\n",
    "                #         # cur_pred_freq = clusters[cur_ind]['f0']\n",
    "                #         # if clusters[cur_ind]['match_count']>1:\n",
    "                #         try:\n",
    "                #             index_of_region = fund_central_freq_lst.index(clusters[cur_ind]['f0'])\n",
    "                #             region_indexes = fund_regions_lst[index_of_region]\n",
    "                #             strt_ind, end_ind = region_indexes[0], region_indexes[1]\n",
    "                #             cur_fine_pred_freq = fl.predict_freq(cur_original_sig, cur_original_sig, strt_ind, end_ind,\n",
    "                #                                                  int((strt_ind + end_ind) // 2))\n",
    "                #             fine_pred_freq_lst.append(cur_fine_pred_freq)\n",
    "                #\n",
    "                #         except:\n",
    "                #             index_of_region = harm_central_freq_lst.index(clusters[cur_ind]['f0'])\n",
    "                #             region_indexes = harm_regions_lst[index_of_region]\n",
    "                #             strt_ind, end_ind = region_indexes[0], region_indexes[1]\n",
    "                #             cur_fine_pred_freq = fl.predict_freq(cur_original_sig, cur_original_sig, strt_ind, end_ind,\n",
    "                #                                                  int((strt_ind + end_ind) // 2))\n",
    "                #             fine_pred_freq_lst.append(cur_fine_pred_freq)\n",
    "                #         # else:\n",
    "                #         #     fine_pred_freq_lst.append(0)\n",
    "                #\n",
    "                #\n",
    "                # else:\n",
    "                #     fine_pred_freq_lst = [0]\n",
    "                #\n",
    "                # print(f\"filename={cur_fil_name} gtruth={cur_fund_freq} predicted={fine_pred_freq_lst}\")\n",
    "                #\n",
    "                # ### fine tuning\n",
    "                # fine_pred_freq_arr = np.array(fine_pred_freq_lst)\n",
    "                # diff_arr = np.abs(fine_pred_freq_arr - cur_fund_freq)\n",
    "                # min_idx = np.argmin(diff_arr)\n",
    "                #\n",
    "                # fine_pred_freq = fine_pred_freq_lst[min_idx]\n",
    "                # \"\"\"\n",
    "                # write results to file\n",
    "                # \"\"\"\n",
    "                # writer.writerow([cur_fil_name, cur_fund_freq,fine_pred_freq, fine_pred_freq_lst, clusters])\n",
    "                # cur_results.append(\n",
    "                #     [[bin_fund_pred, bin_harmonic_pred], binary_cur_truth, cur_x, cur_fund_freq, fine_pred_freq,\n",
    "                #      cur_fil_name, clusters,fine_pred_freq_lst,])\n",
    "\n",
    "                # ### Generate Grad-CAM\n",
    "                with torch.enable_grad():\n",
    "                    cam, _ = grad_cam(torch_x, target_category=0)\n",
    "\n",
    "                ### Convert CAM to same length as input\n",
    "                cam = cam.squeeze()\n",
    "\n",
    "                ### Handle case where cam might be 2D (batch, features)\n",
    "                if cam.ndim > 1:\n",
    "                    cam = cam[0]\n",
    "\n",
    "                cam_resized = np.interp(np.linspace(0, len(cam) - 1, len(cur_fund_prediction_norm)),\n",
    "                                        np.arange(len(cam)), cam)\n",
    "\n",
    "\n",
    "                plt.figure(figsize=(7, 4))\n",
    "                # plt.subplot(2, 1, 1)\n",
    "                for ind_x in range(cur_x.squeeze(0).shape[0]):\n",
    "                    plt.plot(cur_x.squeeze(0)[ind_x], linewidth=1.2, alpha=0.7)\n",
    "                plt.plot(binary_cur_truth, linewidth=1.5, label=\"True\", alpha=0.9, color='black')\n",
    "                # x_axis = np.arange(len(cam_resized))\n",
    "                # plt.fill_between(x_axis, np.min(cur_x), np.max(cur_x),\n",
    "                #                 where=cam_resized > 0.5,\n",
    "                #                 alpha=0.3, color='red', label='Saliency')\n",
    "\n",
    "                # plt.plot(cur_fund_prediction_norm, linewidth=1.2, label=\"f0\", alpha=0.8, color='blue')\n",
    "                plt.plot(bin_fund_pred, linewidth=1.2, label=\"f0\", alpha=0.8, color='blue')\n",
    "                # plt.plot(harmonic_pred, '--', linewidth=1.2, label=\"raw all_harmonics\", alpha=0.8, color='green')\n",
    "                plt.plot(bin_harmonic_pred, '--', linewidth=1.2, label=\"raw all_harmonics\", alpha=0.8, color='green')\n",
    "\n",
    "                plt.plot(cam_resized, color='red', linewidth=1.5, label='CAM')\n",
    "                plt.fill_between(np.arange(len(cam_resized)), cam_resized, alpha=0.3, color='red')\n",
    "\n",
    "                plt.legend(loc='lower right')\n",
    "                plt.title(f\"{cur_fund_freq} - {cur_fil_name}_{comb_lst} - Saliency Overlay\")\n",
    "                plt.ylabel('Amplitude')\n",
    "\n",
    "                # plt.subplot(2, 1, 2)\n",
    "                # plt.plot(cam_resized, color='red', linewidth=1.5, label='Saliency')\n",
    "                # plt.fill_between(np.arange(len(cam_resized)), cam_resized, alpha=0.3, color='red')\n",
    "                # plt.xlabel('Time steps')\n",
    "                # plt.ylabel('Saliency')\n",
    "                # plt.ylim(0, 1)\n",
    "                # plt.title('Grad-CAM Saliency Map')\n",
    "                # plt.legend()\n",
    "\n",
    "                plt.tight_layout()\n",
    "\n",
    "                plt_fil_name = f\"{cur_fund_freq}-{cur_fil_name}_{comb_lst}\"\n",
    "\n",
    "                plt.savefig(os.path.join(dir_path, f\"{plt_fil_name}_gradcam_mtl.png\"), dpi=150)\n",
    "                plt.close()\n",
    "\n",
    "                # plt.show()\n",
    "\n",
    "                if distances[sample_ind] not in cam_res_dict:\n",
    "                    cam_res_dict[distances[sample_ind]] = [[cur_fil_name, cur_fund_freq,X_test[sample_ind],y_test[sample_ind],fund_pred,cur_fund_prediction_norm,binary_cur_truth,cam,cam_resized,harmonic_pred,cur_harm_prediction_norm]]\n",
    "                else:\n",
    "                    cam_res_dict[distances[sample_ind]].append([cur_fil_name, cur_fund_freq,X_test[sample_ind],y_test[sample_ind],fund_pred,cur_fund_prediction_norm,binary_cur_truth,cam,cam_resized,harmonic_pred,cur_harm_prediction_norm])\n",
    "\n",
    "        pkl_path = os.path.join(dir_path, f\"{key}_mtl_cam\")\n",
    "        pickle.dump([cam_res_dict], open(f\"{pkl_path}\", \"wb\"))\n",
    "\n",
    "        #     csv_file.close()\n",
    "        #\n",
    "        # cur_res_dict[key] = cur_results\n",
    "        # pkl_path = os.path.join(dir_path, f\"{key}_results\")\n",
    "        # pickle.dump([cur_res_dict], open(f\"{pkl_path}\", \"wb\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# testing crepe and ppsp\n",
    "# \"\"\"\n",
    "# import warnings, pickle\n",
    "# import os, csv\n",
    "#\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "# mode = \"block\"\n",
    "# # all_combs_lists = [[0], [3], [0, 1, 2, 3]]\n",
    "# all_combs_lists = [[0]]\n",
    "# import torch\n",
    "# from models import fpn_2\n",
    "# from models import crepe\n",
    "# import matplotlib.pyplot as plt\n",
    "# import torch.nn.functional as F\n",
    "# import numpy as np\n",
    "# import fuzzy_logic as fl\n",
    "#\n",
    "# device = 'cpu'\n",
    "#\n",
    "# with open(f\"../conv2d_data/conv2d_psd_scaled_sfnds_1up_{mode}_test_bldc7.pkl\", \"rb\") as f:\n",
    "#     loaded_dict_test = pickle.load(f)\n",
    "#\n",
    "# for ind, comb_lst in enumerate(all_combs_lists):\n",
    "#\n",
    "#     dir_path = f\"./conv2d_data/pred_plots/{comb_lst}/\"\n",
    "#     os.makedirs(dir_path, exist_ok=True)\n",
    "#\n",
    "#     # ppsp_backbone = fpn_2.PPSP(in_channels=len(comb_lst), out_channels=32)\n",
    "#     # crepe = crepe.FPN_2_mtl(in_channels=len(comb_lst))\n",
    "#     crepe = fpn_2.PPSP(in_channels=len(comb_lst))\n",
    "#\n",
    "#     model_name = f\"../1ppsp_weights/best_model_weights_fan5_fan3_bldc_fpn2\"\n",
    "#     crepe.load_state_dict(torch.load(f\"{model_name}\", map_location=torch.device('cpu')))\n",
    "#     crepe.eval()\n",
    "#\n",
    "#     ### Initialize Grad-CAM for the model\n",
    "#     # target_layer = ppsp_1up_model.ppsp_backbone.conv_output1.c\n",
    "#     # grad_cam = GradCAM(ppsp_1up_model, target_layer)\n",
    "#\n",
    "#     processed_test = process_test_dict(\n",
    "#         loaded_dict_test,\n",
    "#         row_indices=comb_lst,\n",
    "#         col_size=1024,\n",
    "#         output_format=\"channels_last\"\n",
    "#     )\n",
    "#     print(f\"Using device: {device}\")\n",
    "#\n",
    "#     for key, (X_test, y_test, fund_freq, distances, file_names, orig_sig) in processed_test.items():\n",
    "#         print(f\"Key: {key}\")\n",
    "#         cur_res_dict = {}\n",
    "#         if key == key:\n",
    "#             # Initialize CSV file for this key (no extra indent)\n",
    "#             cur_results = []\n",
    "#             csv_path = os.path.join(dir_path, f\"{key}_results.csv\")\n",
    "#             csv_file = open(csv_path, mode=\"w\", newline=\"\")\n",
    "#             writer = csv.writer(csv_file)\n",
    "#             writer.writerow([\"filename\", \"gtruth_fund_freq\", \"predicted_fund_freq\", \"predicted_fund_freq_lst\",\"clusters\"])\n",
    "#\n",
    "#             for sample_ind in range(len(distances)):\n",
    "#                 cur_original_sig = orig_sig[sample_ind]\n",
    "#                 cur_fund_freq = fund_freq[sample_ind]\n",
    "#                 cur_fil_name = file_names[sample_ind]\n",
    "#\n",
    "#                 cur_x = np.array(X_test[sample_ind])[:, :, :]\n",
    "#                 torch_x = torch.FloatTensor(cur_x).to('cpu')\n",
    "#                 cur_y = np.array(y_test[sample_ind])\n",
    "#\n",
    "#                 ### Enable gradients for input\n",
    "#                 # torch_x.requires_grad_()\n",
    "#\n",
    "#                 # with torch.enable_grad():\n",
    "#                 cur_prediction = crepe(torch_x)\n",
    "#\n",
    "#                 fund_pred = torch.sigmoid(cur_prediction).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "#                 # harmonic_pred = torch.sigmoid(cur_prediction[1]).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "#\n",
    "#                 cur_fund_prediction_norm = (fund_pred - np.min(fund_pred)) / (\n",
    "#                         np.max(fund_pred) - np.min(fund_pred) + 1e-12)\n",
    "#                 # cur_harm_prediction_norm = (harmonic_pred - np.min(harmonic_pred)) / (\n",
    "#                 #         np.max(harmonic_pred) - np.min(harmonic_pred) + 1e-12)\n",
    "#                 binary_cur_truth = cur_y\n",
    "#\n",
    "#                 # if cur_fil_name in [\"fan_1721415536_7910_35cm_0\"]:\n",
    "#                 # print(cur_fil_name)\n",
    "#                 ### apply thresholding\n",
    "#                 # bin_harmonic_pred = np.where(cur_harm_prediction_norm <= 0.5, 0, 1)\n",
    "#                 bin_fund_pred = np.where(cur_fund_prediction_norm > 0.01, 1, 0)\n",
    "#\n",
    "#                 ###\n",
    "#                 fund_regions_lst, fund_central_freq_lst = fl.find_windows(bin_fund_pred)\n",
    "#                 # harm_regions_lst, harm_central_freq_lst = fl.find_windows(bin_harmonic_pred)\n",
    "#                 ###\n",
    "#                 # clusters = fl.harmonic_clustering(fund_central_freq_lst, harm_central_freq_lst, tolerance=5,\n",
    "#                 #                                   max_harmonic=15, max_freq=1024)\n",
    "#                 # if cur_fil_name in [\"fan_1721413988_2795_90cm_2\"]:\n",
    "#                 # if len(clusters) > 0:\n",
    "#                 #\n",
    "#                 #     fine_pred_freq_lst = []\n",
    "#                 #     ### find the region (start and end of these f0 candidates) for finer speed estimation\n",
    "#                 #     for cur_ind in range(len(clusters)):\n",
    "#                 #         # cur_pred_freq = clusters[cur_ind]['f0']\n",
    "#                 #         # if clusters[cur_ind]['match_count']>1:\n",
    "#                 #         try:\n",
    "#                 #             index_of_region = fund_central_freq_lst.index(clusters[cur_ind]['f0'])\n",
    "#                 #             region_indexes = fund_regions_lst[index_of_region]\n",
    "#                 #             strt_ind, end_ind = region_indexes[0], region_indexes[1]\n",
    "#                 #             cur_fine_pred_freq = fl.predict_freq(cur_original_sig, cur_original_sig, strt_ind, end_ind,\n",
    "#                 #                                                  int((strt_ind + end_ind) // 2))\n",
    "#                 #             fine_pred_freq_lst.append(cur_fine_pred_freq)\n",
    "#                 #\n",
    "#                 #         except:\n",
    "#                 #             index_of_region = harm_central_freq_lst.index(clusters[cur_ind]['f0'])\n",
    "#                 #             region_indexes = harm_regions_lst[index_of_region]\n",
    "#                 #             strt_ind, end_ind = region_indexes[0], region_indexes[1]\n",
    "#                 #             cur_fine_pred_freq = fl.predict_freq(cur_original_sig, cur_original_sig, strt_ind, end_ind,\n",
    "#                 #                                                  int((strt_ind + end_ind) // 2))\n",
    "#                 #             fine_pred_freq_lst.append(cur_fine_pred_freq)\n",
    "#                 #         # else:\n",
    "#                 #         #     fine_pred_freq_lst.append(0)\n",
    "#                 #\n",
    "#                 #\n",
    "#                 # else:\n",
    "#                 #     fine_pred_freq_lst = [0]\n",
    "#                 fine_pred_freq_lst=[fund_regions_lst[0]]\n",
    "#                 print(f\"filename={cur_fil_name} gtruth={cur_fund_freq} predicted={fine_pred_freq_lst}\")\n",
    "#\n",
    "#                 ### fine tuning\n",
    "#                 # fine_pred_freq_arr = np.array(fine_pred_freq_lst)\n",
    "#                 # diff_arr = np.abs(fine_pred_freq_arr - cur_fund_freq)\n",
    "#                 # min_idx = np.argmin(diff_arr)\n",
    "#                 #\n",
    "#                 # fine_pred_freq = fine_pred_freq_lst[min_idx]\n",
    "#                 fine_pred_freq = fund_regions_lst[0]\n",
    "#                 \"\"\"\n",
    "#                 write results to file\n",
    "#                 \"\"\"\n",
    "#                 writer.writerow([cur_fil_name, cur_fund_freq,fine_pred_freq, fine_pred_freq_lst])\n",
    "#                 cur_results.append(\n",
    "#                     [[bin_fund_pred], binary_cur_truth, cur_x, cur_fund_freq, fine_pred_freq,\n",
    "#                      cur_fil_name, fine_pred_freq_lst,])\n",
    "#\n",
    "#                 # # ### Generate Grad-CAM\n",
    "#                 # with torch.enable_grad():\n",
    "#                 #     cam, _ = grad_cam(torch_x, target_category=0)\n",
    "#                 #\n",
    "#                 # ### Convert CAM to same length as input\n",
    "#                 # cam = cam.squeeze()\n",
    "#                 #\n",
    "#                 # ### Handle case where cam might be 2D (batch, features)\n",
    "#                 # if cam.ndim > 1:\n",
    "#                 #     cam = cam[0]\n",
    "#                 #\n",
    "#                 # cam_resized = np.interp(np.linspace(0, len(cam) - 1, len(cur_fund_prediction_norm)),\n",
    "#                 #                         np.arange(len(cam)), cam)\n",
    "#                 #\n",
    "#                 # plt.figure(figsize=(7, 4))\n",
    "#                 # # plt.subplot(2, 1, 1)\n",
    "#                 # for ind_x in range(cur_x.squeeze(0).shape[0]):\n",
    "#                 #     plt.plot(cur_x.squeeze(0)[ind_x], linewidth=1.2, alpha=0.7)\n",
    "#                 # plt.plot(binary_cur_truth, linewidth=1.5, label=\"True\", alpha=0.9, color='black')\n",
    "#                 # # x_axis = np.arange(len(cam_resized))\n",
    "#                 # # plt.fill_between(x_axis, np.min(cur_x), np.max(cur_x),\n",
    "#                 # #                 where=cam_resized > 0.5,\n",
    "#                 # #                 alpha=0.3, color='red', label='Saliency')\n",
    "#                 #\n",
    "#                 # # plt.plot(cur_fund_prediction_norm, linewidth=1.2, label=\"f0\", alpha=0.8, color='blue')\n",
    "#                 # plt.plot(bin_fund_pred, linewidth=1.2, label=\"f0\", alpha=0.8, color='blue')\n",
    "#                 # # plt.plot(harmonic_pred, '--', linewidth=1.2, label=\"raw all_harmonics\", alpha=0.8, color='green')\n",
    "#                 # plt.plot(bin_harmonic_pred, '--', linewidth=1.2, label=\"raw all_harmonics\", alpha=0.8, color='green')\n",
    "#                 #\n",
    "#                 # # plt.plot(cam_resized, color='red', linewidth=1.5, label='CAM')\n",
    "#                 # # plt.fill_between(np.arange(len(cam_resized)), cam_resized, alpha=0.3, color='red')\n",
    "#                 #\n",
    "#                 # plt.legend(loc='lower right')\n",
    "#                 # plt.title(f\"{cur_fund_freq} - {cur_fil_name}_{comb_lst} - Saliency Overlay\")\n",
    "#                 # plt.ylabel('Amplitude')\n",
    "#                 #\n",
    "#                 # # plt.subplot(2, 1, 2)\n",
    "#                 # # plt.plot(cam_resized, color='red', linewidth=1.5, label='Saliency')\n",
    "#                 # # plt.fill_between(np.arange(len(cam_resized)), cam_resized, alpha=0.3, color='red')\n",
    "#                 # # plt.xlabel('Time steps')\n",
    "#                 # # plt.ylabel('Saliency')\n",
    "#                 # # plt.ylim(0, 1)\n",
    "#                 # # plt.title('Grad-CAM Saliency Map')\n",
    "#                 # # plt.legend()\n",
    "#                 #\n",
    "#                 # plt.tight_layout()\n",
    "#                 #\n",
    "#                 # plt_fil_name = f\"{cur_fund_freq}-{cur_fil_name}_{comb_lst}\"\n",
    "#                 #\n",
    "#                 # # plt.savefig(os.path.join(dir_path, f\"{plt_fil_name}_gradcam.png\"), dpi=150)\n",
    "#                 # # plt.close()\n",
    "#                 #\n",
    "#                 # plt.show()\n",
    "#\n",
    "#             csv_file.close()\n",
    "#\n",
    "#         cur_res_dict[key] = cur_results\n",
    "#         pkl_path = os.path.join(dir_path, f\"{key}_results\")\n",
    "#         pickle.dump([cur_res_dict], open(f\"{pkl_path}\", \"wb\"))\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# testing only ppsp_1up head\n",
    "# \"\"\"\n",
    "# import warnings, pickle\n",
    "# import os, csv\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "# mode = \"block\"\n",
    "# # all_combs_lists = [[0], [3], [0, 1, 2, 3]]\n",
    "# all_combs_lists = [[3]]\n",
    "# import torch\n",
    "# from models import fpn_2\n",
    "# import matplotlib.pyplot as plt\n",
    "# from models import ppsp_1up_head\n",
    "# import fuzzy_logic as fl\n",
    "# device = 'cpu'\n",
    "#\n",
    "#\n",
    "# with open(f\"../conv2d_data/conv2d_psd_scaled_sfnds_1up_{mode}_test.pkl\", \"rb\") as f:\n",
    "#     loaded_dict_test = pickle.load(f)\n",
    "#\n",
    "# for ind, comb_lst in enumerate(all_combs_lists):\n",
    "#\n",
    "#     dir_path = f\"./conv2d_data/pred_plots/{comb_lst}/\"\n",
    "#     os.makedirs(dir_path, exist_ok=True)\n",
    "#\n",
    "#     ## load pretrained ppsp\n",
    "#     trained_model = fpn_2.PPSP(in_channels=len(comb_lst),out_channels=32)\n",
    "#     model_name = f\"./model_weights/ppsp_weights.pth\"\n",
    "#     trained_model.load_state_dict(torch.load(f\"{model_name}\", map_location=torch.device('cpu')))\n",
    "#\n",
    "#     ### load the ppsp_1up head\n",
    "#     ppsp_1up = ppsp_1up_head.PPSP_withFundamental(pretrained_ppsp=trained_model, freeze=True, hidden=256)\n",
    "#     ppsp1up_model_name=f\"../best_fpn2_1up_model_{mode}_{comb_lst}.pth\"\n",
    "#     ppsp_1up.load_state_dict((torch.load(f\"{ppsp1up_model_name}\", map_location=torch.device('cpu'))))\n",
    "#     ppsp_1up.eval()\n",
    "#\n",
    "#     processed_test = process_test_dict(\n",
    "#         loaded_dict_test,\n",
    "#         row_indices=comb_lst,\n",
    "#         col_size=1024,\n",
    "#         output_format=\"channels_last\"  # or \"channels_first\"\n",
    "#     )\n",
    "#     # device = torch.device('mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#     print(f\"Using device: {device}\")\n",
    "#\n",
    "#     for key, (X_test, y_test, fund_freq, distances, file_names, orig_sig) in processed_test.items():\n",
    "#         print(f\"Key: {key}\")\n",
    "#         prediction_lst = []\n",
    "#         freq_prediction_lst, fund_freq_lst = [], []\n",
    "#         cur_res_dict = {}\n",
    "#         if key == key:\n",
    "#             cur_results = []\n",
    "#             csv_path = os.path.join(dir_path, f\"{key}_results.csv\")\n",
    "#             csv_file = open(csv_path, mode=\"w\", newline=\"\")\n",
    "#             writer = csv.writer(csv_file)\n",
    "#             writer.writerow([\"filename\", \"gtruth_fund_freq\", \"predicted_fund_freq\", \"predicted_fund_freq_lst\",\"clusters\"])\n",
    "#             for ind in range(len(distances)):\n",
    "#                 if ind == ind:\n",
    "#                     cur_original_sig = orig_sig[ind]\n",
    "#                     cur_fund_freq = fund_freq[ind]\n",
    "#                     cur_fil_name = file_names[ind]\n",
    "#\n",
    "#                     # cur_x = np.array(X_test[ind])[np.newaxis,:,:,:]\n",
    "#                     cur_x = np.array(X_test[ind])[:, :, :]\n",
    "#                     torch_x = torch.FloatTensor(cur_x).to('cpu')\n",
    "#                     cur_y = np.array(y_test[ind])\n",
    "#\n",
    "#                     cur_prediction = ppsp_1up(torch_x)\n",
    "#\n",
    "#                     fund_pred = torch.sigmoid(cur_prediction[0]).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "#                     harmonic_pred = torch.sigmoid(cur_prediction[1]).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "#\n",
    "#                     cur_fund_prediction_norm = (fund_pred - np.min(fund_pred)) / (\n",
    "#                             np.max(fund_pred) - np.min(fund_pred) + 1e-12)\n",
    "#                     cur_harm_prediction_norm = (harmonic_pred - np.min(harmonic_pred)) / (\n",
    "#                             np.max(harmonic_pred) - np.min(harmonic_pred) + 1e-12)\n",
    "#                     binary_cur_truth = cur_y\n",
    "#\n",
    "#                     # if cur_fil_name in [\"fan_1721415536_7910_35cm_0\"]:\n",
    "#                     # print(cur_fil_name)\n",
    "#                     ### apply thresholding\n",
    "#                     bin_harmonic_pred = np.where(cur_harm_prediction_norm <= 0.5, 0, 1)\n",
    "#                     bin_fund_pred = np.where(cur_fund_prediction_norm > 0.01, 1, 0)\n",
    "#\n",
    "#                     ###\n",
    "#                     fund_regions_lst, fund_central_freq_lst = fl.find_windows(bin_fund_pred)\n",
    "#                     harm_regions_lst, harm_central_freq_lst = fl.find_windows(bin_harmonic_pred)\n",
    "#                     ###\n",
    "#                     clusters = fl.harmonic_clustering(fund_central_freq_lst, harm_central_freq_lst, tolerance=5,\n",
    "#                                                       max_harmonic=15, max_freq=1024)\n",
    "#                     # if cur_fil_name in [\"fan_1721413988_2795_90cm_2\"]:\n",
    "#                     if len(clusters) > 0:\n",
    "#\n",
    "#                         fine_pred_freq_lst = []\n",
    "#                         ### find the region (start and end of these f0 candidates) for finer speed estimation\n",
    "#                         for cur_ind in range(len(clusters)):\n",
    "#                             # cur_pred_freq = clusters[cur_ind]['f0']\n",
    "#                             # if clusters[cur_ind]['match_count']>1:\n",
    "#                             try:\n",
    "#                                 index_of_region = fund_central_freq_lst.index(clusters[cur_ind]['f0'])\n",
    "#                                 region_indexes = fund_regions_lst[index_of_region]\n",
    "#                                 strt_ind, end_ind = region_indexes[0], region_indexes[1]\n",
    "#                                 cur_fine_pred_freq = fl.predict_freq(cur_original_sig, cur_original_sig, strt_ind, end_ind,\n",
    "#                                                                      int((strt_ind + end_ind) // 2))\n",
    "#                                 fine_pred_freq_lst.append(cur_fine_pred_freq)\n",
    "#\n",
    "#                             except:\n",
    "#                                 index_of_region = harm_central_freq_lst.index(clusters[cur_ind]['f0'])\n",
    "#                                 region_indexes = harm_regions_lst[index_of_region]\n",
    "#                                 strt_ind, end_ind = region_indexes[0], region_indexes[1]\n",
    "#                                 cur_fine_pred_freq = fl.predict_freq(cur_original_sig, cur_original_sig, strt_ind, end_ind,\n",
    "#                                                                      int((strt_ind + end_ind) // 2))\n",
    "#                                 fine_pred_freq_lst.append(cur_fine_pred_freq)\n",
    "#                             # else:\n",
    "#                             #     fine_pred_freq_lst.append(0)\n",
    "#\n",
    "#\n",
    "#                     else:\n",
    "#                         fine_pred_freq_lst = [0]\n",
    "#\n",
    "#                     print(f\"filename={cur_fil_name} gtruth={cur_fund_freq} predicted={fine_pred_freq_lst}\")\n",
    "#\n",
    "#                     ### fine tuning\n",
    "#                     fine_pred_freq_arr = np.array(fine_pred_freq_lst)\n",
    "#                     diff_arr = np.abs(fine_pred_freq_arr - cur_fund_freq)\n",
    "#                     min_idx = np.argmin(diff_arr)\n",
    "#\n",
    "#                     fine_pred_freq = fine_pred_freq_lst[min_idx]\n",
    "#                     \"\"\"\n",
    "#                     write results to file\n",
    "#                     \"\"\"\n",
    "#                     writer.writerow([cur_fil_name, cur_fund_freq,fine_pred_freq, fine_pred_freq_lst, clusters])\n",
    "#                     cur_results.append(\n",
    "#                         [[bin_fund_pred, bin_harmonic_pred], binary_cur_truth, cur_x, cur_fund_freq, fine_pred_freq,\n",
    "#                          cur_fil_name, clusters,fine_pred_freq_lst,])\n",
    "#\n",
    "#                     \"\"\"\n",
    "#                     plot figures\n",
    "#                     \"\"\"\n",
    "#                     # plt_fil_name = f\"{cur_fund_freq}-{cur_fil_name}_{comb_lst}\"\n",
    "#                     #\n",
    "#                     # plt.title(f\"{cur_fund_freq} - {cur_fil_name}_{comb_lst}\")\n",
    "#                     # for ind_x in range(cur_x.squeeze(0).shape[0]):\n",
    "#                     #     plt.plot(cur_x.squeeze(0)[ind_x],linewidth=1.2)\n",
    "#                     #\n",
    "#                     # plt.plot(binary_cur_truth, linewidth=1.1, label=\"True\",alpha=0.8)\n",
    "#                     #\n",
    "#                     #\n",
    "#                     # plt.plot(cur_fund_prediction_norm, linewidth=0.8, label=\" f0\",alpha=0.8)\n",
    "#                     # plt.plot(harmonic_pred, '--', linewidth=0.8, label=\"raw all_harmonics\",alpha=0.8)\n",
    "#                     #\n",
    "#                     # plt.legend(loc='lower right')\n",
    "#                     #\n",
    "#                     # # plt.savefig(os.path.join(dir_path, f\"{plt_fil_name}.png\"), dpi=150)\n",
    "#                     # # plt.close()\n",
    "#                     #\n",
    "#                     # plt.show()\n",
    "#\n",
    "#             csv_file.close()\n",
    "#\n",
    "#         cur_res_dict[key] = cur_results\n",
    "#         pkl_path = os.path.join(dir_path, f\"{key}_results\")\n",
    "#         pickle.dump([cur_res_dict], open(f\"{pkl_path}\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# testing only ppsp\n",
    "# \"\"\"\n",
    "# import warnings, pickle\n",
    "# import os\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "# mode = \"block\"\n",
    "# # all_combs_lists = [[0], [3], [0, 1, 2, 3]]\n",
    "# all_combs_lists = [[0],[3]]\n",
    "# import torch\n",
    "# from models import fpn_2\n",
    "# from models import ppsp_1up\n",
    "# import matplotlib.pyplot as plt\n",
    "# import torch.nn.functional as F\n",
    "#\n",
    "# device = 'cpu'\n",
    "#\n",
    "#\n",
    "# with open(f\"../conv2d_data/conv2d_psd_scaled_sfnds_1up_{mode}_test.pkl\", \"rb\") as f:\n",
    "#     loaded_dict_test = pickle.load(f)\n",
    "#\n",
    "# for ind, comb_lst in enumerate(all_combs_lists):\n",
    "#\n",
    "#     dir_path = f\"./conv2d_data/pred_plots/{comb_lst}/\"\n",
    "#     os.makedirs(dir_path, exist_ok=True)\n",
    "#\n",
    "#     ppsp_backbone = fpn_2.PPSP(in_channels=len(comb_lst),out_channels=32)\n",
    "#     ppsp_1up = ppsp_1up.PPSP_1up(ppsp_backbone=ppsp_backbone, hidden_nodes=256)\n",
    "#\n",
    "#     model_name = f\"../best_fpn2_1up_model_{mode}_{comb_lst}.pth\"\n",
    "#     ppsp_1up.load_state_dict(torch.load(f\"{model_name}\", map_location=torch.device('cpu')))\n",
    "#     ppsp_1up.eval()\n",
    "#\n",
    "#     processed_test = process_test_dict(\n",
    "#         loaded_dict_test,\n",
    "#         row_indices=comb_lst,\n",
    "#         col_size=1024,\n",
    "#         output_format=\"channels_last\"  # or \"channels_first\"\n",
    "#     )\n",
    "#     # device = torch.device('mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#     print(f\"Using device: {device}\")\n",
    "#\n",
    "#     for key, (X_test, y_test, fund_freq, distances, file_names, orig_sig) in processed_test.items():\n",
    "#         print(f\"Key: {key}\")\n",
    "#         prediction_lst = []\n",
    "#         freq_prediction_lst, fund_freq_lst = [], []\n",
    "#         if key == key:\n",
    "#             for ind in range(len(distances)):\n",
    "#                 if ind == ind:\n",
    "#                     cur_fund_freq = fund_freq[ind]\n",
    "#                     cur_fil_name = file_names[ind]\n",
    "#\n",
    "#                     # cur_x = np.array(X_test[ind])[np.newaxis,:,:,:]\n",
    "#                     cur_x = np.array(X_test[ind])[:, :, :]\n",
    "#                     torch_x = torch.FloatTensor(cur_x).to('cpu')\n",
    "#                     cur_y = np.array(y_test[ind])\n",
    "#\n",
    "#                     torch_x.requires_grad_()\n",
    "#                     cur_prediction = ppsp_1up(torch_x)\n",
    "#\n",
    "#                     fund_pred = torch.sigmoid(cur_prediction[0]).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "#                     harmonic_pred = torch.sigmoid(cur_prediction[1]).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "#\n",
    "#                     # all_harmonic_pred1 = torch.sigmoid(cur_prediction[1]).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "#\n",
    "#\n",
    "#                     cur_fund_prediction_norm = (fund_pred - np.min(fund_pred)) / (np.max(fund_pred) - np.min(fund_pred) + 1e-12)\n",
    "#                     # cur_harmonic_prediction_norm1 = (all_harmonic_pred1 - np.min(all_harmonic_pred1)) / (np.max(all_harmonic_pred1) - np.min(all_harmonic_pred1) + 1e-12)\n",
    "#\n",
    "#\n",
    "#                     binary_cur_truth=cur_y\n",
    "#\n",
    "#\n",
    "#                     plt_fil_name = f\"{cur_fund_freq}-{cur_fil_name}_{comb_lst}\"\n",
    "#\n",
    "#                     plt.title(f\"{cur_fund_freq} - {cur_fil_name}_{comb_lst}\")\n",
    "#                     for ind_x in range(cur_x.squeeze(0).shape[0]):\n",
    "#                         plt.plot(cur_x.squeeze(0)[ind_x],linewidth=1.2)\n",
    "#\n",
    "#                     plt.plot(binary_cur_truth, linewidth=1.1, label=\"True\",alpha=0.8)\n",
    "#\n",
    "#\n",
    "#                     plt.plot(cur_fund_prediction_norm, linewidth=0.8, label=\" f0\",alpha=0.8)\n",
    "#                     plt.plot(harmonic_pred, '--', linewidth=0.8, label=\"raw all_harmonics\",alpha=0.8)\n",
    "#                     # plt.plot(cur_harmonic_prediction_norm1, '--', linewidth=0.7, label=\"raw all_harmonics\",alpha=0.8)\n",
    "#\n",
    "#                     plt.legend(loc='lower right')\n",
    "#\n",
    "#                     # plt.savefig(os.path.join(dir_path, f\"{plt_fil_name}.png\"), dpi=150)\n",
    "#                     # plt.close()\n",
    "#\n",
    "#                     plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
