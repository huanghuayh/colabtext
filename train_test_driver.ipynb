{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from fpn_2 import PPSP\n",
    "from ppsp_1up_head import PPSP_withFundamental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle\n",
    "\n",
    "mode='gaussian'\n",
    "\n",
    "with open(f\"./conv2d_psd_scaled_down_1up_{mode}_1.pkl\", \"rb\") as f:\n",
    "    aggregated_combs_data_lst = pickle.load(f)\n",
    "\n",
    "all_combs_lists = [[0],[3],[0, 1, 2, 3]]\n",
    "\n",
    "print(f\"Datasets length={len(aggregated_combs_data_lst)}, combination_length={len(all_combs_lists)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "psd_length=1024\n",
    "\n",
    "def plot_region_masks(model_1_output, model_2_output, index=0):\n",
    "    \"\"\"\n",
    "    model_1_output: list like [[region_mask_f0, gt_y], ...]\n",
    "    model_2_output: list like [[mask_f0, mask_2f0, mask_3f0, mask_4f0], ...]\n",
    "    index: which sample to visualize\n",
    "    \"\"\"\n",
    "    # unpack\n",
    "    f0_mask, gt_y = model_1_output[index]\n",
    "    masks = model_2_output[index]  # list of harmonic masks\n",
    "    x = np.arange(len(f0_mask))\n",
    "\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(10, 6), sharex=True)\n",
    "\n",
    "    # ---- Row 1: fundamental vs ground truth ----\n",
    "    axes[0].plot(x, gt_y, label='Ground Truth (all harmonics)', color='gray', linewidth=2, alpha=0.7)\n",
    "    axes[0].plot(x, f0_mask, label='Fundamental region (Head1)', color='blue', linewidth=2)\n",
    "    axes[0].set_title('Model 1 Output — Fundamental vs Ground Truth')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, linestyle='--', alpha=0.4)\n",
    "\n",
    "    # ---- Row 2: individual harmonic regions ----\n",
    "    colors = ['r', 'g', 'b', 'orange']\n",
    "    labels = ['f0', '2f0', '3f0', '4f0']\n",
    "\n",
    "    for i, mask in enumerate(masks):\n",
    "        axes[1].plot(x, mask, color=colors[i % len(colors)], label=labels[i], linewidth=2)\n",
    "\n",
    "    axes[1].set_title('Model 2 Output — Individual Harmonic Regions')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, linestyle='--', alpha=0.4)\n",
    "\n",
    "    plt.xlabel('Frequency Bin')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "def make_gaussian(zero_mask, center_idx, psd_length=1024, sigma=2):\n",
    "    x = np.arange(psd_length)\n",
    "    gaussian = (1 / np.sqrt(2 * np.pi * sigma ** 2)) * np.exp(-0.5 * ((x - center_idx) / sigma) ** 2)\n",
    "    gaussian /= gaussian.max()\n",
    "    final_mask = np.maximum(zero_mask, gaussian)\n",
    "\n",
    "    return final_mask.astype(np.float32)\n",
    "\n",
    "def remake_targets(batch_y, total_num_outputs=6):\n",
    "    batch_y_ndarray = batch_y.numpy()\n",
    "    batch_y_shape= batch_y_ndarray.shape\n",
    "    model1_list, model2_list = [], []\n",
    "\n",
    "    for ind in range(batch_y_shape[0]):\n",
    "        cur_harmonic_indices=np.where(batch_y_ndarray[ind]== 1)[0]\n",
    "\n",
    "        top_harmonic_indices=cur_harmonic_indices[:total_num_outputs-2]\n",
    "\n",
    "        cur_zero_mask = np.zeros(psd_length)\n",
    "        region_mask_f0 = make_gaussian(cur_zero_mask, top_harmonic_indices[0])\n",
    "        region_mask_2f0 = make_gaussian(cur_zero_mask, top_harmonic_indices[1])\n",
    "        region_mask_3f0 = make_gaussian(cur_zero_mask, top_harmonic_indices[2])\n",
    "        region_mask_4f0 = make_gaussian(cur_zero_mask, top_harmonic_indices[3])\n",
    "\n",
    "        ### plot_region_masks([[region_mask_f0, batch_y_ndarray[ind]]], [[region_mask_f0, region_mask_2f0, region_mask_3f0, region_mask_4f0]], index=0)\n",
    "\n",
    "        model1_list.append(np.stack([region_mask_f0, batch_y_ndarray[ind]], axis=0).astype(np.float32))\n",
    "        model2_list.append(np.stack([region_mask_f0, region_mask_2f0, region_mask_3f0, region_mask_4f0], axis=0).astype(np.float32))\n",
    "\n",
    "    ### Force float32 before creating torch tensors\n",
    "    model1_array = np.stack(model1_list).astype(np.float32)\n",
    "    model2_array = np.stack(model2_list).astype(np.float32)\n",
    "\n",
    "    model1_targets = torch.from_numpy(model1_array).to(device)\n",
    "    model2_targets = torch.from_numpy(model2_array).to(device)\n",
    "\n",
    "\n",
    "    return model1_targets, model2_targets\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "### Training function\n",
    "def train_fpn2d_model(X_train, y_train, X_val, y_val, num_epochs=50, batch_size=100, learning_rate=0.001, model=None,\n",
    "                      model_name=\"\", train_model_flag=False):\n",
    "    \"\"\"\n",
    "    Train FPN_2D model with format: [batch_size, 1, channels, 512]\n",
    "    \"\"\"\n",
    "    ### Convert to tensors\n",
    "    X_train_tensor = torch.FloatTensor(X_train)\n",
    "    y_train_tensor = torch.FloatTensor(y_train)\n",
    "    X_val_tensor = torch.FloatTensor(X_val)\n",
    "    y_val_tensor = torch.FloatTensor(y_val)\n",
    "\n",
    "    print(f\"Training data shapes:\")\n",
    "    print(f\"X_train_tensor: {X_train_tensor.shape}\")  # [num_samples, 1, selected_rows, 512]\n",
    "    print(f\"y_train_tensor: {y_train_tensor.shape}\")  # [num_samples, 512]\n",
    "    print(f\"X_val_tensor: {X_val_tensor.shape}\")  # [num_samples, 1, selected_rows, 512]\n",
    "    print(f\"y_val_tensor: {y_val_tensor.shape}\")  # [num_samples, 512]\n",
    "\n",
    "    ### Create datasets and dataloaders\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    ### Initialize model, loss, optimizer\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "    # # criterion = DiceLoss()\n",
    "    # criterion = OverlapDiceLoss()\n",
    "    # optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-3)\n",
    "\n",
    "    if train_model_flag:\n",
    "\n",
    "        # Training variables\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        best_val_loss = float('inf')\n",
    "        best_model_weights = None\n",
    "\n",
    "        ### Training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            ### Training phase\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "\n",
    "            for batch_x, batch_y in train_loader:\n",
    "                model1_targets, model2_targets = remake_targets(batch_y)\n",
    "\n",
    "                ### plot_region_masks(model1_targets, model2_targets)\n",
    "\n",
    "                batch_x = batch_x.to(device)  # [batch_size, 1, 2, 512]\n",
    "                batch_y = batch_y.to(device)  # [batch_size, 512]\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(batch_x)\n",
    "\n",
    "                ### loss function for model mtl1\n",
    "                loss_fundamental = criterion(outputs[0].squeeze(1), model1_targets[:, 0, :])\n",
    "                loss = loss_fundamental\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += loss.item() * batch_x.size(0)\n",
    "\n",
    "            train_loss /= len(train_loader.dataset)\n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            ### Validation phase\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for batch_x, batch_y in val_loader:\n",
    "                    model1_targets, model2_targets = remake_targets(batch_y)\n",
    "                    batch_x = batch_x.to(device)  # [batch_size, 1, 2, 512]\n",
    "                    batch_y = batch_y.to(device)  # [batch_size, 512]\n",
    "\n",
    "                    outputs = model(batch_x)  # [batch_size, 1, 1, 512]\n",
    "\n",
    "                    ### loss function for model mtl1\n",
    "                    loss_fundamental = criterion(outputs[0].squeeze(1), model1_targets[:, 0, :])\n",
    "                    loss = loss_fundamental\n",
    "\n",
    "                    val_loss += loss.item() * batch_x.size(0)\n",
    "\n",
    "            val_loss /= len(val_loader.dataset)\n",
    "            val_losses.append(val_loss)\n",
    "\n",
    "            ### Save best model\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model_weights = model.state_dict().copy()\n",
    "                torch.save(best_model_weights, f'/content/drive/My Drive/train_test_data/{model_name}')\n",
    "\n",
    "            if (epoch + 1) % 50 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "                      f'Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, '\n",
    "                      f'Best Val: {best_val_loss:.4f}')\n",
    "\n",
    "        cur_combination=model_name.split('_')[5].split('.')[0]\n",
    "        # Plot training history\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(train_losses, label='Training Loss')\n",
    "        plt.plot(val_losses, label='Validation Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training and Validation Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(f'/content/drive/My Drive/train_test_data/training_history_{cur_combination}.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        # plt.show()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "for ind, (X_train, X_val, y_train, y_val, dist_train, dist_val) in enumerate(aggregated_combs_data_lst):\n",
    "    if ind==ind:\n",
    "        print(f\"Training model: best_fpn1d_model_{mode}_{all_combs_lists[ind]}.pth\")\n",
    "\n",
    "        ppsp_weights_file = \"best_model_weights_fan5_fan3_bldc_fpn2\"\n",
    "        ppsp_model = PPSP(in_channels=1)\n",
    "        ppsp_model.load_state_dict(torch.load(f'./ppsp_orig_weights/{ppsp_weights_file}', map_location=\"cpu\"))\n",
    "\n",
    "        ppsp_1up = PPSP_withFundamental(ppsp_model, freeze=True, hidden=256)\n",
    "\n",
    "        ### Train the model\n",
    "        trained_model = train_fpn2d_model(\n",
    "          X_train, y_train, X_val, y_val,\n",
    "          num_epochs=150,\n",
    "          batch_size=10,\n",
    "          learning_rate=0.001,\n",
    "          model=ppsp_1up,\n",
    "          model_name=f\"best_fpn2_1up_model_{mode}_{all_combs_lists[ind]}.pth\",\n",
    "          train_model_flag=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "# %matplotlib widget\n",
    "import matplotlib\n",
    "import librosa\n",
    "\n",
    "matplotlib.use('QT5Agg')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, pickle, re\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from magtach.op_codes.preprocess_functions import read_files, min_max_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_dict(loaded_dict, row_indices=[0, 4], col_size=512, output_format=\"channels_first\"):\n",
    "    processed_data = {}\n",
    "\n",
    "    for key, (test_x, test_y, fund_freq_lst, distances_lst, file_names_lst, orig_signal_lst) in loaded_dict.items():\n",
    "        test_x = np.array(test_x)\n",
    "        test_y = np.array(test_y)\n",
    "        distances_lst = np.array(distances_lst)\n",
    "        fund_freq_lst = np.array(fund_freq_lst)\n",
    "        orig_signal_lst = np.array(orig_signal_lst)\n",
    "\n",
    "        # Select rows and columns size (preserve original order - no sorting)\n",
    "        X = test_x[:, row_indices, :col_size]\n",
    "        y = test_y\n",
    "\n",
    "        # Reshape based on desired output format\n",
    "        if output_format == \"channels_first\":\n",
    "            X = X[:, :, np.newaxis, :]  # [N, num_channels, 1, col_size]\n",
    "        elif output_format == \"channels_last\":\n",
    "\n",
    "            X = X[:, np.newaxis, :, :]  # [N, 1, num_channels, col_size]\n",
    "        else:\n",
    "            raise ValueError(\"output_format must be 'channels_first' or 'channels_last'\")\n",
    "\n",
    "        # Return all data in original order (no train/val split)\n",
    "        processed_data[key] = (X, y, fund_freq_lst, distances_lst, file_names_lst, orig_signal_lst)\n",
    "\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings, pickle\n",
    "import torch\n",
    "from fpn_2 import PPSP\n",
    "from ppsp_1up_head import PPSP_withFundamental\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "mode = \"gaussian\"\n",
    "# all_combs_lists = [[0], [3], [0, 1, 2, 3]]\n",
    "all_combs_lists = [[0]]\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "with open(f\"./conv2d_psd_scaled_down_1up_{mode}_test.pkl\", \"rb\") as f:\n",
    "    loaded_dict_test = pickle.load(f)\n",
    "\n",
    "for ind, comb_lst in enumerate(all_combs_lists):\n",
    "\n",
    "    dir_path = f\"./conv2d_data/pred_plots/{comb_lst}/\"\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "\n",
    "    processed_test = process_test_dict(\n",
    "        loaded_dict_test,\n",
    "        row_indices=comb_lst,\n",
    "        col_size=1024,\n",
    "        output_format=\"channels_last\"\n",
    "    )\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    ppsp_weights_file = \"best_model_weights_fan5_fan3_bldc_fpn2\"\n",
    "\n",
    "    ppsp_model = PPSP(in_channels=1)\n",
    "    ppsp_model.load_state_dict(torch.load(f'../../data/train_test_data/{ppsp_weights_file}', map_location=\"cpu\"))\n",
    "\n",
    "\n",
    "    ppsp_1up = PPSP_withFundamental(ppsp_model, freeze=True, hidden=256)\n",
    "    ppsp_1up.eval()\n",
    "    print(\"ppsp_model loaded\")\n",
    "\n",
    "    for key, (X_test, y_test, fund_freq, distances, file_names, orig_sig) in processed_test.items():\n",
    "        print(f\"Key: {key}\")\n",
    "        prediction_lst = []\n",
    "        freq_prediction_lst, fund_freq_lst = [], []\n",
    "        if key == \"bldc_6\":\n",
    "            for ind in range(len(distances)):\n",
    "                if ind == ind:\n",
    "                    cur_fund_freq = fund_freq[ind]\n",
    "                    cur_fil_name = file_names[ind]\n",
    "\n",
    "                    cur_x = np.array(X_test[ind])[:, :, :]\n",
    "                    torch_x = torch.FloatTensor(cur_x).to('cpu')\n",
    "                    cur_y = np.array(y_test[ind])\n",
    "\n",
    "                    cur_prediction = ppsp_1up(torch_x)\n",
    "\n",
    "\n",
    "                    fund_pred = torch.sigmoid(cur_prediction[0]).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "                    all_harmonic_pred1 = torch.sigmoid(cur_prediction[1]).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "\n",
    "\n",
    "                    cur_fund_prediction_norm = (fund_pred - np.min(fund_pred)) / (np.max(fund_pred) - np.min(fund_pred) + 1e-12)\n",
    "                    cur_harmonic_prediction_norm1 = (all_harmonic_pred1 - np.min(all_harmonic_pred1)) / (np.max(all_harmonic_pred1) - np.min(all_harmonic_pred1) + 1e-12)\n",
    "\n",
    "\n",
    "                    binary_cur_truth=cur_y\n",
    "\n",
    "\n",
    "                    plt_fil_name = f\"{cur_fund_freq}-{cur_fil_name}_{comb_lst}\"\n",
    "\n",
    "                    plt.title(f\"{cur_fund_freq} - {cur_fil_name}_{comb_lst}\")\n",
    "                    for ind_x in range(cur_x.squeeze(0).shape[0]):\n",
    "                        plt.plot(cur_x.squeeze(0)[ind_x],linewidth=1.2)\n",
    "\n",
    "                    plt.plot(binary_cur_truth, linewidth=1.1, label=\"True\",alpha=0.8)\n",
    "\n",
    "\n",
    "                    plt.plot(cur_fund_prediction_norm, linewidth=0.8, label=\" f0\",alpha=0.8)\n",
    "                    plt.plot(cur_harmonic_prediction_norm1, '--', linewidth=0.7, label=\"raw all_harmonics\",alpha=0.8)\n",
    "\n",
    "                    plt.legend(loc='lower right')\n",
    "\n",
    "                    # plt.savefig(os.path.join(dir_path, f\"{plt_fil_name}.png\"), dpi=150)\n",
    "                    # plt.close()\n",
    "\n",
    "                    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fpn_2 import PPSP\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from ppsp_1up_head import PPSP_withFundamental\n",
    "from ppsp_mtl_9 import FPN2_withFundamental\n",
    "\n",
    "ppsp_weights_file = \"best_model_weights_fan5_fan3_bldc_fpn2\"\n",
    "\n",
    "ppsp_model = PPSP(in_channels=1)\n",
    "ppsp_model.load_state_dict(torch.load(f'../../data/train_test_data/{ppsp_weights_file}', map_location=\"cpu\"))\n",
    "# ppsp_model.eval()\n",
    "\n",
    "ppsp_1up_noEval = FPN2_withFundamental(ppsp_model, freeze=True, hidden=256)\n",
    "ppsp_1up_noEval.eval()\n",
    "\n",
    "# ppsp_1up_noEval = PPSP_withFundamental(ppsp_model, freeze=True, hidden=256)\n",
    "# ppsp_1up_noEval.eval()\n",
    "print(\"ppsp_model loaded\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, matplotlib\n",
    "matplotlib.use(\"Qt5Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "files=pickle.load(open(f\"../../data/train_test_data/test_x_y_bldc_correct\",\"rb\"))\n",
    "test_dict_lst =files[0]\n",
    "\n",
    "for ind, values in enumerate(test_dict_lst):\n",
    "\n",
    "    if values[1] in [\"bldc_1\"]:\n",
    "        print(f\"{values[1]}\")\n",
    "        test_dict, fundamental_freq = values[0], values[2]\n",
    "        res_file = f\"{values[1]}_results\"\n",
    "\n",
    "        for key, val in test_dict.items():\n",
    "            if key == \"5cm\":\n",
    "                print(key, len(val))\n",
    "                cur_results = []\n",
    "\n",
    "                for sig_ind in range(len(val)):\n",
    "                    # print(sig_ind)\n",
    "                    cur_fil_name = val[sig_ind][4]\n",
    "                    print(cur_fil_name)\n",
    "\n",
    "                    orig_sig = np.array(val[sig_ind][3])\n",
    "                    cur_x, cur_y = val[sig_ind][0], val[sig_ind][1][:1, :][0]\n",
    "\n",
    "                    cur_x = torch.tensor(cur_x, dtype=torch.float32).reshape(1, 1, -1)\n",
    "                    sig = (cur_x[0][0].detach().numpy())\n",
    "\n",
    "                    cur_pred = ppsp_model(cur_x)\n",
    "                    ppsp_1up_noEval_pred = ppsp_1up_noEval(cur_x)\n",
    "                    # ppsp_1up_Eval_pred = ppsp_1up_Eval(cur_pred)\n",
    "\n",
    "                    cur_pred = torch.sigmoid(cur_pred)\n",
    "                    pred = cur_pred[0][0].detach().numpy()\n",
    "\n",
    "                    ppsp_1up_noEval_pred =torch.sigmoid(ppsp_1up_noEval_pred[1])\n",
    "                    ppsp_1up_noEval_pred = ppsp_1up_noEval_pred[0][0].detach().numpy()\n",
    "\n",
    "                    # cur_pred =torch.sigmoid(cur_pred)\n",
    "                    # sig = (cur_x[0][0].detach().numpy())\n",
    "                    # pred = cur_pred[0][0].detach().numpy()\n",
    "                    # pred = np.where(pred <= 0.5, 0, pred)\n",
    "\n",
    "                    plt.title(f\"{cur_fil_name}_{fundamental_freq}\")\n",
    "                    plt.plot(sig)\n",
    "                    plt.plot(pred)\n",
    "                    plt.plot(ppsp_1up_noEval_pred, '--',color='green',alpha=0.7)\n",
    "                    plt.plot(cur_y, \"--\", linewidth='0.8',color='red',alpha=0.5)\n",
    "\n",
    "                    plt.tight_layout()\n",
    "\n",
    "                    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
