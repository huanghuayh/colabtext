{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "# %matplotlib widget\n",
    "import matplotlib\n",
    "import librosa\n",
    "\n",
    "matplotlib.use('QT5Agg')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, pickle, re\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from magtach.op_codes.preprocess_functions import read_files, min_max_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_resample_factors(start: float, end: float, step: float = 0.001):\n",
    "    resample_factors = []\n",
    "    rounding_precision = len(str(step).split('.')[1])\n",
    "    # resample_factors.append(0.32)\n",
    "    current = start\n",
    "    while current < end:\n",
    "        current += step\n",
    "        current = np.round(current, rounding_precision)\n",
    "        resample_factors.append(current)\n",
    "    return resample_factors\n",
    "\n",
    "\n",
    "def generate_resample_factors_v2(cur_fund_freq , start, end, step, rounding_precision=6):\n",
    "    freq_lst = np.arange(start, end+step, step)\n",
    "    freq_lst = freq_lst[freq_lst != 60]\n",
    "\n",
    "    resample_factors = np.round(cur_fund_freq / freq_lst, rounding_precision)\n",
    "\n",
    "    mask = (resample_factors > 0.1) & (resample_factors < 2.0)\n",
    "\n",
    "    freq_generated = freq_lst[mask]\n",
    "    resample_factors = resample_factors[mask]\n",
    "\n",
    "    return resample_factors, freq_generated\n",
    "\n",
    "\n",
    "# strt_pnt = 0.3\n",
    "# resampl_factor_lst = generate_resample_factors(start=strt_pnt, end=1.9, step=0.01)\n",
    "def scale_psd(orig_psd_db, final_length_psd, scale_factor, method=\"average\"):\n",
    "    if scale_factor is None or scale_factor == 1:\n",
    "        return orig_psd_db[:final_length_psd]\n",
    "\n",
    "    if method == \"decimate\":\n",
    "        ### pick every nth bin\n",
    "        cur_psd = orig_psd_db[::scale_factor]\n",
    "\n",
    "    elif method == \"nbins_average\":\n",
    "        orig_psd_copy = orig_psd_db[:final_length_psd * scale_factor].copy()\n",
    "        cur_psd = []\n",
    "        window_length = scale_factor\n",
    "        for ind in range(0, len(orig_psd_copy), window_length):\n",
    "            cur_psd.append(np.mean(orig_psd_copy[ind:ind + window_length]))\n",
    "\n",
    "    elif method == \"average\":\n",
    "        ### Average pooling sliding bins of length = scale factor\n",
    "        ### no overlap\n",
    "        cur_psd = orig_psd_db[:final_length_psd * scale_factor].reshape(final_length_psd, scale_factor).mean(axis=1)\n",
    "    elif method == \"median\":\n",
    "        ### Average pooling sliding bins of length = scale factor\n",
    "        ### no overlap\n",
    "        cur_psd = orig_psd_db[:final_length_psd * scale_factor].reshape(final_length_psd, scale_factor).median(axis=1)\n",
    "\n",
    "    elif method == \"max\":\n",
    "        ### Max pooling sliding bins of length = scale factor\n",
    "        ### no overlap\n",
    "        cur_psd = orig_psd_db[:final_length_psd * scale_factor].reshape(final_length_psd, scale_factor).max(axis=1)\n",
    "\n",
    "    elif method == \"softmax\":\n",
    "        blocks = orig_psd_db[:final_length_psd * scale_factor].reshape(final_length_psd, scale_factor)\n",
    "\n",
    "        # subtract max for numerical stability\n",
    "        exps = np.exp((blocks - np.max(blocks, axis=1, keepdims=True)) / 1.0)  # temperature=1.0\n",
    "        weights = exps / np.sum(exps, axis=1, keepdims=True)\n",
    "\n",
    "        cur_psd = np.sum(blocks * weights, axis=1)\n",
    "\n",
    "    elif method == \"resample\":\n",
    "        ### resample the psd to desired length\n",
    "        cur_psd = orig_psd_db[:int(final_length_psd * scale_factor)]\n",
    "        cur_psd = signal.resample(cur_psd, len(cur_psd) // scale_factor)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"method must be 'decimate', 'average', or 'resample'\")\n",
    "\n",
    "    return cur_psd[:final_length_psd]\n",
    "\n",
    "\n",
    "def compute_harmonic_peaks(fundamental_freq: int, spectral_window: int = 1024, max_iter: int = 500):\n",
    "    harmonics = []\n",
    "    j = 0\n",
    "    for _ in range(max_iter):\n",
    "        if j + fundamental_freq > spectral_window:\n",
    "            break\n",
    "        j += fundamental_freq\n",
    "        harmonics.append(j)\n",
    "\n",
    "    peaks = [int(np.round(i, 0)) for i in harmonics]\n",
    "    return peaks\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def make_true_mask_v2(cur_fund_freq, psd_length=1024, sigma=4.0, n_harmonics=100, mode=\"gaussian\", band_width=2):\n",
    "    # Collect harmonic indices\n",
    "    cur_fund_freq_lst = []\n",
    "    j = 0\n",
    "    for i in range(n_harmonics):\n",
    "        if j + cur_fund_freq >= psd_length - 2:\n",
    "            break\n",
    "        j += cur_fund_freq\n",
    "        cur_fund_freq_lst.append(j)\n",
    "\n",
    "    cur_fund_freq_lst = np.array([int(np.round(i)) for i in cur_fund_freq_lst])\n",
    "\n",
    "    # Build mask\n",
    "    true_mask = np.zeros(psd_length)\n",
    "    x = np.arange(psd_length)\n",
    "\n",
    "    if mode == \"gaussian\":\n",
    "        for f in cur_fund_freq_lst:\n",
    "            gaussian = (1 / np.sqrt(2 * np.pi * sigma ** 2)) * np.exp(-0.5 * ((x - f) / sigma) ** 2)\n",
    "            true_mask = np.maximum(true_mask, gaussian)\n",
    "\n",
    "        # Normalize so max=1\n",
    "        if np.max(true_mask) > 0:\n",
    "            true_mask /= np.max(true_mask)\n",
    "\n",
    "    elif mode == \"block\":\n",
    "        for f in cur_fund_freq_lst:\n",
    "            start = max(0, f - band_width)\n",
    "            end = min(psd_length, f + band_width + 1)\n",
    "            true_mask[start:end] = 1.0\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown mode: {mode}, choose 'gaussian' or 'block'\")\n",
    "\n",
    "    return true_mask, cur_fund_freq_lst\n",
    "\n",
    "\n",
    "def plot_psds_with_mask(cur_psds, true_mask, file=\"psd_plot\",\n",
    "                        resamp_factor=1, cur_fund_freq=None,\n",
    "                        psd_scale_down_factors=None,\n",
    "                        save_fig=False, out_dir=\"./\"):\n",
    "    n_psds = len(cur_psds)\n",
    "    fig, axes = plt.subplots(n_psds, 1, figsize=(8, 1.5 * n_psds), sharex=False)\n",
    "\n",
    "    if n_psds == 1:\n",
    "        axes = [axes]  # make iterable for single PSD case\n",
    "\n",
    "    title_str = f\"{file}_{resamp_factor}\"\n",
    "    if cur_fund_freq is not None:\n",
    "        title_str += f\"_{cur_fund_freq:.2f}\"\n",
    "\n",
    "    fig.suptitle(title_str)\n",
    "\n",
    "    for idx, psd in enumerate(cur_psds):\n",
    "        axes[idx].plot(psd, label=\"PSD\")\n",
    "        axes[idx].plot(true_mask, label=\"True Mask\", linestyle=\"--\")\n",
    "\n",
    "        if psd_scale_down_factors is not None:\n",
    "            axes[idx].set_title(f\"PSD {idx + 1} (factor {psd_scale_down_factors[idx]})\")\n",
    "        else:\n",
    "            axes[idx].set_title(f\"PSD {idx + 1}\")\n",
    "\n",
    "        axes[idx].legend(loc=\"upper right\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_fig:\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        fig.savefig(os.path.join(out_dir, f\"{file}.png\"))\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def comb_scores_linear(psd, fmin=10, fmax=None, Kmin=3, weights=\"inv\"):\n",
    "    # psd: shape [F], 1 Hz spacing assumed\n",
    "    F = len(psd)\n",
    "    if fmax is None: fmax = F - 1\n",
    "    # # normalize PSD to tame huge lines\n",
    "    # P = psd / (np.median(psd[(fmin//2):fmax]) + 1e-12)\n",
    "    P = psd\n",
    "\n",
    "    def get_w(K):\n",
    "        k = np.arange(1, K+1, dtype=float)\n",
    "        if weights == \"inv\": w = 1.0 / k\n",
    "        elif weights == \"inv2\": w = 1.0 / (k**2)\n",
    "        else: w = np.ones_like(k)\n",
    "        return w\n",
    "\n",
    "    H = np.zeros(F)\n",
    "    for F0 in range(fmin, fmax+1):\n",
    "        K = fmax // F0\n",
    "        if K < Kmin:\n",
    "            continue\n",
    "        w = get_w(K)\n",
    "        vals = []\n",
    "        for k in range(1, K+1):\n",
    "            fk = k * F0\n",
    "            lo = int(np.floor(fk))\n",
    "            hi = min(lo + 1, fmax)\n",
    "            t = fk - lo\n",
    "            pk = (1 - t) * P[lo] + t * P[hi]\n",
    "            vals.append(pk)\n",
    "        w = w / (w.sum() + 1e-12)\n",
    "        H[F0] = np.dot(w, np.array(vals))\n",
    "    return H  # maximal H index is your F0 estimate\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Training\n",
    "2. compute the hps different scales of welch\n",
    "3. store the welch, filename, ground truth mas for PPSP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "1. accept a list of training folder\n",
    "    - variable to select the psd length\n",
    "    - For each file\n",
    "      - Generate augmented files\n",
    "        - For each augmented file\n",
    "          - Welch of each file\n",
    "          - Summed version of scaled down welch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "root_folder_pth = f\"../data/\"\n",
    "# train_folders_lst = [(\"fan5_3spd_augment\", 41.97), (\"fan3_3spd_augment\", 96.7), (\"bldc_1_augment\", 94.98),\n",
    "#                      (\"bldc_2_augment\", 80.25)(\"bldc_5_augment\",45.5),(\"fan5_1spd_augment\",27.82)(\"bldc_3_augment\",55.55),]\n",
    "# train_folders_lst = [(\"fan5_2spd_augment\", 35.55),(\"bldc_2_augment\", 80.25),(\"fan5_3spd_augment\", 41.97),(\"bldc_1_augment\", 94.98)]\n",
    "train_folders_lst = [(\"fan5_3spd_augment\", 41.97),(\"bldc_2_augment\", 80.25)]\n",
    "\n",
    "\n",
    "psd_length = 1024\n",
    "fs = 44100\n",
    "ss_num_chunks, welch_num_chunks = 3, 2\n",
    "psd_scale_down_factors = [1, 2, 3, 'sum']\n",
    "plot_fig, save_fig = True, False\n",
    "### calculating resample factors\n",
    "# strt_pnt = 0.3\n",
    "# resampl_factor_lst = generate_resample_factors(start=strt_pnt, end=1.9, step=0.01)\n",
    "pattern = re.compile(r\"(\\d+)cm\")\n",
    "block_width = 3\n",
    "augmented_freq_gen_lst = []\n",
    "train_val_dict = OrderedDict()\n",
    "save_train_data = False\n",
    "mode = \"block\"\n",
    "if save_train_data:\n",
    "    for _, (train_folder, fund_freq) in enumerate(train_folders_lst):\n",
    "        print(train_folder, fund_freq)\n",
    "\n",
    "        cur_folder_pth = os.path.join(root_folder_pth, train_folder)\n",
    "        if not os.path.exists(cur_folder_pth):\n",
    "            print(f\"{cur_folder_pth} does not exist\")\n",
    "            continue\n",
    "        else:\n",
    "            data_folder_pth = os.path.join(cur_folder_pth, \"orig_files\")\n",
    "            files_lst = os.listdir(data_folder_pth)\n",
    "\n",
    "            distances_lst = []\n",
    "            train_x, train_y = [], []\n",
    "\n",
    "            for file in files_lst:\n",
    "\n",
    "                if file not in [\".DS_Store\"]:\n",
    "                    print(file)\n",
    "                    if train_folder.split(\"_\")[0] in [\"bldc\"]:\n",
    "                        cur_file_rpm = int(file.split('_')[2])\n",
    "                        fund_freq = cur_file_rpm/60\n",
    "                    cur_file_pth = os.path.join(data_folder_pth, file)\n",
    "                    cur_signal = np.sum(read_files(cur_file_pth), axis=0)\n",
    "\n",
    "                    resampl_factor_lst, freq_generated = generate_resample_factors_v2(fund_freq, 22, 250, 3, 4)\n",
    "                    # resampl_factor_lst, freq_generated = [1],[fund_freq]\n",
    "\n",
    "                    for resamp_ind, resamp_factor in enumerate(resampl_factor_lst):\n",
    "                        try:\n",
    "                            match = pattern.search(file)\n",
    "                            cm_value = int(match.group(1))\n",
    "                            distances_lst.append(cm_value)\n",
    "                        except:\n",
    "                            distances_lst.append(0)\n",
    "\n",
    "                        cur_psds = []\n",
    "                        ### Adjusted fundamental frequency\n",
    "                        cur_fund_freq = fund_freq / resamp_factor\n",
    "\n",
    "                        # print(cur_fund_freq)\n",
    "                        true_mask, cur_fund_freq_lst = make_true_mask_v2(cur_fund_freq, psd_length=psd_length, sigma=block_width, n_harmonics=100,\n",
    "                                                      mode=mode, band_width=block_width)\n",
    "                        augmented_freq_gen_lst.append(cur_fund_freq_lst[0])\n",
    "\n",
    "                        if 0.0 < resamp_factor < 3.0:\n",
    "                            # print(f\"Resample factor {resamp_factor}, cur signal id {file}\")\n",
    "                            resample_sig = librosa.resample(cur_signal, orig_sr=fs, target_sr=int(fs * resamp_factor))\n",
    "\n",
    "                            resamp_num_pnts = len(resample_sig) // welch_num_chunks\n",
    "\n",
    "                            if resamp_factor >= 2.0:\n",
    "                                resamp_freq_ss, resamp_Pxx_ss = signal.welch(resample_sig, fs, nperseg=resamp_num_pnts,\n",
    "                                                                             nfft=int(fs * resamp_factor))\n",
    "                            else:\n",
    "                                resamp_freq_ss, resamp_Pxx_ss = signal.welch(resample_sig, fs, nperseg=resamp_num_pnts,\n",
    "                                                                             nfft=fs)\n",
    "\n",
    "                            resamp_log_Pxx_ss = np.log(resamp_Pxx_ss)\n",
    "                            #### perform spectrum downsampling\n",
    "                            cur_psds = [min_max_norm(resamp_log_Pxx_ss[:psd_length])]\n",
    "\n",
    "                            for scale_factor in psd_scale_down_factors:\n",
    "                                if scale_factor not in [1, 'sum']:\n",
    "                                    cur_scaled_psd = scale_psd(resamp_log_Pxx_ss, psd_length, scale_factor,\n",
    "                                                               method=\"average\")\n",
    "                                    # cur_psds.append(cur_scaled_psd)\n",
    "                                    cur_psds.append(min_max_norm(cur_scaled_psd))\n",
    "\n",
    "                            stacked = np.stack(cur_psds, axis=0)\n",
    "                            max_psd = np.median(stacked, axis=0)\n",
    "                            cur_psds.append(min_max_norm(max_psd))\n",
    "\n",
    "                            # h = comb_scores_linear(cur_psds[4])\n",
    "                            # print()\n",
    "\n",
    "                        cur_x, cur_y = np.array(cur_psds), true_mask\n",
    "                        train_x.append(cur_x)\n",
    "                        train_y.append(cur_y)\n",
    "                        #\n",
    "                        # plot_psds_with_mask(cur_psds,true_mask,file=f\"{file}_{resamp_factor}.png\", resamp_factor=resamp_factor,cur_fund_freq=cur_fund_freq,psd_scale_down_factors=psd_scale_down_factors,save_fig=save_fig,out_dir=f\"./conv2d_data/train_plots/\")\n",
    "\n",
    "                    # print()\n",
    "            train_val_dict[train_folder] = [train_x, train_y, distances_lst, psd_scale_down_factors]\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "                'augmented_frequency': augmented_freq_gen_lst,\n",
    "            })\n",
    "\n",
    "    #### Count occurrences of each frequency\n",
    "    df_counts = (\n",
    "        df['augmented_frequency']\n",
    "        .value_counts()\n",
    "        .rename_axis(\"augmented_frequency\")\n",
    "        .reset_index(name=\"count\")\n",
    "        .sort_values(\"augmented_frequency\")\n",
    "    )\n",
    "\n",
    "    # Save to CSV\n",
    "    df_counts.to_csv(\"augmented_frequency_lst.csv\", index=False)\n",
    "\n",
    "    with open(f\"./conv2d_data/conv2d_psd_scaled_down_1up_{mode}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(train_val_dict, f)\n",
    "\n",
    "    print(f\"Saved dictionary to conv2d_psd_scaled_down_1up_{mode}.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmented_freq_csv = pd.read_csv(f\"augmented_frequency_lst.csv\", header=0, index_col=None)\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def process_loaded_dict(loaded_dict, row_indices=[0, 4], col_size=512, val_ratio=0.001,\n",
    "                        random_state=42, output_format=\"channels_first\"):\n",
    "    processed_data = {}\n",
    "    for key, (train_x, train_y, distances, *_) in loaded_dict.items():\n",
    "        train_x = np.array(train_x)\n",
    "        train_y = np.array(train_y)\n",
    "        distances = np.array(distances)\n",
    "\n",
    "        ### sort by distance\n",
    "        sorted_indices = np.argsort(distances)\n",
    "        train_x = train_x[sorted_indices]\n",
    "        train_y = train_y[sorted_indices]\n",
    "        distances = distances[sorted_indices]\n",
    "\n",
    "        ### select rows and columns size\n",
    "        X = train_x[:, row_indices, :col_size]\n",
    "        # train_y = train_y[:,:col_size]\n",
    "\n",
    "        ### reshape based on desired output format\n",
    "        if output_format == \"channels_first\":\n",
    "            # [N, num_channels, 1, col_size] - channels first\n",
    "            X = X[:, :, np.newaxis, :]\n",
    "        elif output_format == \"channels_last\":\n",
    "            # [N, 1, num_channels, col_size] - channels last\n",
    "            X = X[:, np.newaxis, :, :]\n",
    "        else:\n",
    "            raise ValueError(\"output_format must be 'channels_first' or 'channels_last'\")\n",
    "\n",
    "        ### split into train/val sets\n",
    "        X_train, X_val, y_train, y_val, dist_train, dist_val = train_test_split(\n",
    "            X, train_y, distances, test_size=val_ratio, random_state=random_state\n",
    "        )\n",
    "\n",
    "        processed_data[key] = (X_train, X_val, y_train, y_val, dist_train, dist_val)\n",
    "\n",
    "    return processed_data\n",
    "\n",
    "\n",
    "import itertools\n",
    "\n",
    "nums = [0, 1, 2, 3]\n",
    "\n",
    "# --- List of tuples (default from itertools.combinations) ---\n",
    "all_combs_tuples = []\n",
    "for r in range(2, len(nums) + 1):\n",
    "    all_combs_tuples.extend(itertools.combinations(nums, r))\n",
    "\n",
    "# all_combs_lists = [list(c) for c in all_combs_tuples if 0 in c]\n",
    "all_combs_lists = [[0], [3], [0, 1, 2, 3]]\n",
    "print(all_combs_lists)\n",
    "\n",
    "with open(f\"./conv2d_data/conv2d_psd_scaled_down_1up_{mode}.pkl\", \"rb\") as f:\n",
    "    loaded_dict = pickle.load(f)\n",
    "\n",
    "# ### [N, 4, 1, 512] - channels first\n",
    "# processed_channels_first = process_loaded_dict(\n",
    "#     loaded_dict,\n",
    "#     row_indices=[0, 4],\n",
    "#     col_size=1024,\n",
    "#     val_ratio=0.2,\n",
    "#     output_format=\"channels_first\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### X_train, X_val, y_train, y_val, dist_train, dist_val = processed['fan3_3spd_augment']\n",
    "aggregated_combs_data_lst = []\n",
    "for comb in all_combs_lists:\n",
    "\n",
    "    ### [N, 1, 4, 512] - channels last\n",
    "    processed_channels_last = process_loaded_dict(\n",
    "        loaded_dict,\n",
    "        row_indices=comb,\n",
    "        col_size=1024,\n",
    "        val_ratio=0.2,\n",
    "        output_format=\"channels_last\"\n",
    "    )\n",
    "    all_X_train, all_X_val = [], []\n",
    "    all_y_train, all_y_val = [], []\n",
    "    all_dist_train, all_dist_val = [], []\n",
    "\n",
    "    for key, (X_train, X_val, y_train, y_val, dist_train, dist_val) in processed_channels_last.items():\n",
    "        all_X_train.append(X_train)\n",
    "        all_X_val.append(X_val)\n",
    "        all_y_train.append(y_train)\n",
    "        all_y_val.append(y_val)\n",
    "        all_dist_train.append(dist_train)\n",
    "        all_dist_val.append(dist_val)\n",
    "\n",
    "    ### Concatenate along first axis\n",
    "    # X_train = np.concatenate(all_X_train, axis=0)\n",
    "    # X_val   = np.concatenate(all_X_val, axis=0)\n",
    "    # y_train = np.concatenate(all_y_train, axis=0)\n",
    "    # y_val   = np.concatenate(all_y_val, axis=0)\n",
    "    # dist_train = np.concatenate(all_dist_train, axis=0)\n",
    "    # dist_val   = np.concatenate(all_dist_val, axis=0)\n",
    "\n",
    "    X_train = np.concatenate(all_X_train, axis=0).squeeze(1)\n",
    "    X_val = np.concatenate(all_X_val, axis=0).squeeze(1)\n",
    "    y_train = np.concatenate(all_y_train, axis=0)\n",
    "    y_val = np.concatenate(all_y_val, axis=0)\n",
    "    dist_train = np.concatenate(all_dist_train, axis=0)\n",
    "    dist_val = np.concatenate(all_dist_val, axis=0)\n",
    "\n",
    "    aggregated_combs_data_lst.append((X_train, X_val, y_train, y_val, dist_train, dist_val))\n",
    "\n",
    "print(f\"Datasets length={len(aggregated_combs_data_lst)}, combination_length={len(all_combs_lists)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from magtach.op_codes.nn_functions import DiceLoss, OverlapDiceLoss\n",
    "from magtach.op_codes.nn_models import FPN_2D, FPN_1D, FPN_2D_regression, FPN_1D_regression, FPN_2_1up, FPN_2, \\\n",
    "    FPN_2_1up, FCN1D\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from magtach.op_codes.mtl_models import MTL_1, MTL_2\n",
    "from magtach.op_codes.ppsp_mtl import FPN_2_mtl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "def plot_region_masks(model_1_output, model_2_output, index=0):\n",
    "    \"\"\"\n",
    "    model_1_output: list like [[region_mask_f0, gt_y], ...]\n",
    "    model_2_output: list like [[mask_f0, mask_2f0, mask_3f0, mask_4f0], ...]\n",
    "    index: which sample to visualize\n",
    "    \"\"\"\n",
    "    # unpack\n",
    "    f0_mask, gt_y = model_1_output[index]\n",
    "    masks = model_2_output[index]  # list of harmonic masks\n",
    "    x = np.arange(len(f0_mask))\n",
    "\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(10, 6), sharex=True)\n",
    "\n",
    "    # ---- Row 1: fundamental vs ground truth ----\n",
    "    axes[0].plot(x, gt_y, label='Ground Truth (all harmonics)', color='gray', linewidth=2, alpha=0.7)\n",
    "    axes[0].plot(x, f0_mask, label='Fundamental region (Head1)', color='blue', linewidth=2)\n",
    "    axes[0].set_title('Model 1 Output — Fundamental vs Ground Truth')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, linestyle='--', alpha=0.4)\n",
    "\n",
    "    # ---- Row 2: individual harmonic regions ----\n",
    "    colors = ['r', 'g', 'b', 'orange']\n",
    "    labels = ['f0', '2f0', '3f0', '4f0']\n",
    "\n",
    "    for i, mask in enumerate(masks):\n",
    "        axes[1].plot(x, mask, color=colors[i % len(colors)], label=labels[i], linewidth=2)\n",
    "\n",
    "    axes[1].set_title('Model 2 Output — Individual Harmonic Regions')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, linestyle='--', alpha=0.4)\n",
    "\n",
    "    plt.xlabel('Frequency Bin')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def make_gaussian(zero_mask, center_idx, psd_length=1024, sigma=block_width):\n",
    "    \"\"\"Smooth Gaussian mask centered at center_idx.\"\"\"\n",
    "    x = np.arange(psd_length)\n",
    "    gaussian = (1 / np.sqrt(2 * np.pi * sigma ** 2)) * np.exp(-0.5 * ((x - center_idx) / sigma) ** 2)\n",
    "    gaussian /= gaussian.max()\n",
    "    final_mask = np.maximum(zero_mask, gaussian)\n",
    "    return final_mask.astype(np.float32)\n",
    "\n",
    "\n",
    "def make_block_mask(zero_mask, center_idx, psd_length=1024, block_width=block_width):\n",
    "    \"\"\"Binary block mask: 1 in a window around center_idx, else 0.\"\"\"\n",
    "    start = max(0, center_idx - block_width)\n",
    "    end = min(psd_length, center_idx + block_width + 1)\n",
    "    mask = zero_mask.copy()\n",
    "    mask[start:end] = 1.0\n",
    "    return mask.astype(np.float32)\n",
    "\n",
    "\n",
    "def remake_targets(batch_y, total_num_outputs=6, mode=mode, psd_length=1024, block_width=block_width):\n",
    "    \"\"\"\n",
    "    Builds multi-task targets for both fundamental and synthetically generated harmonics (2F0, 3F0, 4F0).\n",
    "    mode: 'gaussian' or 'block'\n",
    "    \"\"\"\n",
    "    batch_y_np = batch_y.numpy()\n",
    "    model1_list, model2_list = [], []\n",
    "\n",
    "    for b in range(batch_y_np.shape[0]):\n",
    "        cur_mask = batch_y_np[b]\n",
    "        f0_indices = np.where(cur_mask == 1)[0]\n",
    "        if len(f0_indices) == 0:\n",
    "            continue\n",
    "\n",
    "        f0_idx = int(f0_indices[0])+block_width\n",
    "        zero_mask = np.zeros(psd_length, dtype=np.float32)\n",
    "\n",
    "        # --- compute synthetic harmonic indices ---\n",
    "        harmonic_indices = [f0_idx * i for i in range(1, 5)]\n",
    "        harmonic_indices = [min(idx, psd_length - 1) for idx in harmonic_indices]\n",
    "\n",
    "        # --- make region masks ---\n",
    "        if mode == \"gaussian\":\n",
    "            f0_mask = make_gaussian(zero_mask, harmonic_indices[0], psd_length, block_width)\n",
    "            f2_mask = make_gaussian(zero_mask, harmonic_indices[1], psd_length, block_width)\n",
    "            f3_mask = make_gaussian(zero_mask, harmonic_indices[2], psd_length, block_width)\n",
    "            f4_mask = make_gaussian(zero_mask, harmonic_indices[3], psd_length, block_width)\n",
    "        elif mode == \"block\":\n",
    "            f0_mask = make_block_mask(zero_mask, harmonic_indices[0], psd_length, block_width)\n",
    "            f2_mask = make_block_mask(zero_mask, harmonic_indices[1], psd_length, block_width)\n",
    "            f3_mask = make_block_mask(zero_mask, harmonic_indices[2], psd_length, block_width)\n",
    "            f4_mask = make_block_mask(zero_mask, harmonic_indices[3], psd_length, block_width)\n",
    "        else:\n",
    "            raise ValueError(\"mode must be 'gaussian' or 'block'\")\n",
    "\n",
    "        # --- stack for both model heads ---\n",
    "        model1_list.append(np.stack([f0_mask, cur_mask], axis=0))\n",
    "        model2_list.append(np.stack([f0_mask, f2_mask, f3_mask, f4_mask], axis=0))\n",
    "\n",
    "    model1_targets = torch.from_numpy(np.stack(model1_list)).float().to(device)\n",
    "    model2_targets = torch.from_numpy(np.stack(model2_list)).float().to(device)\n",
    "    return model1_targets, model2_targets\n",
    "\n",
    "\n",
    "# device = torch.device('mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "### Training function\n",
    "def train_fpn2d_model(X_train, y_train, X_val, y_val, num_epochs=50, batch_size=100, learning_rate=0.001, model=None,\n",
    "                      model_name=\"\", train_model_flag=False):\n",
    "    \"\"\"\n",
    "    Train FPN_2D model with format: [batch_size, 1, channels, 512]\n",
    "    \"\"\"\n",
    "    ### Convert to tensors\n",
    "    X_train_tensor = torch.FloatTensor(X_train)\n",
    "    y_train_tensor = torch.FloatTensor(y_train)\n",
    "    X_val_tensor = torch.FloatTensor(X_val)\n",
    "    y_val_tensor = torch.FloatTensor(y_val)\n",
    "\n",
    "    print(f\"Training data shapes:\")\n",
    "    print(f\"X_train_tensor: {X_train_tensor.shape}\")  # [num_samples, 1, selected_rows, 512]\n",
    "    print(f\"y_train_tensor: {y_train_tensor.shape}\")  # [num_samples, 512]\n",
    "    print(f\"X_val_tensor: {X_val_tensor.shape}\")  # [num_samples, 1, selected_rows, 512]\n",
    "    print(f\"y_val_tensor: {y_val_tensor.shape}\")  # [num_samples, 512]\n",
    "\n",
    "    ### Create datasets and dataloaders\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    ### Initialize model, loss, optimizer\n",
    "\n",
    "    model.to(device)\n",
    "    # criterion = DiceLoss()\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    criterion = OverlapDiceLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-3)\n",
    "\n",
    "    if train_model_flag:\n",
    "\n",
    "        # Training variables\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        best_val_loss = float('inf')\n",
    "        best_model_weights = None\n",
    "\n",
    "        ### Training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            ### Training phase\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "\n",
    "            for batch_x, batch_y in train_loader:\n",
    "                model1_targets, model2_targets = remake_targets(batch_y)\n",
    "                plot_region_masks(model1_targets, model2_targets)\n",
    "                batch_x = batch_x.to(device)  # [batch_size, 1, 2, 512]\n",
    "                batch_y = batch_y.to(device)  # [batch_size, 512]\n",
    "\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(batch_x)  # [batch_size, 1, 2, 512] -> [batch_size, 1, 1, 512]\n",
    "                # loss = criterion(outputs.squeeze(1), batch_y)  # Remove extra dimensions\n",
    "                ### loss function for model mtl1\n",
    "                # loss_fundamental = criterion(outputs[0].squeeze(1), model1_targets[:, 0, :])\n",
    "                loss_fundamental = criterion(outputs.squeeze(1), model1_targets[:, 0, :])\n",
    "                # loss_harmonic = criterion(outputs[1].squeeze(1), model1_targets[:, 1, :])\n",
    "\n",
    "                alpha = 0.5\n",
    "                # loss = alpha * loss_fundamental + (1 - alpha) * loss_harmonic\n",
    "                loss = loss_fundamental\n",
    "                ### loss function for model mtl2\n",
    "                # loss_f0 = criterion(outputs[0].squeeze(1), model2_targets[:, 0, :])\n",
    "                # loss_2f0 = criterion(outputs[1].squeeze(1), model2_targets[:, 1, :])\n",
    "                # loss_3f0 = criterion(outputs[2].squeeze(1), model2_targets[:, 2, :])\n",
    "                # loss_4f0 = criterion(outputs[3].squeeze(1), model2_targets[:, 3, :])\n",
    "                # loss = (loss_f0 + loss_2f0 + loss_3f0 + loss_4f0)*(1/model2_targets.shape[1])\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += loss.item() * batch_x.size(0)\n",
    "\n",
    "            train_loss /= len(train_loader.dataset)\n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            ### Validation phase\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for batch_x, batch_y in val_loader:\n",
    "                    model1_targets, model2_targets = remake_targets(batch_y)\n",
    "                    batch_x = batch_x.to(device)  # [batch_size, 1, 2, 512]\n",
    "                    batch_y = batch_y.to(device)  # [batch_size, 512]\n",
    "\n",
    "                    outputs = model(batch_x)  # [batch_size, 1, 1, 512]\n",
    "                    # loss = criterion(outputs.squeeze(1), batch_y)\n",
    "\n",
    "                    ### loss function for model mtl1\n",
    "                    # loss_fundamental = criterion(outputs[0].squeeze(1), model1_targets[:, 0, :])\n",
    "                    loss_fundamental = criterion(outputs.squeeze(1), model1_targets[:, 0, :])\n",
    "                    # loss_harmonic = criterion(outputs[1].squeeze(1), model1_targets[:, 1, :])\n",
    "\n",
    "                    alpha = 0.5\n",
    "                    # loss = alpha * loss_fundamental + (1 - alpha) * loss_harmonic\n",
    "                    loss = loss_fundamental\n",
    "                    ### loss function for model mtl2\n",
    "                    # loss_f0 = criterion(outputs[0].squeeze(1), model2_targets[:, 0, :])\n",
    "                    # loss_2f0 = criterion(outputs[1].squeeze(1), model2_targets[:, 1, :])\n",
    "                    # loss_3f0 = criterion(outputs[2].squeeze(1), model2_targets[:, 2, :])\n",
    "                    # loss_4f0 = criterion(outputs[3].squeeze(1), model2_targets[:, 3, :])\n",
    "                    # loss = (loss_f0 + loss_2f0 + loss_3f0 + loss_4f0)*(1/model2_targets.shape[1])\n",
    "\n",
    "                    val_loss += loss.item() * batch_x.size(0)\n",
    "\n",
    "            val_loss /= len(val_loader.dataset)\n",
    "            val_losses.append(val_loss)\n",
    "\n",
    "            ### Save best model\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model_weights = model.state_dict().copy()\n",
    "                torch.save(best_model_weights, f'{model_name}')\n",
    "\n",
    "            if (epoch + 1) % 50 == 0:\n",
    "                print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
    "                      f'Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, '\n",
    "                      f'Best Val: {best_val_loss:.4f}')\n",
    "\n",
    "        cur_combination = model_name.split('_')[4].split('.')[0]\n",
    "        # Plot training history\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(train_losses, label='Training Loss')\n",
    "        plt.plot(val_losses, label='Validation Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('MSE Loss')\n",
    "        plt.title('Training and Validation Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(f'training_history_{cur_combination}.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        # plt.show()\n",
    "\n",
    "        ### Load best model\n",
    "        model.load_state_dict(torch.load(f\"{model_name}\", map_location=torch.device(device)))\n",
    "        model.eval()\n",
    "        print(f\"Best validation loss: {best_val_loss:.6f}\")\n",
    "    else:\n",
    "        pass\n",
    "        ### Load best model\n",
    "        # model.load_state_dict(torch.load(f\"{model_name}\", map_location=torch.device(device)))\n",
    "        # model.eval()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "for ind, (X_train, X_val, y_train, y_val, dist_train, dist_val) in enumerate(aggregated_combs_data_lst):\n",
    "    # model = FPN_2(in_channels=X_train.shape[1], out_channels=32)\n",
    "    # model = FPN_2_1up(in_channels=X_train.shape[1], encoded_channels=32, output_size=1024)\n",
    "    # model = FCN1D(in_channels=X_train.shape[1], num_classes=1024, kernel_size=7)\n",
    "    # model1 = MTL_1(in_ch=X_train.shape[1], seq_len=1024, base=32, hidden=512, dilations=(1, 1, 1))\n",
    "    # model1 = MTL_2(in_ch=X_train.shape[1], seq_len=1024, base=32, hidden=512, num_heads=4,dilations=(1, 1, 1))\n",
    "    model1 = FPN_2_mtl(in_channels=X_train.shape[1],out_channels=32)\n",
    "    # model = FPN_2D(in_channels=1,base_channels=32)\n",
    "    print(f\"Training model: best_fpn1d_model_{mode}_{all_combs_lists[ind]}.pth\")\n",
    "    ### Train the model\n",
    "    trained_model = train_fpn2d_model(\n",
    "        X_train, y_train, X_val, y_val,\n",
    "        num_epochs=200,\n",
    "        batch_size=100,\n",
    "        learning_rate=0.001,\n",
    "        model=model1,\n",
    "        model_name=f\"best_fpn2_1up_model_{mode}_{all_combs_lists[ind]}.pth\",\n",
    "        train_model_flag=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model = FPN_1D(in_channels=1, base_channels=16, output_size=y_train.shape[1])\n",
    "# model = FPN_2D(in_channels=1, base_channels=16, output_size=y_train.shape[1])\n",
    "\n",
    "# model = FPN_1D_regression(in_channels=1, base_channels=32, input_size=psd_length)\n",
    "# model = FPN_2D_regression(in_channels=1, base_channels=32,input_height=X_train.shape[2], input_width=psd_length)\n",
    "# criterion = torch.nn.MSELoss()\n",
    "\n",
    "# model = Conv2d_1up(in_channels=1,nb_classes=y_train.shape[1])\n",
    "\n",
    "# model = FPN_2_1up(in_channels=X_train.shape[1])\n",
    "# model = FPN_2()\n",
    "# model.to(device)\n",
    "# criterion = DiceLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "# %matplotlib widget\n",
    "import matplotlib\n",
    "import librosa\n",
    "\n",
    "matplotlib.use('QT5Agg')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, pickle, re\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from magtach.op_codes.preprocess_functions import read_files, min_max_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_model_training = not(trained_model.training)\n",
    "# print(F\"Model in testing mode: {is_model_training}\")\n",
    "root_folder_pth = f\"../data/\"\n",
    "### testing folders bldc_2 and bldc_6\n",
    "from collections import OrderedDict\n",
    "### (\"bldc_5\", 45.5),\n",
    "test_folders_lst = [ (\"bldc_5\", 45.5), (\"bldc_2\", 80.25), (\"bldc_6\", 131.81)]\n",
    "\n",
    "psd_length = 1024\n",
    "fs = 44100\n",
    "ss_num_chunks, welch_num_chunks = 3, 2\n",
    "psd_scale_down_factors = [1, 2, 3, 'sum']\n",
    "plot_fig, save_fig = True, False\n",
    "### calculating resample factors\n",
    "pattern = re.compile(r\"(\\d+)cm\")\n",
    "\n",
    "test_dict = OrderedDict()\n",
    "save_test_data = False\n",
    "mode = \"gaussian\"\n",
    "if save_test_data:\n",
    "    for _, (test_folder, fund_freq) in enumerate(test_folders_lst):\n",
    "        print(test_folder, fund_freq)\n",
    "\n",
    "        cur_folder_pth = os.path.join(root_folder_pth, test_folder)\n",
    "        if not os.path.exists(cur_folder_pth):\n",
    "            print(f\"{cur_folder_pth} does not exist\")\n",
    "            continue\n",
    "        else:\n",
    "            data_folder_pth = os.path.join(cur_folder_pth, \"testing\")\n",
    "            files_lst = os.listdir(data_folder_pth)\n",
    "\n",
    "            orig_signal_lst, file_names_lst = [], []\n",
    "            distances_lst, fund_freq_lst = [], []\n",
    "            test_x, test_y = [], []\n",
    "\n",
    "            for file in files_lst:\n",
    "\n",
    "                if file not in [\".DS_Store\"]:\n",
    "                    print(file)\n",
    "\n",
    "                    cur_file_pth = os.path.join(data_folder_pth, file)\n",
    "                    cur_signal = np.sum(read_files(cur_file_pth), axis=0)\n",
    "\n",
    "                    orig_signal_lst.append(cur_signal)\n",
    "                    file_names_lst.append(file)\n",
    "\n",
    "                    try:\n",
    "                        match = pattern.search(file)\n",
    "                        cm_value = int(match.group(1))\n",
    "                        distances_lst.append(cm_value)\n",
    "                    except:\n",
    "                        distances_lst.append(0)\n",
    "\n",
    "                    try:\n",
    "                        cur_fund_freq = round(int(file.split(\"_\")[2]) / 60, 4)\n",
    "                        fund_freq_lst.append(cur_fund_freq)\n",
    "                    except:\n",
    "                        cur_fund_freq = fund_freq\n",
    "                        fund_freq_lst.append(cur_fund_freq)\n",
    "\n",
    "                    num_pnts = len(cur_signal) // welch_num_chunks\n",
    "\n",
    "                    fxx, cur_pxx = signal.welch(cur_signal, fs, nperseg=num_pnts, nfft=fs)\n",
    "                    log_pxx = np.log(cur_pxx)\n",
    "\n",
    "                    # true_mask, cur_fund_freq_lst= make_true_mask_v2(cur_fund_freq, psd_length=psd_length, sigma=4.0, n_harmonics=100,\n",
    "                    #                               mode=mode, band_width=4)\n",
    "                    true_mask, cur_fund_freq_lst = make_true_mask_v2(cur_fund_freq, psd_length=psd_length, sigma=3.0, n_harmonics=100,\n",
    "                                                      mode=mode, band_width=3)\n",
    "                    cur_psds = []\n",
    "\n",
    "                    for scale_factor in psd_scale_down_factors:\n",
    "                        if scale_factor not in ['sum']:\n",
    "                            cur_scaled_psd = scale_psd(log_pxx, psd_length, scale_factor, method=\"average\")\n",
    "                            # cur_psds.append(cur_scaled_psd)\n",
    "                            cur_psds.append(min_max_norm(cur_scaled_psd))\n",
    "\n",
    "                    stacked = np.stack(cur_psds, axis=0)\n",
    "                    max_psd = np.median(stacked, axis=0)\n",
    "                    cur_psds.append(min_max_norm(max_psd))\n",
    "\n",
    "                    cur_x, cur_y = np.array(cur_psds), true_mask\n",
    "\n",
    "                    # plot_psds_with_mask(cur_psds,true_mask,file=f\"{file}.png\", resamp_factor=1,cur_fund_freq=cur_fund_freq,psd_scale_down_factors=psd_scale_down_factors,save_fig=save_fig,out_dir=f\"./\")\n",
    "\n",
    "                    test_x.append(cur_x)\n",
    "                    test_y.append(cur_y)\n",
    "\n",
    "            test_dict[test_folder] = [test_x, test_y, fund_freq_lst, distances_lst, file_names_lst, orig_signal_lst]\n",
    "\n",
    "    with open(f\"./conv2d_data/conv2d_psd_scaled_down_1up_{mode}_test.pkl\", \"wb\") as f:\n",
    "        pickle.dump(test_dict, f)\n",
    "\n",
    "    print(f\"Saved dictionary to conv2d_psd_scaled_down_1up_{mode}_test.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_dict(loaded_dict, row_indices=[0, 4], col_size=512, output_format=\"channels_first\"):\n",
    "    processed_data = {}\n",
    "\n",
    "    for key, (test_x, test_y, fund_freq_lst, distances_lst, file_names_lst, orig_signal_lst) in loaded_dict.items():\n",
    "        test_x = np.array(test_x)\n",
    "        test_y = np.array(test_y)\n",
    "        distances_lst = np.array(distances_lst)\n",
    "        fund_freq_lst = np.array(fund_freq_lst)\n",
    "        orig_signal_lst = np.array(orig_signal_lst)\n",
    "\n",
    "        # Select rows and columns size (preserve original order - no sorting)\n",
    "        X = test_x[:, row_indices, :col_size]\n",
    "        y = test_y\n",
    "\n",
    "        # Reshape based on desired output format\n",
    "        if output_format == \"channels_first\":\n",
    "            X = X[:, :, np.newaxis, :]  # [N, num_channels, 1, col_size]\n",
    "        elif output_format == \"channels_last\":\n",
    "\n",
    "            X = X[:, np.newaxis, :, :]  # [N, 1, num_channels, col_size]\n",
    "        else:\n",
    "            raise ValueError(\"output_format must be 'channels_first' or 'channels_last'\")\n",
    "\n",
    "        # Return all data in original order (no train/val split)\n",
    "        processed_data[key] = (X, y, fund_freq_lst, distances_lst, file_names_lst, orig_signal_lst)\n",
    "\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fuzzy_logic_functions as fuzzy_funcs\n",
    "import warnings, pickle\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "mode = \"gaussian\"\n",
    "# all_combs_lists = [[0], [3], [0, 1, 2, 3]]\n",
    "all_combs_lists = [[0]]\n",
    "import matplotlib\n",
    "matplotlib.use('QT5Agg')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch, os\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "# from magtach.op_codes.nn_models import FPN_2D, FPN_1D, FPN_2D_regression, FPN_1D_regression, FPN_2_1up, FPN_2, \\\n",
    "#     FPN_2_1up, FCN1D, FCN1D_resnet, SEResNet1D_FC\n",
    "from magtach.op_codes.mtl_models import MTL_1, MTL_2, MTL_1_v1\n",
    "# from magtach.op_codes.ppsp_mtl import FPN_2_mtl\n",
    "# from magtach.op_codes.ppsp_mtl_6 import FPN_2_MTL_Residual\n",
    "from magtach.op_codes.ppsp_mtl_7 import MTL_V1_Residual_FundGuidesHarm\n",
    "# from magtach.op_codes.ppsp_mtl_8 import FPN_2, FundamentalFromHarmonics\n",
    "from magtach.op_codes.ppsp_mtl_9 import  FPN_2,FPN2_withFundamental\n",
    "from magtach.op_codes.ppsp_mtl_1up import FPN_2_mtl\n",
    "# from magtach.op_codes.ppsp_mtl_3 import FPN_2_mtl\n",
    "# from magtach.op_codes.ppsp_mtl_5 import DualBranchDenseMTL\n",
    "# from magtach.op_codes.ppsp_mtl_1 import FPN_2_MTL_Dual\n",
    "# from magtach.op_codes.ppsp_1up_head import PPSP_withFundamental, PPSP\n",
    "import copy\n",
    "# device = torch.device('mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "fpn2_weights_pth=\"../data/train_test_data/\"\n",
    "\n",
    "fpn_weights_file = \"best_model_weights_fan5_fan3_bldc_fpn2\"\n",
    "model_name2 = \"best_fpn2_1up_model_gaussian_[0].pth\"\n",
    "\n",
    "# ---- Load base FPN_2 ----\n",
    "harm_model = FPN_2()\n",
    "harm_model.load_state_dict(torch.load(f'../data/train_test_data/{fpn_weights_file}', map_location=\"cpu\"))\n",
    "harm_model.eval()\n",
    "\n",
    "# ---- Create wrapper ----\n",
    "trained_model2 = FPN2_withFundamental(copy.deepcopy(harm_model))\n",
    "trained_model2.eval()\n",
    "\n",
    "# ---- Load fundamental head weights ----\n",
    "trained_model2.load_state_dict(torch.load(f\"{model_name2}\", map_location=\"cpu\"), strict=False)\n",
    "\n",
    "# ---- Reapply harmonic weights to ensure identical BN stats ----\n",
    "trained_model2.harm_net.load_state_dict(torch.load(f'../data/train_test_data/{fpn_weights_file}', map_location=\"cpu\"))\n",
    "\n",
    "trained_model3 = FPN_2_mtl(in_channels=1,out_channels=32)\n",
    "model_name3=\"crepe\"\n",
    "trained_model3.load_state_dict(torch.load(f'./1up_weights/best_fpn2_1up_model_gaussian_[0].pth', map_location=\"cpu\"))\n",
    "trained_model3.eval()\n",
    "\n",
    "\n",
    "\n",
    "print(F\"ppsp+1up in testing mode: {not(trained_model2.training)}\")\n",
    "# print(F\"crepe in testing mode: {not(trained_model3.training)}\")\n",
    "\n",
    "files=pickle.load(open(f\"../data/train_test_data/test_x_y_bldc_correct\",\"rb\"))\n",
    "test_dict_lst =files[0]\n",
    "\n",
    "dir_path = f\"./conv2d_data/pred_plots/[0]/\"\n",
    "os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "for ind, values in enumerate(test_dict_lst):\n",
    "\n",
    "    if values[1] in [\"bldc_6\",\"bldc_5\"]:\n",
    "        print(f\"{values[1]}\")\n",
    "        test_dict, fundamental_freq = values[0], values[2]\n",
    "        res_file = f\"{values[1]}_results\"\n",
    "\n",
    "        for key, val in test_dict.items():\n",
    "            if key == key:\n",
    "                print(key, len(val))\n",
    "                cur_results = []\n",
    "\n",
    "                for sig_ind in range(len(val)):\n",
    "                    # print(sig_ind)\n",
    "                    cur_fil_name = val[sig_ind][4]\n",
    "                    print(cur_fil_name)\n",
    "\n",
    "                    orig_sig = np.array(val[sig_ind][3])\n",
    "                    cur_x, cur_y = val[sig_ind][0], val[sig_ind][1][:1, :][0]\n",
    "\n",
    "                    cur_x = torch.tensor(cur_x, dtype=torch.float32).reshape(1, 1, -1)\n",
    "\n",
    "                    crepe_prediction = trained_model3(cur_x)\n",
    "                    ppsp_1up_prediction = trained_model2(cur_x)\n",
    "\n",
    "                    # cur_pred= trained_model(cur_x)\n",
    "                    # cur_pred = torch.sigmoid(cur_pred)\n",
    "                    # pred = cur_pred[0][0].detach().numpy()\n",
    "                    # pred = np.where(pred <= 0.5, 0, pred)\n",
    "\n",
    "                    crepe_fund = torch.sigmoid(crepe_prediction).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "\n",
    "                    ppsp_fund = torch.sigmoid(ppsp_1up_prediction[0]).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "                    ppsp_harmonics = torch.sigmoid(ppsp_1up_prediction[1]).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "\n",
    "                    # ppsp_harmonics=np.where(ppsp_harmonics <= 0.5, 0, ppsp_harmonics)\n",
    "\n",
    "                    ppsp_fund = (ppsp_fund - np.min(ppsp_fund)) / (np.max(ppsp_fund) - np.min(ppsp_fund) + 1e-12)\n",
    "\n",
    "                    crepe_fund = (crepe_fund - np.min(crepe_fund)) / (np.max(crepe_fund) - np.min(crepe_fund) + 1e-12)\n",
    "\n",
    "\n",
    "\n",
    "                    plt_fil_name = f\"{fundamental_freq}-{cur_fil_name}\"\n",
    "\n",
    "\n",
    "\n",
    "                    fig, axes = plt.subplots(1, 2, figsize=(10, 4), sharey=True)\n",
    "\n",
    "                    # --- Left: FPN_2 prediction + input channels ---\n",
    "                    for ind_x in range(cur_x.squeeze(0).shape[0]):\n",
    "                        axes[0].plot(cur_x.squeeze(0)[ind_x], linewidth=1.2, alpha=0.9)\n",
    "                    axes[0].plot(cur_y, linewidth=1.1, label=\"True\",color=\"orange\", alpha=0.7)\n",
    "                    axes[0].plot(ppsp_fund, '--',linewidth=0.8, color=\"green\", label=\"ppsp_1up\", alpha=0.8)\n",
    "                    axes[0].plot(np.maximum(0.3,ppsp_harmonics*0.8),'--', linewidth=0.7, color=\"red\", label=\"non normalized_harmonics\", alpha=0.9)\n",
    "                    axes[0].set_title(\"ppsp_1up\")\n",
    "                    axes[0].legend(loc=\"lower right\")\n",
    "\n",
    "                    # --- Right: FPN_2_mtl prediction + same inputs for reference ---\n",
    "                    for ind_x in range(cur_x.squeeze(0).shape[0]):\n",
    "                        axes[1].plot(cur_x.squeeze(0)[ind_x], linewidth=1.2, alpha=0.7)\n",
    "                    axes[1].plot(cur_y, linewidth=1, label=\"True\", alpha=0.8)\n",
    "                    axes[1].plot(crepe_fund,'--', linewidth=0.8, color=\"green\", label=\"1up\", alpha=0.9)\n",
    "                    axes[1].set_title(\"1up(crepe)\")\n",
    "                    axes[1].legend(loc=\"lower right\")\n",
    "\n",
    "                    plt.suptitle(f\"{fundamental_freq} Hz – {cur_fil_name}\", fontsize=11)\n",
    "                    plt.tight_layout()\n",
    "\n",
    "                    # plt.savefig(os.path.join(dir_path, f\"{plt_fil_name}_compare.png\"), dpi=150)\n",
    "                    # plt.close()\n",
    "                    plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fuzzy_logic_functions as fuzzy_funcs\n",
    "import warnings, pickle\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "mode = \"gaussian\"\n",
    "# all_combs_lists = [[0], [3], [0, 1, 2, 3]]\n",
    "all_combs_lists = [[0],[3]]\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "# from magtach.op_codes.nn_models import FPN_2D, FPN_1D, FPN_2D_regression, FPN_1D_regression, FPN_2_1up, FPN_2, \\\n",
    "#     FPN_2_1up, FCN1D, FCN1D_resnet, SEResNet1D_FC\n",
    "# from magtach.op_codes.mtl_models import MTL_1, MTL_2, MTL_1_v1\n",
    "# from magtach.op_codes.ppsp_mtl import FPN_2_mtl\n",
    "# from magtach.op_codes.ppsp_mtl_6 import FPN_2_MTL_Residual\n",
    "# from magtach.op_codes.ppsp_mtl_7 import MTL_V1_Residual_FundGuidesHarm\n",
    "# from magtach.op_codes.ppsp_mtl_8 import FPN_2, FundamentalFromHarmonics\n",
    "from magtach.op_codes.ppsp_mtl_9 import FPN_2, FPN2_withFundamental\n",
    "# from magtach.op_codes.ppsp_mtl_1up import FPN_2_mtl\n",
    "# from magtach.op_codes.ppsp_mtl_3 import FPN_2_mtl\n",
    "# from magtach.op_codes.ppsp_mtl_5 import DualBranchDenseMTL\n",
    "# from magtach.op_codes.ppsp_mtl_1 import FPN_2_MTL_Dual\n",
    "from magtach.op_codes.crepe_1up import FPN_2_mtl\n",
    "# from magtach.op_codes.fpn_2 import PPSP\n",
    "# from magtach.op_codes.ppsp_1up_head import PPSP_withFundamental, PPSP\n",
    "# from magtach.op_codes.ppsp_1up import PPSP_1up\n",
    "import copy\n",
    "# device = torch.device('mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "# fpn2_weights_pth=\"../data/train_test_data/\"\n",
    "# fpn_weights_file= \"best_model_weights_fan5_fan3_bldc_fpn2\"\n",
    "\n",
    "def dice_coeff(predictions, targets, smooth=1):\n",
    "    predictions = predictions.astype(float)\n",
    "    targets = targets.astype(float)\n",
    "    intersection = (predictions * targets).sum()\n",
    "    dice = (2. * intersection + smooth) / (predictions.sum() + targets.sum() + smooth)\n",
    "    return dice\n",
    "\n",
    "\n",
    "def overlap_dice(predictions, targets, threshold=0.3, smooth=1e-6):\n",
    "    ## Binarize predictions\n",
    "    preds_bin = (predictions > threshold).astype(float)\n",
    "    targets_bin = (targets > 0.1).astype(float)\n",
    "    ## True positive region: predictions overlapping target\n",
    "    TP = np.sum(preds_bin * targets_bin)\n",
    "    ## False positives outside true regions\n",
    "    FP = np.sum(preds_bin * (1 - targets_bin))\n",
    "    FN = np.sum((1 - preds_bin) * targets_bin)\n",
    "    ## Denominator = TP + FP + smoothing\n",
    "    # dice = TP / (TP + FP + smooth)\n",
    "    ## F1 score as the loss\n",
    "    f1_score = (2 * TP) / ((2 * TP) + FP + FN)\n",
    "    return f1_score\n",
    "\n",
    "\n",
    "def region_accuracy(y_true, y_pred, threshold=0.5):\n",
    "    true_idx = np.where(y_true == 1)[0]\n",
    "    pred_idx = np.where(y_pred == 1)[0]\n",
    "\n",
    "    if len(true_idx) == 0 and len(pred_idx) == 0:\n",
    "        return 1.0\n",
    "    if len(true_idx) == 0 or len(pred_idx) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    overlap = len(np.intersect1d(true_idx, pred_idx))\n",
    "\n",
    "    frac_overlap = overlap / len(true_idx)\n",
    "\n",
    "    return 1.0 if frac_overlap >= threshold else 0.0\n",
    "\n",
    "\n",
    "with open(f\"./conv2d_data/conv2d_psd_scaled_down_1up_{mode}_test.pkl\", \"rb\") as f:\n",
    "    loaded_dict_test = pickle.load(f)\n",
    "\n",
    "for ind, comb_lst in enumerate(all_combs_lists):\n",
    "\n",
    "    dir_path = f\"./conv2d_data/pred_plots/{comb_lst}/\"\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "    fpn2_weights_pth=\"../data/train_test_data/\"\n",
    "\n",
    "    fpn_weights_file = \"best_model_weights_fan5_fan3_bldc_fpn2\"\n",
    "    model_name2 = \"best_fpn2_1up_model_gaussian_[0].pth\"\n",
    "\n",
    "    # ---- Load base FPN_2 ----\n",
    "    harm_model = FPN_2()\n",
    "    harm_model.load_state_dict(torch.load(f'../data/train_test_data/{fpn_weights_file}', map_location=\"cpu\"))\n",
    "    harm_model.eval()\n",
    "\n",
    "    # ---- Create wrapper ----\n",
    "    trained_model2 = FPN2_withFundamental(copy.deepcopy(harm_model))\n",
    "    trained_model2.eval()\n",
    "\n",
    "    # ---- Load fundamental head weights ----\n",
    "    trained_model2.load_state_dict(torch.load(f\"{model_name2}\", map_location=\"cpu\"), strict=False)\n",
    "\n",
    "    # ---- Reapply harmonic weights to ensure identical BN stats ----\n",
    "    trained_model2.harm_net.load_state_dict(torch.load(f'../data/train_test_data/{fpn_weights_file}', map_location=\"cpu\"))\n",
    "\n",
    "    trained_model3 = FPN_2_mtl(in_channels=1,out_channels=32)\n",
    "    model_name3=\"crepe\"\n",
    "    trained_model3.load_state_dict(torch.load(f'./1up_weights/best_fpn2_1up_model_gaussian_[0].pth', map_location=\"cpu\"))\n",
    "    trained_model3.eval()\n",
    "\n",
    "    processed_test = process_test_dict(\n",
    "        loaded_dict_test,\n",
    "        row_indices=comb_lst,\n",
    "        col_size=1024,\n",
    "        output_format=\"channels_last\"  # or \"channels_first\"\n",
    "    )\n",
    "    # device = torch.device('mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    for key, (X_test, y_test, fund_freq, distances, file_names, orig_sig) in processed_test.items():\n",
    "        print(f\"Key: {key}\")\n",
    "        prediction_lst = []\n",
    "        freq_prediction_lst, fund_freq_lst = [], []\n",
    "        if key == \"bldc_6\":\n",
    "            for ind in range(len(distances)):\n",
    "                if ind == ind:\n",
    "                    cur_fund_freq = fund_freq[ind]\n",
    "                    cur_fil_name = file_names[ind]\n",
    "\n",
    "                    # cur_x = np.array(X_test[ind])[np.newaxis,:,:,:]\n",
    "                    cur_x = np.array(X_test[ind])[:, :, :]\n",
    "                    torch_x = torch.FloatTensor(cur_x).to('cpu')\n",
    "                    cur_y = np.array(y_test[ind])\n",
    "\n",
    "                    # cur_prediction = trained_model(torch_x).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "                    # cur_prediction = torch.sigmoid(trained_model(torch_x)).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "                    cur_prediction = trained_model2(torch_x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    # fund_pred = torch.softmax(cur_prediction[0], dim=1).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "                    fund_pred = torch.sigmoid(cur_prediction[0]).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "                    # fund_pred = torch.sigmoid(cur_prediction).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "\n",
    "                    # fund_pred2 = torch.sigmoid(cur_prediction2[0]).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "                    # all_harmonic_pred = torch.sigmoid(cur_prediction2[1]).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "                    all_harmonic_pred1 = torch.sigmoid(cur_prediction[1]).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "                    # all_harmonic_pred2 = torch.sigmoid(cur_prediction[3]).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "                    # prediction_lst.append(cur_prediction)\n",
    "                    # cur_prediction_norm = (cur_prediction - np.min(cur_prediction)) / (np.max(cur_prediction) - np.min(cur_prediction) + 1e-12)\n",
    "\n",
    "                    cur_fund_prediction_norm = (fund_pred - np.min(fund_pred)) / (np.max(fund_pred) - np.min(fund_pred) + 1e-12)\n",
    "\n",
    "                    # cur_fund_prediction_norm2 = (fund_pred2 - np.min(fund_pred2)) / (np.max(fund_pred2) - np.min(fund_pred2) + 1e-12)\n",
    "                    #\n",
    "                    # cur_harmonic_prediction_norm = (all_harmonic_pred - np.min(all_harmonic_pred)) / (np.max(all_harmonic_pred) - np.min(all_harmonic_pred) + 1e-12)\n",
    "                    cur_harmonic_prediction_norm1 = (all_harmonic_pred1 - np.min(all_harmonic_pred1)) / (np.max(all_harmonic_pred1) - np.min(all_harmonic_pred1) + 1e-12)\n",
    "                    # cur_harmonic_prediction_norm2 = (all_harmonic_pred2 - np.min(all_harmonic_pred2)) / (np.max(all_harmonic_pred2) - np.min(all_harmonic_pred2) + 1e-12)\n",
    "\n",
    "\n",
    "                    # binary_cur_prediction=np.where(cur_prediction_norm<=0.35,0,1)\n",
    "                    binary_cur_prediction=cur_fund_prediction_norm\n",
    "                    binary_cur_truth=cur_y\n",
    "\n",
    "\n",
    "                    plt_fil_name = f\"{cur_fund_freq}-{cur_fil_name}_{comb_lst}\"\n",
    "\n",
    "                    plt.title(f\"{cur_fund_freq} - {cur_fil_name}_{comb_lst}\")\n",
    "                    for ind_x in range(cur_x.squeeze(0).shape[0]):\n",
    "                        plt.plot(cur_x.squeeze(0)[ind_x],linewidth=1.2)\n",
    "                    # plt.plot(cur_x.squeeze(0)[0])\n",
    "                    # plt.plot(cur_x.squeeze(0)[1])\n",
    "\n",
    "                    plt.plot(binary_cur_truth, linewidth=1.1, label=\"True\",alpha=0.8)\n",
    "                    # plt.plot(binary_cur_prediction, '--', linewidth=1, label=\"Predicted\")\n",
    "                    # plt.plot(cur_prediction, linewidth=0.8, label=\"raw prediction\")\n",
    "\n",
    "                    plt.plot(cur_fund_prediction_norm, linewidth=0.8, label=\" f0\",alpha=0.8)\n",
    "                    plt.plot(cur_harmonic_prediction_norm1, '--', linewidth=0.7, label=\"raw all_harmonics\",alpha=0.8)\n",
    "                    # plt.plot(cur_fund_prediction_norm, linewidth=0.8,label=\"ppsp_original\",alpha=0.8)\n",
    "\n",
    "                    # plt.plot(fund_pred2, linewidth=0.8, label=\"raw f0\",alpha=0.8)\n",
    "                    # plt.plot(all_harmonic_pred, linewidth=0.7, label=\"raw all_harmonics\",alpha=0.8)\n",
    "                    # plt.plot(fund_pred, linewidth=0.8,label=\"ppsp_original\",alpha=0.8)\n",
    "                    # plt.plot(cur_harmonic_prediction_norm2, linewidth=0.8, label=\"f3\")\n",
    "                    plt.legend(loc='lower right')\n",
    "\n",
    "                    # plt.savefig(f\"./conv2d_data/pred_plots/{plt_fil_name}.png\")\n",
    "                    # plt.close()\n",
    "                    #\n",
    "                    # plt.savefig(os.path.join(dir_path, f\"{plt_fil_name}.png\"), dpi=150)\n",
    "                    # plt.close()\n",
    "\n",
    "                    plt.show()\n",
    "\n",
    "\n",
    "                    # fig, axes = plt.subplots(2, 2, figsize=(10, 4), sharey=True)\n",
    "                    #\n",
    "                    # # --- Left: FPN_2 prediction + input channels ---\n",
    "                    # for ind_x in range(cur_x.squeeze(0).shape[0]):\n",
    "                    #     axes[0].plot(cur_x.squeeze(0)[ind_x], linewidth=1.2, alpha=0.9)\n",
    "                    # axes[0].plot(binary_cur_truth, linewidth=1.1, label=\"True\",color=\"orange\", alpha=0.7)\n",
    "                    # axes[0].plot(cur_fund_prediction_norm2,'--', linewidth=0.7, color=\"green\", label=\"ppsp_1up\", alpha=0.8)\n",
    "                    # axes[0].plot(all_harmonic_pred*0.8,'--', linewidth=0.7, color=\"red\", label=\"non normalized_harmonics\", alpha=0.9)\n",
    "                    # axes[0].set_title(\"ppsp_1up\")\n",
    "                    # axes[0].legend(loc=\"lower right\")\n",
    "                    #\n",
    "                    # # --- Right: FPN_2_mtl prediction + same inputs for reference ---\n",
    "                    # for ind_x in range(cur_x.squeeze(0).shape[0]):\n",
    "                    #     axes[1].plot(cur_x.squeeze(0)[ind_x], linewidth=1.2, alpha=0.7)\n",
    "                    # axes[1].plot(binary_cur_truth, linewidth=1, label=\"True\", alpha=0.8)\n",
    "                    # axes[1].plot(cur_fund_prediction_norm,'--', linewidth=0.8, color=\"green\", label=\"1up\", alpha=0.9)\n",
    "                    # axes[1].set_title(\"1up(crepe)\")\n",
    "                    # axes[1].legend(loc=\"lower right\")\n",
    "                    #\n",
    "                    # plt.suptitle(f\"{cur_fund_freq} Hz – {cur_fil_name}_{comb_lst}\", fontsize=11)\n",
    "                    # plt.tight_layout()\n",
    "                    #\n",
    "                    # # plt.savefig(os.path.join(dir_path, f\"{plt_fil_name}_compare.png\"), dpi=150)\n",
    "                    # # plt.close()\n",
    "                    # plt.show()\n",
    "\n",
    "\n",
    "                    # cur_pred_accuracy = dice_coeff(binary_cur_prediction, binary_cur_truth)\n",
    "                    cur_overlap_accuracy = overlap_dice(binary_cur_prediction, binary_cur_truth)\n",
    "\n",
    "                    ### fuzzy logic\n",
    "                    # lr_strt, lr_end, cur_peak = fuzzy_funcs.lr_prediction(binary_cur_prediction,cur_x.squeeze(0).squeeze(0)[0],cur_fund_freq, distances[ind],plt_fil_name)\n",
    "                    # print(f\"lrstart: {lr_strt},lrend: {lr_end}, lrpeak: {cur_peak}\")\n",
    "\n",
    "                    # freq_pred = fuzzy_funcs.predict_freq(orig_sig[ind], orig_sig[ind], lr_strt, lr_end,\n",
    "                    #                                      cur_peak)\n",
    "                    # print(f\"fundamental freq: {cur_fund_freq},freq_pred: {freq_pred}\")\n",
    "\n",
    "                    # fund_freq_lst.append(cur_fund_freq)\n",
    "                    # freq_prediction_lst.append(freq_pred)\n",
    "                    # criterion = torch.nn.BCELoss()\n",
    "                    # loss = criterion(binary_cur_prediction, binary_cur_truth)\n",
    "                    # cur_pred_accuracy2= torch.nn.BCELoss()(binary_cur_prediction, binary_cur_truth)\n",
    "                    # cur_pred_accuracy = region_accuracy(binary_cur_truth, binary_cur_prediction, threshold=0.3)\n",
    "\n",
    "                    prediction_lst.append(cur_overlap_accuracy)\n",
    "                    #\n",
    "                    # print(f\"freqpred: {freq_pred}\")\n",
    "                    # prediction_lst.append(freq_pred)\n",
    "\n",
    "            accuracy = sum(prediction_lst) / len(prediction_lst)\n",
    "            # Convert to numpy arrays\n",
    "            cur_gtruth = np.array(fund_freq) * 60\n",
    "            cur_predict = np.array(prediction_lst) * 60\n",
    "\n",
    "            #### filter out rows where cur_predict == 0\n",
    "            # filtered_data = [(gt, pred) for gt, pred in zip(cur_gtruth, cur_predict) if pred != 0]\n",
    "            #\n",
    "            # filtered_gtruth, filtered_predict = zip(*filtered_data)\n",
    "            # filtered_gtruth = np.array(filtered_gtruth)\n",
    "            # filtered_predict = np.array(filtered_predict)\n",
    "\n",
    "            #### Calculate absolute error and mean percentage error\n",
    "            # abs_err = np.abs(filtered_gtruth - filtered_predict)\n",
    "            # mean_err = np.mean((abs_err / filtered_gtruth) * 100)\n",
    "            abs_err = np.abs(cur_gtruth - cur_predict)\n",
    "            mean_err = np.mean((abs_err/cur_gtruth)*100)\n",
    "\n",
    "            df = pd.DataFrame({\n",
    "                'fundamental_frequency': list(fund_freq),\n",
    "                'predictions_array': prediction_lst,\n",
    "                'distance': list(distances),\n",
    "                'file_name': file_names\n",
    "                # 'fund_freq': fund_freq_lst,\n",
    "                # 'predictions': freq_prediction_lst\n",
    "            })\n",
    "            # # df = df[df['predictions_array'] != 0]\n",
    "            # df['abs_err'] = np.abs((df['fundamental_frequency'] * 60) - (df['predictions_array'] * 60))\n",
    "            # #### Save to CSV\n",
    "            df.to_csv(f\"{dir_path}/{key}_{accuracy}_conv1d_ppsp.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fuzzy_logic_functions as fuzzy_funcs\n",
    "# import warnings, pickle\n",
    "#\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "# mode = \"gaussian\"\n",
    "# # all_combs_lists = [[0], [3], [0, 1, 2, 3]]\n",
    "# all_combs_lists = [[0],[3]]\n",
    "# import torch\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "# # from magtach.op_codes.nn_models import FPN_2D, FPN_1D, FPN_2D_regression, FPN_1D_regression, FPN_2_1up, FPN_2, \\\n",
    "# #     FPN_2_1up, FCN1D, FCN1D_resnet, SEResNet1D_FC\n",
    "# from magtach.op_codes.mtl_models import MTL_1, MTL_2, MTL_1_v1\n",
    "# # from magtach.op_codes.ppsp_mtl import FPN_2_mtl\n",
    "# # from magtach.op_codes.ppsp_mtl_6 import FPN_2_MTL_Residual\n",
    "# # from magtach.op_codes.ppsp_mtl_7 import MTL_V1_Residual_FundGuidesHarm\n",
    "# # from magtach.op_codes.ppsp_mtl_8 import FPN_2, FundamentalFromHarmonics\n",
    "# # from magtach.op_codes.ppsp_mtl_9 import FPN_2, FPN2_withFundamental\n",
    "# # from magtach.op_codes.ppsp_mtl_1up import FPN_2_mtl\n",
    "# # from magtach.op_codes.ppsp_mtl_3 import FPN_2_mtl\n",
    "# # from magtach.op_codes.ppsp_mtl_5 import DualBranchDenseMTL\n",
    "# # from magtach.op_codes.ppsp_mtl_1 import FPN_2_MTL_Dual\n",
    "# from magtach.op_codes.crepe_1up import FPN_2_mtl\n",
    "# # from magtach.op_codes.fpn_2 import PPSP\n",
    "# from magtach.op_codes.ppsp_1up_head import PPSP_withFundamental, PPSP\n",
    "# # from magtach.op_codes.ppsp_1up import PPSP_1up\n",
    "# import copy\n",
    "# # device = torch.device('mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = 'cpu'\n",
    "# # fpn2_weights_pth=\"../data/train_test_data/\"\n",
    "# # fpn_weights_file= \"best_model_weights_fan5_fan3_bldc_fpn2\"\n",
    "#\n",
    "# def dice_coeff(predictions, targets, smooth=1):\n",
    "#     predictions = predictions.astype(float)\n",
    "#     targets = targets.astype(float)\n",
    "#     intersection = (predictions * targets).sum()\n",
    "#     dice = (2. * intersection + smooth) / (predictions.sum() + targets.sum() + smooth)\n",
    "#     return dice\n",
    "#\n",
    "#\n",
    "# def overlap_dice(predictions, targets, threshold=0.3, smooth=1e-6):\n",
    "#     ## Binarize predictions\n",
    "#     preds_bin = (predictions > threshold).astype(float)\n",
    "#     targets_bin = (targets > 0.1).astype(float)\n",
    "#     ## True positive region: predictions overlapping target\n",
    "#     TP = np.sum(preds_bin * targets_bin)\n",
    "#     ## False positives outside true regions\n",
    "#     FP = np.sum(preds_bin * (1 - targets_bin))\n",
    "#     FN = np.sum((1 - preds_bin) * targets_bin)\n",
    "#     ## Denominator = TP + FP + smoothing\n",
    "#     # dice = TP / (TP + FP + smooth)\n",
    "#     ## F1 score as the loss\n",
    "#     f1_score = (2 * TP) / ((2 * TP) + FP + FN)\n",
    "#     return f1_score\n",
    "#\n",
    "#\n",
    "# def region_accuracy(y_true, y_pred, threshold=0.5):\n",
    "#     true_idx = np.where(y_true == 1)[0]\n",
    "#     pred_idx = np.where(y_pred == 1)[0]\n",
    "#\n",
    "#     if len(true_idx) == 0 and len(pred_idx) == 0:\n",
    "#         return 1.0\n",
    "#     if len(true_idx) == 0 or len(pred_idx) == 0:\n",
    "#         return 0.0\n",
    "#\n",
    "#     overlap = len(np.intersect1d(true_idx, pred_idx))\n",
    "#\n",
    "#     frac_overlap = overlap / len(true_idx)\n",
    "#\n",
    "#     return 1.0 if frac_overlap >= threshold else 0.0\n",
    "#\n",
    "#\n",
    "# with open(f\"./conv2d_data/conv2d_psd_scaled_down_1up_{mode}_test.pkl\", \"rb\") as f:\n",
    "#     loaded_dict_test = pickle.load(f)\n",
    "#\n",
    "# for ind, comb_lst in enumerate(all_combs_lists):\n",
    "#\n",
    "#     dir_path = f\"./conv2d_data/pred_plots/{comb_lst}/\"\n",
    "#     os.makedirs(dir_path, exist_ok=True)\n",
    "#\n",
    "#     # trained_model = FPN_2(in_channels=len(comb_lst), out_channels=32)\n",
    "#     # trained_model = FPN_2_1up(in_channels=len(comb_lst), encoded_channels=32, output_size=1024)\n",
    "#\n",
    "#     # trained_model = FCN1D(in_channels=len(comb_lst), num_classes=1024, kernel_size=7)\n",
    "#     # trained_model =  SEResNet1D_FC(in_channels=len(comb_lst), kernel_size=7)\n",
    "#     # trained_model = MTL_1(in_ch=len(comb_lst), seq_len=1024, base=8, hidden=512, dilations=(1, 1,  1))\n",
    "#     # trained_model = MTL_2(in_ch=len(comb_lst), seq_len=1024, base=32, hidden=512,dilations=(1, 1, 1))\n",
    "#     # trained_model = MTL_2(in_ch=len(comb_lst), seq_len=1024, base=8, hidden=256,dilations=(1, 1, 1))\n",
    "#     # trained_model = FPN_2_mtl(in_channels=len(comb_lst),fusion_type=\"local\")\n",
    "#     # trained_model = FPN_2_MTL_Dual(in_channels=len(comb_lst))\n",
    "#     # trained_model = FCN1D_resnet(in_channels=len(comb_lst), num_classes=1024, kernel_size=3)\n",
    "#     # trained_model = FCN1D(in_channels=len(comb_lst), num_classes=1024, kernel_size=7)\n",
    "#\n",
    "#\n",
    "#     # trained_model = FPN_2_mtl(in_channels=len(comb_lst),out_channels=32)\n",
    "#     trained_model = PPSP(in_channels=len(comb_lst),out_channels=32)\n",
    "#     # trained_model = PPSP_1up(in_channels=len(comb_lst),out_channels=32)\n",
    "#     model_name = f\"ppsp[0].pth\"\n",
    "#     # model_name = f\"best_fpn2_1up_model_{mode}_{comb_lst}.pth\"\n",
    "#     # model_name = f\"best_ppsp_model_gaussian_[0]_100cm.pth\"\n",
    "#     trained_model.load_state_dict(torch.load(f\"{model_name}\", map_location=torch.device('cpu')))\n",
    "#     trained_model.eval()\n",
    "#\n",
    "#     trained_model2 = PPSP_withFundamental(trained_model, freeze=True, hidden=256)\n",
    "#     # trained_model = PPSP_1up(in_channels=len(comb_lst),out_channels=32)\n",
    "#     model_name2 = f\"best_fpn2_1up_model_gaussian_[0].pth\"\n",
    "#     # model_name = f\"best_fpn2_1up_model_{mode}_{comb_lst}.pth\"\n",
    "#     # model_name = f\"best_ppsp_model_gaussian_[0]_100cm.pth\"\n",
    "#     trained_model2.load_state_dict(torch.load(f\"{model_name2}\", map_location=torch.device('cpu')))\n",
    "#     trained_model2.eval()\n",
    "#\n",
    "#\n",
    "#\n",
    "#     processed_test = process_test_dict(\n",
    "#         loaded_dict_test,\n",
    "#         row_indices=comb_lst,\n",
    "#         col_size=1024,\n",
    "#         output_format=\"channels_last\"  # or \"channels_first\"\n",
    "#     )\n",
    "#     # device = torch.device('mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#     print(f\"Using device: {device}\")\n",
    "#\n",
    "#     for key, (X_test, y_test, fund_freq, distances, file_names, orig_sig) in processed_test.items():\n",
    "#         print(f\"Key: {key}\")\n",
    "#         prediction_lst = []\n",
    "#         freq_prediction_lst, fund_freq_lst = [], []\n",
    "#         if key == \"bldc_6\":\n",
    "#             for ind in range(len(distances)):\n",
    "#                 if ind == ind:\n",
    "#                     cur_fund_freq = fund_freq[ind]\n",
    "#                     cur_fil_name = file_names[ind]\n",
    "#\n",
    "#                     # cur_x = np.array(X_test[ind])[np.newaxis,:,:,:]\n",
    "#                     cur_x = np.array(X_test[ind])[:, :, :]\n",
    "#                     torch_x = torch.FloatTensor(cur_x).to('cpu')\n",
    "#                     cur_y = np.array(y_test[ind])\n",
    "#\n",
    "#                     # cur_prediction = trained_model(torch_x).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "#                     # cur_prediction = torch.sigmoid(trained_model(torch_x)).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "#                     cur_prediction = trained_model2(torch_x)\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#                     # fund_pred = torch.softmax(cur_prediction[0], dim=1).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "#                     fund_pred = torch.sigmoid(cur_prediction[0]).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "#                     # fund_pred = torch.sigmoid(cur_prediction).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "#\n",
    "#                     # fund_pred2 = torch.sigmoid(cur_prediction2[0]).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "#                     # all_harmonic_pred = torch.sigmoid(cur_prediction2[1]).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "#                     all_harmonic_pred1 = torch.sigmoid(cur_prediction[1]).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "#                     # all_harmonic_pred2 = torch.sigmoid(cur_prediction[3]).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "#                     # prediction_lst.append(cur_prediction)\n",
    "#                     # cur_prediction_norm = (cur_prediction - np.min(cur_prediction)) / (np.max(cur_prediction) - np.min(cur_prediction) + 1e-12)\n",
    "#\n",
    "#                     cur_fund_prediction_norm = (fund_pred - np.min(fund_pred)) / (np.max(fund_pred) - np.min(fund_pred) + 1e-12)\n",
    "#\n",
    "#                     # cur_fund_prediction_norm2 = (fund_pred2 - np.min(fund_pred2)) / (np.max(fund_pred2) - np.min(fund_pred2) + 1e-12)\n",
    "#                     #\n",
    "#                     # cur_harmonic_prediction_norm = (all_harmonic_pred - np.min(all_harmonic_pred)) / (np.max(all_harmonic_pred) - np.min(all_harmonic_pred) + 1e-12)\n",
    "#                     cur_harmonic_prediction_norm1 = (all_harmonic_pred1 - np.min(all_harmonic_pred1)) / (np.max(all_harmonic_pred1) - np.min(all_harmonic_pred1) + 1e-12)\n",
    "#                     # cur_harmonic_prediction_norm2 = (all_harmonic_pred2 - np.min(all_harmonic_pred2)) / (np.max(all_harmonic_pred2) - np.min(all_harmonic_pred2) + 1e-12)\n",
    "#\n",
    "#\n",
    "#                     # binary_cur_prediction=np.where(cur_prediction_norm<=0.35,0,1)\n",
    "#                     binary_cur_prediction=cur_fund_prediction_norm\n",
    "#                     binary_cur_truth=cur_y\n",
    "#\n",
    "#\n",
    "#                     plt_fil_name = f\"{cur_fund_freq}-{cur_fil_name}_{comb_lst}\"\n",
    "#\n",
    "#                     plt.title(f\"{cur_fund_freq} - {cur_fil_name}_{comb_lst}\")\n",
    "#                     for ind_x in range(cur_x.squeeze(0).shape[0]):\n",
    "#                         plt.plot(cur_x.squeeze(0)[ind_x],linewidth=1.2)\n",
    "#                     # plt.plot(cur_x.squeeze(0)[0])\n",
    "#                     # plt.plot(cur_x.squeeze(0)[1])\n",
    "#\n",
    "#                     plt.plot(binary_cur_truth, linewidth=1.1, label=\"True\",alpha=0.8)\n",
    "#                     # plt.plot(binary_cur_prediction, '--', linewidth=1, label=\"Predicted\")\n",
    "#                     # plt.plot(cur_prediction, linewidth=0.8, label=\"raw prediction\")\n",
    "#\n",
    "#                     plt.plot(cur_fund_prediction_norm, linewidth=0.8, label=\" f0\",alpha=0.8)\n",
    "#                     plt.plot(cur_harmonic_prediction_norm1, '--', linewidth=0.7, label=\"raw all_harmonics\",alpha=0.8)\n",
    "#                     # plt.plot(cur_fund_prediction_norm, linewidth=0.8,label=\"ppsp_original\",alpha=0.8)\n",
    "#\n",
    "#                     # plt.plot(fund_pred2, linewidth=0.8, label=\"raw f0\",alpha=0.8)\n",
    "#                     # plt.plot(all_harmonic_pred, linewidth=0.7, label=\"raw all_harmonics\",alpha=0.8)\n",
    "#                     # plt.plot(fund_pred, linewidth=0.8,label=\"ppsp_original\",alpha=0.8)\n",
    "#                     # plt.plot(cur_harmonic_prediction_norm2, linewidth=0.8, label=\"f3\")\n",
    "#                     plt.legend(loc='lower right')\n",
    "#\n",
    "#                     # plt.savefig(f\"./conv2d_data/pred_plots/{plt_fil_name}.png\")\n",
    "#                     # plt.close()\n",
    "#                     #\n",
    "#                     # plt.savefig(os.path.join(dir_path, f\"{plt_fil_name}.png\"), dpi=150)\n",
    "#                     # plt.close()\n",
    "#\n",
    "#                     plt.show()\n",
    "#\n",
    "#\n",
    "#                     # fig, axes = plt.subplots(2, 2, figsize=(10, 4), sharey=True)\n",
    "#                     #\n",
    "#                     # # --- Left: FPN_2 prediction + input channels ---\n",
    "#                     # for ind_x in range(cur_x.squeeze(0).shape[0]):\n",
    "#                     #     axes[0].plot(cur_x.squeeze(0)[ind_x], linewidth=1.2, alpha=0.9)\n",
    "#                     # axes[0].plot(binary_cur_truth, linewidth=1.1, label=\"True\",color=\"orange\", alpha=0.7)\n",
    "#                     # axes[0].plot(cur_fund_prediction_norm2,'--', linewidth=0.7, color=\"green\", label=\"ppsp_1up\", alpha=0.8)\n",
    "#                     # axes[0].plot(all_harmonic_pred*0.8,'--', linewidth=0.7, color=\"red\", label=\"non normalized_harmonics\", alpha=0.9)\n",
    "#                     # axes[0].set_title(\"ppsp_1up\")\n",
    "#                     # axes[0].legend(loc=\"lower right\")\n",
    "#                     #\n",
    "#                     # # --- Right: FPN_2_mtl prediction + same inputs for reference ---\n",
    "#                     # for ind_x in range(cur_x.squeeze(0).shape[0]):\n",
    "#                     #     axes[1].plot(cur_x.squeeze(0)[ind_x], linewidth=1.2, alpha=0.7)\n",
    "#                     # axes[1].plot(binary_cur_truth, linewidth=1, label=\"True\", alpha=0.8)\n",
    "#                     # axes[1].plot(cur_fund_prediction_norm,'--', linewidth=0.8, color=\"green\", label=\"1up\", alpha=0.9)\n",
    "#                     # axes[1].set_title(\"1up(crepe)\")\n",
    "#                     # axes[1].legend(loc=\"lower right\")\n",
    "#                     #\n",
    "#                     # plt.suptitle(f\"{cur_fund_freq} Hz – {cur_fil_name}_{comb_lst}\", fontsize=11)\n",
    "#                     # plt.tight_layout()\n",
    "#                     #\n",
    "#                     # # plt.savefig(os.path.join(dir_path, f\"{plt_fil_name}_compare.png\"), dpi=150)\n",
    "#                     # # plt.close()\n",
    "#                     # plt.show()\n",
    "#\n",
    "#\n",
    "#                     # cur_pred_accuracy = dice_coeff(binary_cur_prediction, binary_cur_truth)\n",
    "#                     cur_overlap_accuracy = overlap_dice(binary_cur_prediction, binary_cur_truth)\n",
    "#\n",
    "#                     ### fuzzy logic\n",
    "#                     # lr_strt, lr_end, cur_peak = fuzzy_funcs.lr_prediction(binary_cur_prediction,cur_x.squeeze(0).squeeze(0)[0],cur_fund_freq, distances[ind],plt_fil_name)\n",
    "#                     # print(f\"lrstart: {lr_strt},lrend: {lr_end}, lrpeak: {cur_peak}\")\n",
    "#\n",
    "#                     # freq_pred = fuzzy_funcs.predict_freq(orig_sig[ind], orig_sig[ind], lr_strt, lr_end,\n",
    "#                     #                                      cur_peak)\n",
    "#                     # print(f\"fundamental freq: {cur_fund_freq},freq_pred: {freq_pred}\")\n",
    "#\n",
    "#                     # fund_freq_lst.append(cur_fund_freq)\n",
    "#                     # freq_prediction_lst.append(freq_pred)\n",
    "#                     # criterion = torch.nn.BCELoss()\n",
    "#                     # loss = criterion(binary_cur_prediction, binary_cur_truth)\n",
    "#                     # cur_pred_accuracy2= torch.nn.BCELoss()(binary_cur_prediction, binary_cur_truth)\n",
    "#                     # cur_pred_accuracy = region_accuracy(binary_cur_truth, binary_cur_prediction, threshold=0.3)\n",
    "#\n",
    "#                     prediction_lst.append(cur_overlap_accuracy)\n",
    "#                     #\n",
    "#                     # print(f\"freqpred: {freq_pred}\")\n",
    "#                     # prediction_lst.append(freq_pred)\n",
    "#\n",
    "#             accuracy = sum(prediction_lst) / len(prediction_lst)\n",
    "#             # Convert to numpy arrays\n",
    "#             cur_gtruth = np.array(fund_freq) * 60\n",
    "#             cur_predict = np.array(prediction_lst) * 60\n",
    "#\n",
    "#             #### filter out rows where cur_predict == 0\n",
    "#             # filtered_data = [(gt, pred) for gt, pred in zip(cur_gtruth, cur_predict) if pred != 0]\n",
    "#             #\n",
    "#             # filtered_gtruth, filtered_predict = zip(*filtered_data)\n",
    "#             # filtered_gtruth = np.array(filtered_gtruth)\n",
    "#             # filtered_predict = np.array(filtered_predict)\n",
    "#\n",
    "#             #### Calculate absolute error and mean percentage error\n",
    "#             # abs_err = np.abs(filtered_gtruth - filtered_predict)\n",
    "#             # mean_err = np.mean((abs_err / filtered_gtruth) * 100)\n",
    "#             abs_err = np.abs(cur_gtruth - cur_predict)\n",
    "#             mean_err = np.mean((abs_err/cur_gtruth)*100)\n",
    "#\n",
    "#             df = pd.DataFrame({\n",
    "#                 'fundamental_frequency': list(fund_freq),\n",
    "#                 'predictions_array': prediction_lst,\n",
    "#                 'distance': list(distances),\n",
    "#                 'file_name': file_names\n",
    "#                 # 'fund_freq': fund_freq_lst,\n",
    "#                 # 'predictions': freq_prediction_lst\n",
    "#             })\n",
    "#             # # df = df[df['predictions_array'] != 0]\n",
    "#             # df['abs_err'] = np.abs((df['fundamental_frequency'] * 60) - (df['predictions_array'] * 60))\n",
    "#             # #### Save to CSV\n",
    "#             df.to_csv(f\"{dir_path}/{key}_{accuracy}_conv1d_ppsp.csv\", index=False)\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fuzzy_logic_functions as fuzzy_funcs\n",
    "# import warnings, pickle\n",
    "#\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "# mode = \"gaussian\"\n",
    "# # all_combs_lists = [[0], [3], [0, 1, 2, 3]]\n",
    "# all_combs_lists = [[0]]\n",
    "# import torch\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "# # from magtach.op_codes.nn_models import FPN_2D, FPN_1D, FPN_2D_regression, FPN_1D_regression, FPN_2_1up, FPN_2, \\\n",
    "# #     FPN_2_1up, FCN1D, FCN1D_resnet, SEResNet1D_FC\n",
    "# from magtach.op_codes.mtl_models import MTL_1, MTL_2, MTL_1_v1\n",
    "# # from magtach.op_codes.ppsp_mtl import FPN_2_mtl\n",
    "# # from magtach.op_codes.ppsp_mtl_6 import FPN_2_MTL_Residual\n",
    "# from magtach.op_codes.ppsp_mtl_7 import MTL_V1_Residual_FundGuidesHarm\n",
    "# # from magtach.op_codes.ppsp_mtl_8 import FPN_2, FundamentalFromHarmonics\n",
    "# from magtach.op_codes.ppsp_mtl_9 import FPN_2, FPN2_withFundamental\n",
    "# from magtach.op_codes.ppsp_mtl_1up import FPN_2_mtl\n",
    "# # from magtach.op_codes.ppsp_mtl_3 import FPN_2_mtl\n",
    "# # from magtach.op_codes.ppsp_mtl_5 import DualBranchDenseMTL\n",
    "# # from magtach.op_codes.ppsp_mtl_1 import FPN_2_MTL_Dual\n",
    "# import copy\n",
    "# # device = torch.device('mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = 'cpu'\n",
    "# fpn2_weights_pth=\"../data/train_test_data/\"\n",
    "# fpn_weights_file= \"best_model_weights_fan5_fan3_bldc_fpn2\"\n",
    "#\n",
    "# def dice_coeff(predictions, targets, smooth=1):\n",
    "#     predictions = predictions.astype(float)\n",
    "#     targets = targets.astype(float)\n",
    "#     intersection = (predictions * targets).sum()\n",
    "#     dice = (2. * intersection + smooth) / (predictions.sum() + targets.sum() + smooth)\n",
    "#     return dice\n",
    "#\n",
    "#\n",
    "# def overlap_dice(predictions, targets, threshold=0.3, smooth=1e-6):\n",
    "#     ## Binarize predictions\n",
    "#     preds_bin = (predictions > threshold).astype(float)\n",
    "#     targets_bin = (targets > 0.1).astype(float)\n",
    "#     ## True positive region: predictions overlapping target\n",
    "#     TP = np.sum(preds_bin * targets_bin)\n",
    "#     ## False positives outside true regions\n",
    "#     FP = np.sum(preds_bin * (1 - targets_bin))\n",
    "#     FN = np.sum((1 - preds_bin) * targets_bin)\n",
    "#     ## Denominator = TP + FP + smoothing\n",
    "#     # dice = TP / (TP + FP + smooth)\n",
    "#     ## F1 score as the loss\n",
    "#     f1_score = (2 * TP) / ((2 * TP) + FP + FN)\n",
    "#     return f1_score\n",
    "#\n",
    "#\n",
    "# def region_accuracy(y_true, y_pred, threshold=0.5):\n",
    "#     true_idx = np.where(y_true == 1)[0]\n",
    "#     pred_idx = np.where(y_pred == 1)[0]\n",
    "#\n",
    "#     if len(true_idx) == 0 and len(pred_idx) == 0:\n",
    "#         return 1.0\n",
    "#     if len(true_idx) == 0 or len(pred_idx) == 0:\n",
    "#         return 0.0\n",
    "#\n",
    "#     overlap = len(np.intersect1d(true_idx, pred_idx))\n",
    "#\n",
    "#     frac_overlap = overlap / len(true_idx)\n",
    "#\n",
    "#     return 1.0 if frac_overlap >= threshold else 0.0\n",
    "#\n",
    "#\n",
    "# with open(f\"./conv2d_data/conv2d_psd_scaled_down_1up_{mode}_test.pkl\", \"rb\") as f:\n",
    "#     loaded_dict_test = pickle.load(f)\n",
    "#\n",
    "# for ind, comb_lst in enumerate(all_combs_lists):\n",
    "#\n",
    "#     dir_path = f\"./conv2d_data/pred_plots/{comb_lst}/\"\n",
    "#     os.makedirs(dir_path, exist_ok=True)\n",
    "#\n",
    "#     # trained_model = FPN_2(in_channels=len(comb_lst), out_channels=32)\n",
    "#     # trained_model = FPN_2_1up(in_channels=len(comb_lst), encoded_channels=32, output_size=1024)\n",
    "#\n",
    "#     # trained_model = FCN1D(in_channels=len(comb_lst), num_classes=1024, kernel_size=7)\n",
    "#     # trained_model =  SEResNet1D_FC(in_channels=len(comb_lst), kernel_size=7)\n",
    "#     # trained_model = MTL_1(in_ch=len(comb_lst), seq_len=1024, base=8, hidden=512, dilations=(1, 1,  1))\n",
    "#     # trained_model = MTL_2(in_ch=len(comb_lst), seq_len=1024, base=32, hidden=512,dilations=(1, 1, 1))\n",
    "#     # trained_model = MTL_2(in_ch=len(comb_lst), seq_len=1024, base=8, hidden=256,dilations=(1, 1, 1))\n",
    "#     # trained_model = FPN_2_mtl(in_channels=len(comb_lst),fusion_type=\"local\")\n",
    "#     # trained_model = FPN_2_MTL_Dual(in_channels=len(comb_lst))\n",
    "#     # trained_model = FCN1D_resnet(in_channels=len(comb_lst), num_classes=1024, kernel_size=3)\n",
    "#     # trained_model = FCN1D(in_channels=len(comb_lst), num_classes=1024, kernel_size=7)\n",
    "#\n",
    "#     # trained_model = FPN_2()\n",
    "#     # model_name= \"FPN2\"\n",
    "#     # trained_model.load_state_dict(torch.load(f'../data/train_test_data/{fpn_weights_file}', map_location=torch.device('cpu')))\n",
    "#     # trained_model.eval()\n",
    "#\n",
    "#     # trained_model2 = MTL_V1_Residual_FundGuidesHarm(in_channels=len(comb_lst), gamma=0.5)\n",
    "#     # model_name2 = f\"best_fpn2_1up_model_{mode}_{comb_lst}.pth\"\n",
    "#     # trained_model2.load_state_dict(torch.load(f\"{model_name2}\", map_location=torch.device('cpu')))\n",
    "#     # trained_model2.eval()\n",
    "#     # harmonic_model = FPN_2(in_channels=1, out_channels=32)\n",
    "#     # harmonic_model.load_state_dict(torch.load(f'../data/train_test_data/{fpn_weights_file}',\n",
    "#     #                                           map_location=\"cpu\"))\n",
    "#     # trained_model = FPN_2()\n",
    "#     # model_name=\"ppsp\"\n",
    "#     # trained_model.load_state_dict(torch.load(f'../data/train_test_data/{fpn_weights_file}', map_location=\"cpu\"))\n",
    "#\n",
    "#     # trained_model3 = FPN_2_mtl(in_channels=len(comb_lst),out_channels=32)\n",
    "#     # model_name3=\"ppsp_1up\"\n",
    "#     # trained_model3.load_state_dict(torch.load(f'./1up_weights/best_fpn2_1up_model_gaussian_[0].pth', map_location=\"cpu\"))\n",
    "#     # trained_model3.eval()\n",
    "#     #\n",
    "#     # trained_model2 = FPN2_withFundamental(trained_model)\n",
    "#     # model_name2 = f\"best_fpn2_1up_model_{mode}_{comb_lst}.pth\"\n",
    "#     # trained_model2.load_state_dict(torch.load(f\"{model_name2}\", map_location=torch.device('cpu')))\n",
    "#     #\n",
    "#     # trained_model2.eval()\n",
    "#     #\n",
    "#     # trained_model.eval()\n",
    "#     #\n",
    "#     # is_model_training = not (trained_model.training)\n",
    "#     # print(F\"{model_name} in testing mode: {is_model_training}\")\n",
    "#     # print(F\"{model_name2} in testing mode: {trained_model2.training}\")\n",
    "#     model_name2 = \"best_fpn2_1up_model_gaussian_[0].pth\"\n",
    "#     # # ---- Load base FPN_2 ----\n",
    "#     harm_model = FPN_2()\n",
    "#     harm_model.load_state_dict(torch.load(f'../data/train_test_data/{fpn_weights_file}', map_location=\"cpu\"))\n",
    "#     harm_model.eval()\n",
    "#\n",
    "#     # ---- Create wrapper ----\n",
    "#     trained_model2 = FPN2_withFundamental(copy.deepcopy(harm_model), freeze=True)\n",
    "#     trained_model2.eval()\n",
    "#\n",
    "#     # ---- Load fundamental head weights ----\n",
    "#     trained_model2.load_state_dict(torch.load(f\"{model_name2}\", map_location=\"cpu\"), strict=False)\n",
    "#\n",
    "#     # ---- Reapply harmonic weights to ensure identical BN stats ----\n",
    "#     trained_model2.harm_net.load_state_dict(torch.load(f'../data/train_test_data/{fpn_weights_file}', map_location=\"cpu\"))\n",
    "#\n",
    "#\n",
    "#     trained_model3 = FPN_2_mtl(in_channels=1,out_channels=32)\n",
    "#     model_name3=\"crepe\"\n",
    "#     trained_model3.load_state_dict(torch.load(f'./1up_weights/best_fpn2_1up_model_gaussian_[0].pth', map_location=\"cpu\"))\n",
    "#     trained_model3.eval()\n",
    "#\n",
    "#\n",
    "#\n",
    "#     print(F\"ppsp+1up in testing mode: {not(trained_model2.training)}\")\n",
    "#     print(F\"crepe in testing mode: {not(trained_model3.training)}\")\n",
    "#\n",
    "#     processed_test = process_test_dict(\n",
    "#         loaded_dict_test,\n",
    "#         row_indices=comb_lst,\n",
    "#         col_size=1024,\n",
    "#         output_format=\"channels_last\"  # or \"channels_first\"\n",
    "#     )\n",
    "#     # device = torch.device('mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#     print(f\"Using device: {device}\")\n",
    "#\n",
    "#\n",
    "#     # \"\"\"crepe CAM\"\"\"\n",
    "#     # activations = {}\n",
    "#     # gradients = {}\n",
    "#     #\n",
    "#     # def save_activation(name):\n",
    "#     #     def hook(module, input, output):\n",
    "#     #         activations[name] = output.detach()\n",
    "#     #     return hook\n",
    "#     #\n",
    "#     # def save_gradient(name):\n",
    "#     #     def hook(module, grad_input, grad_output):\n",
    "#     #         gradients[name] = grad_output[0].detach()\n",
    "#     #     return hook\n",
    "#     #\n",
    "#     # target_layer = trained_model3.conv_block10.c\n",
    "#     # target_layer.register_forward_hook(save_activation(\"feat\"))\n",
    "#     # target_layer.register_backward_hook(save_gradient(\"feat\"))\n",
    "#\n",
    "#\n",
    "#     for key, (X_test, y_test, fund_freq, distances, file_names, orig_sig) in processed_test.items():\n",
    "#         print(f\"Key: {key}\")\n",
    "#         prediction_lst = []\n",
    "#         freq_prediction_lst, fund_freq_lst = [], []\n",
    "#         if key == key:\n",
    "#             for ind in range(len(distances)):\n",
    "#                 if ind == ind:\n",
    "#                     cur_fund_freq = fund_freq[ind]\n",
    "#                     cur_fil_name = file_names[ind]\n",
    "#\n",
    "#                     # cur_x = np.array(X_test[ind])[np.newaxis,:,:,:]\n",
    "#                     cur_x = np.array(X_test[ind])[:, :, :]\n",
    "#                     torch_x = torch.FloatTensor(cur_x).to('cpu')\n",
    "#                     cur_y = np.array(y_test[ind])\n",
    "#\n",
    "#                     # cur_prediction = trained_model(torch_x).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "#                     # cur_prediction = torch.sigmoid(trained_model(torch_x)).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "#                     cur_prediction = trained_model3(torch_x)\n",
    "#                     cur_prediction2 = trained_model2(torch_x)\n",
    "#                     \"\"\"\n",
    "#                     PPSP1up sailency map\n",
    "#                     \"\"\"\n",
    "#                     torch_x1 = torch.FloatTensor(cur_x).to('cpu').requires_grad_(True)\n",
    "#                     fund_pred, harm_pred = trained_model2(torch_x1)\n",
    "#                     target_index1 = np.argmax(fund_pred.detach().cpu().numpy())\n",
    "#                     score1 = fund_pred[0, 0, target_index1]\n",
    "#\n",
    "#                     trained_model2.zero_grad()\n",
    "#                     score1.backward(retain_graph=True)\n",
    "#\n",
    "#                     # Gradient w.r.t. input\n",
    "#                     input_grad1 = torch_x1.grad.detach().cpu().numpy().squeeze()\n",
    "#                     input_grad_abs1 = np.abs(input_grad1)\n",
    "#                     input_grad_norm1 = input_grad_abs1 / (np.max(input_grad_abs1) + 1e-12)\n",
    "#\n",
    "#\n",
    "#\n",
    "#                     # fund_pred = torch.softmax(cur_prediction[0], dim=1).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "#                     fund_pred = torch.sigmoid(cur_prediction).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "#                     fund_pred2 = torch.sigmoid(cur_prediction2[0]).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "#                     all_harmonic_pred = torch.sigmoid(cur_prediction2[1]).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "#                     # all_harmonic_pred1 = torch.sigmoid(cur_prediction[2]).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "#                     # all_harmonic_pred2 = torch.sigmoid(cur_prediction[3]).squeeze(1).squeeze(0).detach().cpu().numpy()\n",
    "#                     # prediction_lst.append(cur_prediction)\n",
    "#                     # cur_prediction_norm = (cur_prediction - np.min(cur_prediction)) / (np.max(cur_prediction) - np.min(cur_prediction) + 1e-12)\n",
    "#\n",
    "#                     cur_fund_prediction_norm = (fund_pred - np.min(fund_pred)) / (np.max(fund_pred) - np.min(fund_pred) + 1e-12)\n",
    "#\n",
    "#                     cur_fund_prediction_norm2 = (fund_pred2 - np.min(fund_pred2)) / (np.max(fund_pred2) - np.min(fund_pred2) + 1e-12)\n",
    "#\n",
    "#                     cur_harmonic_prediction_norm = (all_harmonic_pred - np.min(all_harmonic_pred)) / (np.max(all_harmonic_pred) - np.min(all_harmonic_pred) + 1e-12)\n",
    "#                     # cur_harmonic_prediction_norm1 = (all_harmonic_pred1 - np.min(all_harmonic_pred1)) / (np.max(all_harmonic_pred1) - np.min(all_harmonic_pred1) + 1e-12)\n",
    "#                     # cur_harmonic_prediction_norm2 = (all_harmonic_pred2 - np.min(all_harmonic_pred2)) / (np.max(all_harmonic_pred2) - np.min(all_harmonic_pred2) + 1e-12)\n",
    "#                     # Apply threshold (keep >=0.8, zero out rest)\n",
    "#                     # cur_fund_prediction_norm2[cur_fund_prediction_norm2 < 0.85] = 0\n",
    "#                     # cur_harmonic_prediction_norm[cur_harmonic_prediction_norm < 0.85] = 0\n",
    "#                     # cur_fund_prediction_norm[cur_harmonic_prediction_norm < 0.85] = 0\n",
    "#\n",
    "#\n",
    "#                     # binary_cur_prediction=np.where(cur_prediction_norm<=0.35,0,1)\n",
    "#                     binary_cur_prediction=all_harmonic_pred\n",
    "#                     binary_cur_truth=cur_y\n",
    "#                     # binary_cur_truth=np.where(cur_y<=0.35,0,1)\n",
    "#\n",
    "#                     # mod_cur_prediction = np.zeros(len(cur_prediction))\n",
    "#                     # max_f_pred = np.argmax(cur_prediction)\n",
    "#                     #\n",
    "#                     # mod_cur_prediction[max_f_pred - 1:max_f_pred + 5] = 1\n",
    "#                     # binary_cur_prediction = mod_cur_prediction\n",
    "#                     # binary_cur_truth = cur_y\n",
    "#\n",
    "#                     plt_fil_name = f\"{cur_fund_freq}-{cur_fil_name}_{comb_lst}\"\n",
    "#\n",
    "#                     # plt.title(f\"{cur_fund_freq} - {cur_fil_name}_{comb_lst}\")\n",
    "#                     # for ind_x in range(cur_x.squeeze(0).shape[0]):\n",
    "#                     #     plt.plot(cur_x.squeeze(0)[ind_x],linewidth=1.2)\n",
    "#                     # # plt.plot(cur_x.squeeze(0)[0])\n",
    "#                     # # plt.plot(cur_x.squeeze(0)[1])\n",
    "#                     #\n",
    "#                     # plt.plot(binary_cur_truth, linewidth=1.1, label=\"True\",alpha=0.8)\n",
    "#                     # # plt.plot(binary_cur_prediction, '--', linewidth=1, label=\"Predicted\")\n",
    "#                     # # plt.plot(cur_prediction, linewidth=0.8, label=\"raw prediction\")\n",
    "#                     #\n",
    "#                     # plt.plot(cur_fund_prediction_norm2, linewidth=0.8, label=\" f0\",alpha=0.8)\n",
    "#                     # # plt.plot(cur_harmonic_prediction_norm, '--', linewidth=0.7, label=\"raw all_harmonics\",alpha=0.8)\n",
    "#                     # # plt.plot(cur_fund_prediction_norm, linewidth=0.8,label=\"ppsp_original\",alpha=0.8)\n",
    "#                     #\n",
    "#                     # # plt.plot(fund_pred2, linewidth=0.8, label=\"raw f0\",alpha=0.8)\n",
    "#                     # # plt.plot(all_harmonic_pred, linewidth=0.7, label=\"raw all_harmonics\",alpha=0.8)\n",
    "#                     # # plt.plot(fund_pred, linewidth=0.8,label=\"ppsp_original\",alpha=0.8)\n",
    "#                     # # plt.plot(cur_harmonic_prediction_norm2, linewidth=0.8, label=\"f3\")\n",
    "#                     # plt.legend(loc='lower right')\n",
    "#                     #\n",
    "#                     # # plt.savefig(f\"./conv2d_data/pred_plots/{plt_fil_name}.png\")\n",
    "#                     # # plt.close()\n",
    "#                     # #\n",
    "#                     # # plt.savefig(os.path.join(dir_path, f\"{plt_fil_name}.png\"), dpi=150)\n",
    "#                     # # plt.close()\n",
    "#                     #\n",
    "#                     # plt.show()\n",
    "#                     \"\"\"\n",
    "#                     Class activation map crepe\n",
    "#                     \"\"\"\n",
    "#                     torch_x.requires_grad = True\n",
    "#                     output = trained_model3(torch_x)\n",
    "#                     target_index = np.argmax(output.detach().cpu().numpy())\n",
    "#                     score = output[0, 0, target_index]\n",
    "#                     trained_model3.zero_grad()\n",
    "#                     score.backward(retain_graph=True)\n",
    "#\n",
    "#                     # Compute gradient of output w.r.t. input PSD\n",
    "#                     input_grad = torch_x.grad.detach().cpu().numpy().squeeze()\n",
    "#                     input_grad_abs = np.abs(input_grad)\n",
    "#                     input_grad_norm = input_grad_abs / (np.max(input_grad_abs) + 1e-12)\n",
    "#\n",
    "#\n",
    "#                     fig, axes = plt.subplots(2, 2, figsize=(12, 6), sharey=False)\n",
    "#                     for ind_x in range(cur_x.squeeze(0).shape[0]):\n",
    "#                         axes[0, 0].plot(cur_x.squeeze(0)[ind_x], linewidth=1.2, alpha=0.9)\n",
    "#                     axes[0, 0].plot(binary_cur_truth, linewidth=1.1, label=\"True\", color=\"orange\", alpha=0.7)\n",
    "#                     axes[0, 0].plot(cur_fund_prediction_norm2, '--', linewidth=0.7, color=\"green\", label=\"ppsp_1up\", alpha=0.8)\n",
    "#                     axes[0, 0].plot(all_harmonic_pred * 0.8, '--', linewidth=0.7, color=\"red\", label=\"non normalized_harmonics\", alpha=0.9)\n",
    "#                     axes[0, 0].set_title(\"ppsp_1up\")\n",
    "#                     axes[0, 0].legend(loc=\"lower right\")\n",
    "#\n",
    "#\n",
    "#                     for ind_x in range(cur_x.squeeze(0).shape[0]):\n",
    "#                         axes[0, 1].plot(cur_x.squeeze(0)[ind_x], linewidth=1.2, alpha=0.7)\n",
    "#                     axes[0, 1].plot(binary_cur_truth, linewidth=1, label=\"True\", alpha=0.8)\n",
    "#                     axes[0, 1].plot(cur_fund_prediction_norm, '--', linewidth=0.8, color=\"green\", label=\"1up\", alpha=0.9)\n",
    "#                     axes[0, 1].set_title(\"1up(crepe)\")\n",
    "#                     axes[0, 1].legend(loc=\"lower right\")\n",
    "#\n",
    "#                     # axes[1,0].axis('off')\n",
    "#                     axes[1, 0].plot(cur_x.squeeze(), color=\"gray\",linewidth=1.8, alpha=0.8, label=\"PSD\")\n",
    "#                     axes[1, 0].plot(binary_cur_truth, linewidth=1, label=\"True\", alpha=0.8)\n",
    "#                     axes[1,0].plot(input_grad_norm1, '--', color=\"red\", linewidth=0.7, label=\"sailency\",alpha=0.9 )\n",
    "#                     axes[1, 0].set_title(f\"PPSP1up Input Saliency \")\n",
    "#                     axes[1, 0].legend(loc=\"lower right\",fontsize=8)\n",
    "#\n",
    "#\n",
    "#                     axes[1, 1].plot(cur_x.squeeze(), color=\"gray\",linewidth=1.8, alpha=0.8, label=\"PSD\")\n",
    "#                     axes[1, 1].plot(binary_cur_truth, linewidth=1, label=\"True\", alpha=0.8)\n",
    "#                     axes[1, 1].plot(cur_fund_prediction_norm, color=\"green\",linewidth=1, label=\"crepe\")\n",
    "#                     axes[1, 1].plot(input_grad_norm,'--', color=\"red\", linewidth=0.7, label=\"CAM\",alpha=0.9)\n",
    "#                     axes[1, 1].set_title(f\"Crepe CAM \")\n",
    "#                     axes[1, 1].legend(loc=\"lower right\")\n",
    "#\n",
    "#                     plt.suptitle(f\"{cur_fund_freq} Hz – {cur_fil_name}_{comb_lst}\",fontsize=8)\n",
    "#                     plt.tight_layout()\n",
    "#                     plt.savefig(os.path.join(dir_path, f\"{plt_fil_name}_compare.png\"), dpi=150)\n",
    "#                     plt.close()\n",
    "#                     # plt.show()\n",
    "#\n",
    "#                     # fig, axes = plt.subplots(2, 2, figsize=(10, 4), sharey=True)\n",
    "#                     #\n",
    "#                     # # --- Left: FPN_2 prediction + input channels ---\n",
    "#                     # for ind_x in range(cur_x.squeeze(0).shape[0]):\n",
    "#                     #     axes[0].plot(cur_x.squeeze(0)[ind_x], linewidth=1.2, alpha=0.9)\n",
    "#                     # axes[0].plot(binary_cur_truth, linewidth=1.1, label=\"True\",color=\"orange\", alpha=0.7)\n",
    "#                     # axes[0].plot(cur_fund_prediction_norm2,'--', linewidth=0.7, color=\"green\", label=\"ppsp_1up\", alpha=0.8)\n",
    "#                     # axes[0].plot(all_harmonic_pred*0.8,'--', linewidth=0.7, color=\"red\", label=\"non normalized_harmonics\", alpha=0.9)\n",
    "#                     # axes[0].set_title(\"ppsp_1up\")\n",
    "#                     # axes[0].legend(loc=\"lower right\")\n",
    "#                     #\n",
    "#                     # # --- Right: FPN_2_mtl prediction + same inputs for reference ---\n",
    "#                     # for ind_x in range(cur_x.squeeze(0).shape[0]):\n",
    "#                     #     axes[1].plot(cur_x.squeeze(0)[ind_x], linewidth=1.2, alpha=0.7)\n",
    "#                     # axes[1].plot(binary_cur_truth, linewidth=1, label=\"True\", alpha=0.8)\n",
    "#                     # axes[1].plot(cur_fund_prediction_norm,'--', linewidth=0.8, color=\"green\", label=\"1up\", alpha=0.9)\n",
    "#                     # axes[1].set_title(\"1up(crepe)\")\n",
    "#                     # axes[1].legend(loc=\"lower right\")\n",
    "#                     #\n",
    "#                     # plt.suptitle(f\"{cur_fund_freq} Hz – {cur_fil_name}_{comb_lst}\", fontsize=11)\n",
    "#                     # plt.tight_layout()\n",
    "#                     #\n",
    "#                     # # plt.savefig(os.path.join(dir_path, f\"{plt_fil_name}_compare.png\"), dpi=150)\n",
    "#                     # # plt.close()\n",
    "#                     # plt.show()\n",
    "#\n",
    "#\n",
    "#                     # cur_pred_accuracy = dice_coeff(binary_cur_prediction, binary_cur_truth)\n",
    "#                     cur_overlap_accuracy = overlap_dice(binary_cur_prediction, binary_cur_truth)\n",
    "#\n",
    "#                     ### fuzzy logic\n",
    "#                     # lr_strt, lr_end, cur_peak = fuzzy_funcs.lr_prediction(binary_cur_prediction,cur_x.squeeze(0).squeeze(0)[0],cur_fund_freq, distances[ind],plt_fil_name)\n",
    "#                     # print(f\"lrstart: {lr_strt},lrend: {lr_end}, lrpeak: {cur_peak}\")\n",
    "#\n",
    "#                     # freq_pred = fuzzy_funcs.predict_freq(orig_sig[ind], orig_sig[ind], lr_strt, lr_end,\n",
    "#                     #                                      cur_peak)\n",
    "#                     # print(f\"fundamental freq: {cur_fund_freq},freq_pred: {freq_pred}\")\n",
    "#\n",
    "#                     # fund_freq_lst.append(cur_fund_freq)\n",
    "#                     # freq_prediction_lst.append(freq_pred)\n",
    "#                     # criterion = torch.nn.BCELoss()\n",
    "#                     # loss = criterion(binary_cur_prediction, binary_cur_truth)\n",
    "#                     # cur_pred_accuracy2= torch.nn.BCELoss()(binary_cur_prediction, binary_cur_truth)\n",
    "#                     # cur_pred_accuracy = region_accuracy(binary_cur_truth, binary_cur_prediction, threshold=0.3)\n",
    "#\n",
    "#                     prediction_lst.append(cur_overlap_accuracy)\n",
    "#\n",
    "#                     # print(f\"freqpred: {freq_pred}\")\n",
    "#                     # prediction_lst.append(freq_pred)\n",
    "#\n",
    "#             accuracy = sum(prediction_lst) / len(prediction_lst)\n",
    "#             ## Convert to numpy arrays\n",
    "#             # cur_gtruth = np.array(fund_freq) * 60\n",
    "#             # cur_predict = np.array(prediction_lst) * 60\n",
    "#             #\n",
    "#             # #### filter out rows where cur_predict == 0\n",
    "#             # # filtered_data = [(gt, pred) for gt, pred in zip(cur_gtruth, cur_predict) if pred != 0]\n",
    "#             # #\n",
    "#             # # filtered_gtruth, filtered_predict = zip(*filtered_data)\n",
    "#             # # filtered_gtruth = np.array(filtered_gtruth)\n",
    "#             # # filtered_predict = np.array(filtered_predict)\n",
    "#             #\n",
    "#             # #### Calculate absolute error and mean percentage error\n",
    "#             # # abs_err = np.abs(filtered_gtruth - filtered_predict)\n",
    "#             # # mean_err = np.mean((abs_err / filtered_gtruth) * 100)\n",
    "#             # abs_err = np.abs(cur_gtruth - cur_predict)\n",
    "#             # mean_err = np.mean((abs_err/cur_gtruth)*100)\n",
    "#             #\n",
    "#             df = pd.DataFrame({\n",
    "#                 'fundamental_frequency': list(fund_freq),\n",
    "#                 'predictions_array': prediction_lst,\n",
    "#                 'distance': list(distances),\n",
    "#                 'file_name': file_names\n",
    "#                 # 'fund_freq': fund_freq_lst,\n",
    "#                 # 'predictions': freq_prediction_lst\n",
    "#             })\n",
    "#             # # df = df[df['predictions_array'] != 0]\n",
    "#             # df['abs_err'] = np.abs((df['fundamental_frequency'] * 60) - (df['predictions_array'] * 60))\n",
    "#             # #### Save to CSV\n",
    "#             df.to_csv(f\"{dir_path}/{key}_{accuracy}_conv1d_ppsp.csv\", index=False)\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### use the full train data for training and whole test dataset for validation.\n",
    "# ### once this is done, pickle dump it in the same format used for model training\n",
    "#\n",
    "# import numpy as np\n",
    "# import pickle\n",
    "# all_combs_lists = [[0],[3],[0, 1,2, 3]]\n",
    "# print(all_combs_lists)\n",
    "#\n",
    "# def process_dict_test(loaded_dict, row_indices=[0,4], col_size=512, output_format=\"channels_first\"):\n",
    "#\n",
    "#     processed_data = {}\n",
    "#\n",
    "#     for key, (test_x, test_y, fund_freq_lst, distances_lst, file_names_lst,orig_signal_lst) in loaded_dict.items():\n",
    "#         test_x = np.array(test_x)\n",
    "#         test_y = np.array(test_y)\n",
    "#         distances_lst = np.array(distances_lst)\n",
    "#         fund_freq_lst = np.array(fund_freq_lst)\n",
    "#         orig_signal_lst = np.array(orig_signal_lst)\n",
    "#\n",
    "#         # Select rows and columns size (preserve original order - no sorting)\n",
    "#         X = test_x[:, row_indices, :col_size]\n",
    "#         y = test_y\n",
    "#\n",
    "#         # Reshape based on desired output format\n",
    "#         if output_format == \"channels_first\":\n",
    "#             X = X[:, :, np.newaxis, :]  # [N, num_channels, 1, col_size]\n",
    "#         elif output_format == \"channels_last\":\n",
    "#\n",
    "#             X = X[:, np.newaxis, :, :]  # [N, 1, num_channels, col_size]\n",
    "#         else:\n",
    "#             raise ValueError(\"output_format must be 'channels_first' or 'channels_last'\")\n",
    "#\n",
    "#         # Return all data in original order (no train/val split)\n",
    "#         processed_data[key] = (X, y, distances_lst)\n",
    "#\n",
    "#     return processed_data\n",
    "#\n",
    "# def process_dict_train(loaded_dict, row_indices=[0,4], col_size=512, output_format=\"channels_first\"):\n",
    "#\n",
    "#     processed_data = {}\n",
    "#     for key, (train_x, train_y, distances, *_) in loaded_dict.items():\n",
    "#         train_x = np.array(train_x)\n",
    "#         train_y = np.array(train_y)\n",
    "#         distances = np.array(distances)\n",
    "#\n",
    "#         ### sort by distance\n",
    "#         sorted_indices = np.argsort(distances)\n",
    "#         train_x = train_x[sorted_indices]\n",
    "#         train_y = train_y[sorted_indices]\n",
    "#         distances = distances[sorted_indices]\n",
    "#\n",
    "#         ### select rows and columns size\n",
    "#         X = train_x[:, row_indices, :col_size]\n",
    "#         # train_y = train_y[:,:col_size]\n",
    "#\n",
    "#         ### reshape based on desired output format\n",
    "#         if output_format == \"channels_first\":\n",
    "#             # [N, num_channels, 1, col_size] - channels first\n",
    "#             X = X[:, :, np.newaxis, :]\n",
    "#         elif output_format == \"channels_last\":\n",
    "#             # [N, 1, num_channels, col_size] - channels last\n",
    "#             X = X[:, np.newaxis, :, :]\n",
    "#         else:\n",
    "#             raise ValueError(\"output_format must be 'channels_first' or 'channels_last'\")\n",
    "#\n",
    "#         ### split into train/val sets\n",
    "#         X_train, y_train = X, train_y\n",
    "#         # X_train, X_val, y_train, y_val, dist_train, dist_val = train_test_split(\n",
    "#         #     X, train_y, distances, test_size=val_ratio, random_state=random_state\n",
    "#         # )\n",
    "#\n",
    "#         processed_data[key] = (X_train, y_train, distances)\n",
    "#\n",
    "#     return processed_data\n",
    "#\n",
    "# mode = \"block\"\n",
    "# with open(f\"./conv2d_data/conv2d_psd_scaled_down_1up_{mode}.pkl\", \"rb\") as f:\n",
    "#     loaded_train_dict = pickle.load(f)\n",
    "#\n",
    "# with open(f\"./conv2d_data/conv2d_psd_scaled_down_1up_{mode}_test.pkl\", \"rb\") as f:\n",
    "#     loaded_test_dict = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregated_combs_data_lst=[]\n",
    "# for comb in all_combs_lists:\n",
    "#\n",
    "#     ### [N, 1, 4, 512] - channels last\n",
    "#     train_processed_channels_last = process_dict_train(\n",
    "#         loaded_train_dict,\n",
    "#         row_indices=comb,\n",
    "#         col_size=1024,\n",
    "#         output_format=\"channels_last\"\n",
    "#     )\n",
    "#     test_processed_channels_last = process_dict_test(\n",
    "#         loaded_test_dict,\n",
    "#         row_indices=comb,\n",
    "#         col_size=1024,\n",
    "#         output_format=\"channels_last\"\n",
    "#     )\n",
    "#\n",
    "#     all_X_train, all_X_val = [], []\n",
    "#     all_y_train, all_y_val = [], []\n",
    "#     all_dist_train, all_dist_val = [], []\n",
    "#\n",
    "#     for key, (X_train, y_train, dist_train) in train_processed_channels_last.items():\n",
    "#         all_X_train.append(X_train)\n",
    "#         all_y_train.append(y_train)\n",
    "#         all_dist_train.append(dist_train)\n",
    "#\n",
    "#     for key, (X_train, y_train, dist_train) in test_processed_channels_last.items():\n",
    "#         all_X_val.append(X_train)\n",
    "#         all_y_val.append(y_train)\n",
    "#         all_dist_val.append(dist_train)\n",
    "#\n",
    "#     X_train = np.concatenate(all_X_train, axis=0).squeeze(1)\n",
    "#     X_val   = np.concatenate(all_X_val, axis=0).squeeze(1)\n",
    "#     y_train = np.concatenate(all_y_train, axis=0)\n",
    "#     y_val   = np.concatenate(all_y_val, axis=0)\n",
    "#     dist_train = np.concatenate(all_dist_train, axis=0)\n",
    "#     dist_val   = np.concatenate(all_dist_val, axis=0)\n",
    "#\n",
    "#     aggregated_combs_data_lst.append((X_train, X_val, y_train, y_val, dist_train, dist_val))\n",
    "#\n",
    "# with open(f\"./conv2d_data/conv2d_psd_scaled_down_1up_{mode}_1.pkl\", \"wb\") as f:\n",
    "#         pickle.dump(aggregated_combs_data_lst, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode = \"gaussian\"\n",
    "# with open(f\"./conv2d_data/conv2d_psd_scaled_down_1up_{mode}_1.pkl\", \"rb\") as f:\n",
    "#     loaded_dict = pickle.load(f)\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# all_X_train, all_X_val = [], []\n",
    "# all_y_train, all_y_val = [], []\n",
    "# all_dist_train, all_dist_val = [], []\n",
    "#\n",
    "# for key, (X_train, X_val, y_train, y_val, dist_train, dist_val) in processed_channels_last.items():\n",
    "#     all_X_train.append(X_train)\n",
    "#     all_X_val.append(X_val)\n",
    "#     all_y_train.append(y_train)\n",
    "#     all_y_val.append(y_val)\n",
    "#     all_dist_train.append(dist_train)\n",
    "#     all_dist_val.append(dist_val)\n",
    "#\n",
    "# ### Concatenate along first axis\n",
    "# # X_train = np.concatenate(all_X_train, axis=0)\n",
    "# # X_val   = np.concatenate(all_X_val, axis=0)\n",
    "# # y_train = np.concatenate(all_y_train, axis=0)\n",
    "# # y_val   = np.concatenate(all_y_val, axis=0)\n",
    "# # dist_train = np.concatenate(all_dist_train, axis=0)\n",
    "# # dist_val   = np.concatenate(all_dist_val, axis=0)\n",
    "#\n",
    "# X_train = np.concatenate(all_X_train, axis=0).squeeze(1)\n",
    "# X_val   = np.concatenate(all_X_val, axis=0).squeeze(1)\n",
    "# y_train = np.concatenate(all_y_train, axis=0)\n",
    "# y_val   = np.concatenate(all_y_val, axis=0)\n",
    "# dist_train = np.concatenate(all_dist_train, axis=0)\n",
    "# dist_val   = np.concatenate(all_dist_val, axis=0)\n",
    "#\n",
    "# aggregated_combs_data_lst.append((X_train, X_val, y_train, y_val, dist_train, dist_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = FPN_2D(in_channels=1, base_channels=16)\n",
    "# model.load_state_dict(torch.load('best_fpn2d_model.pth', map_location=device))\n",
    "# model.eval()\n",
    "#\n",
    "# # X_train = np.concatenate(all_X_train, axis=0)\n",
    "# # X_val   = np.concatenate(all_X_val, axis=0)\n",
    "# # y_train = np.concatenate(all_y_train, axis=0)\n",
    "# # y_val   = np.concatenate(all_y_val, axis=0)\n",
    "# # dist_train = np.concatenate(all_dist_train, axis=0)\n",
    "# # dist_val   = np.concatenate(all_dist_val, axis=0)\n",
    "# for ind in list(np.where(dist_train>80)[0]):\n",
    "#     X_test = torch.FloatTensor(np.array([[X_train[ind]]]))  # [num_samples, 1, 2, 512]\n",
    "#     y_test = torch.FloatTensor(y_train[ind])\n",
    "#\n",
    "#     # test_x1= X_train[1605]\n",
    "#     # test_x1= X_train[1614]\n",
    "#     prediction=model(X_test)\n",
    "#\n",
    "#     plt.title(f'{dist_train[ind]}')\n",
    "#     plt.plot(X_train[ind].T)\n",
    "#     plt.plot(y_test, label='True Mask', linestyle='--',linewidth=2, color='green')\n",
    "#     plt.plot(prediction.detach().numpy()[0].T, label='Predicted Mask', linestyle='--', color='red')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "#\n",
    "# # print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # ===== Case 1: [N, 1, 4, 512] =====\n",
    "# model_case1 = FPN_2D(in_channels=1, base_channels=16)  # base_channels smaller for quick test\n",
    "# x1 = torch.randn(2, 1, 4, 1024)   # batch=2, 1 channel, height=4, width=512\n",
    "# y1 = model_case1(x1)\n",
    "# print(\"Case 1 input:\", x1.shape, \" -> output:\", y1.shape)\n",
    "#\n",
    "#\n",
    "# # ===== Case 2: [N, 4, 1, 512] =====\n",
    "# model_case2 = FPN_2D(in_channels=4, base_channels=16)\n",
    "# x2 = torch.randn(2, 4, 1, 1024)   # batch=2, 4 channels, height=1, width=512\n",
    "# y2 = model_case2(x2)\n",
    "# print(\"Case 2 input:\", x2.shape, \" -> output:\", y2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_folder_pth = f\"../data/\"\n",
    "# train_folders_lst = [(\"fan3_3spd_augment\",96.7),(\"fan5_3spd_augment\",41.97), (\"bldc_1_augment\",94.98),  (\"bldc_2_augment\",80.25)]\n",
    "#\n",
    "# psd_length = 1024\n",
    "# fs = 44100\n",
    "# ss_num_chunks, welch_num_chunks = 3, 2\n",
    "# psd_scale_down_factors = [1,2,3,4,'sum']\n",
    "# plot_fig, save_fig = False, False\n",
    "# ### calculating resample factors\n",
    "# strt_pnt = 0.3\n",
    "# resampl_factor_lst = generate_resample_factors(start=strt_pnt, end=3.1, step=0.1)\n",
    "#\n",
    "# for _,(train_folder,cur_fund_freq) in enumerate(train_folders_lst):\n",
    "#     print(train_folder, cur_fund_freq)\n",
    "#\n",
    "#     cur_folder_pth = os.path.join(root_folder_pth, train_folder)\n",
    "#     if not os.path.exists(cur_folder_pth):\n",
    "#         print(f\"{cur_folder_pth} does not exist\")\n",
    "#         continue\n",
    "#     else:\n",
    "#         data_folder_pth = os.path.join(cur_folder_pth, \"orig_files\")\n",
    "#         files_lst = os.listdir(data_folder_pth)\n",
    "#\n",
    "#         for file in files_lst:\n",
    "#             print(file)\n",
    "#             if file not in [\".DS_Store\"]:\n",
    "#                 cur_file_pth = os.path.join(data_folder_pth, file)\n",
    "#                 cur_signal = np.sum(read_files(cur_file_pth), axis=0)\n",
    "#\n",
    "#                 # num_pnts = len(cur_signal) // welch_num_chunks\n",
    "#                 #\n",
    "#                 # ### original signal psd (1st scaled or no scaled version)\n",
    "#                 # orig_freq_ss, orig_Pxx_ss = signal.welch(cur_signal, fs, nperseg=num_pnts, nfft=fs)\n",
    "#                 # log_Pxx_ss = np.log(orig_Pxx_ss)\n",
    "#                 # log_Pxx_ss = min_max_norm(log_Pxx_ss)\n",
    "#                 # # orig_norm_Pxx = min_max_norm(log_Pxx_ss[:psd_length])\n",
    "#                 # orig_norm_Pxx = log_Pxx_ss[:psd_length]\n",
    "#                 #\n",
    "#                 # cur_psds = [orig_norm_Pxx]\n",
    "#                 # for scale_factor in psd_scale_down_factors:\n",
    "#                 #     if scale_factor not in [1 ,'sum']:\n",
    "#                 #         cur_scaled_psd = scale_psd(log_Pxx_ss, psd_length, scale_factor, method=\"average\")\n",
    "#                 #         # cur_psds.append(cur_scaled_psd)\n",
    "#                 #         cur_psds.append(min_max_norm(cur_scaled_psd))\n",
    "#                 #\n",
    "#                 # # summed_psd = cur_psds[0].copy()\n",
    "#                 # # for p in cur_psds[1:]:\n",
    "#                 # #     summed_psd += p\n",
    "#                 # #\n",
    "#                 # # cur_psds.append(min_max_norm(summed_psd))\n",
    "#                 #\n",
    "#                 # stacked = np.stack(cur_psds, axis=0)\n",
    "#                 # max_psd = np.median(stacked, axis=0)\n",
    "#                 # cur_psds.append(min_max_norm(max_psd))\n",
    "#                 #\n",
    "#                 # peaks = compute_harmonic_peaks(fundamental_freq=cur_fund_freq)\n",
    "#\n",
    "#                 for resamp_ind, resamp_factor in enumerate(resampl_factor_lst):\n",
    "#                     if resamp_factor not in [0.0, 3.0]:\n",
    "#                         print(f\"Resample factor {resamp_factor}, cur signal id {file}\")\n",
    "#                         resample_sig = librosa.resample(cur_signal, orig_sr=fs, target_sr=int(fs * resamp_factor))\n",
    "#\n",
    "#                         resamp_num_pnts = len(resample_sig) // welch_num_chunks\n",
    "#\n",
    "#                         if resamp_factor >= 2.0:\n",
    "#                             resamp_freq_ss, resamp_Pxx_ss = signal.welch(resample_sig, fs, nperseg=resamp_num_pnts,\n",
    "#                                                                          nfft=int(fs * resamp_factor))\n",
    "#                         else:\n",
    "#                             resamp_freq_ss, resamp_Pxx_ss = signal.welch(resample_sig, fs, nperseg=resamp_num_pnts,\n",
    "#                                                                          nfft=fs)\n",
    "#\n",
    "#                         resamp_log_Pxx_ss = np.log(resamp_Pxx_ss)\n",
    "#                         #### perform spectrum downsampling\n",
    "#\n",
    "#                         resamp_norm_Pxx_ss = resamp_log_Pxx_ss[:psd_length]\n",
    "#                         resamp_norm_Pxx_ss[:5]=0\n",
    "#                         resamp_norm_Pxx_ss = min_max_norm(resamp_norm_Pxx_ss)\n",
    "#\n",
    "#                         cur_fund_freq = (cur_fund_freq / resamp_factor)[0]\n",
    "#\n",
    "#                         cur_fund_freq_lst = []\n",
    "#                         j = 0\n",
    "#                         for i in range(50):\n",
    "#                             if j + cur_fund_freq >= psd_length-2:\n",
    "#                                 break\n",
    "#                             j += cur_fund_freq\n",
    "#                             cur_fund_freq_lst.append(j)\n",
    "#\n",
    "#                         cur_fund_freq_lst = [int(np.round(i,0)) for i in cur_fund_freq_lst]\n",
    "#\n",
    "#                 if plot_fig:\n",
    "#                     fig, axes = plt.subplots(len(cur_psds), 1, figsize=(8, 1.5*len(cur_psds)), sharex=False)\n",
    "#                     fig.suptitle(f\"{file}\")\n",
    "#                     for idx, psd in enumerate(cur_psds):\n",
    "#                         axes[idx].plot(psd)\n",
    "#                         axes[idx].set_title(f\"PSD {idx+1} (factor {psd_scale_down_factors[idx]})\")\n",
    "#                         for h in peaks:\n",
    "#                             if h <= orig_freq_ss[psd_length-1]:  # only mark if inside plotted range\n",
    "#                                 cur_idx = np.argmin(np.abs(orig_freq_ss[:psd_length] - h))  # closest index\n",
    "#                                 axes[idx].plot(orig_freq_ss[cur_idx], psd[cur_idx], \"r*\", markersize=10)\n",
    "#\n",
    "#                     plt.tight_layout()\n",
    "#\n",
    "#                     if save_fig:\n",
    "#                         plt.savefig(os.path.join(\"./\", f\"{file}.png\"))\n",
    "#                     else:\n",
    "#                         plt.show()\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"./conv2d_data/conv2d_psd_scaled_down.pkl\", \"rb\") as f:\n",
    "#     loaded_dict = pickle.load(f)\n",
    "#\n",
    "# processed = process_loaded_dict(\n",
    "#     loaded_dict,\n",
    "#     row_indices=[0, 4],\n",
    "#     col_size=512,\n",
    "#     val_ratio=0.2\n",
    "# )\n",
    "#\n",
    "# all_X_train, all_X_val = [], []\n",
    "# all_y_train, all_y_val = [], []\n",
    "#\n",
    "# for key, (X_train, X_val, y_train, y_val, dist_train, dist_val) in processed.items():\n",
    "#     all_X_train.append(X_train)\n",
    "#     all_X_val.append(X_val)\n",
    "#     all_y_train.append(y_train)\n",
    "#     all_y_val.append(y_val)\n",
    "#\n",
    "# # Concatenate data\n",
    "# X_train = np.concatenate(all_X_train, axis=0)  # Shape: (num_samples, 2, 512)\n",
    "# X_val = np.concatenate(all_X_val, axis=0)      # Shape: (num_samples, 2, 512)\n",
    "# y_train = np.concatenate(all_y_train, axis=0)  # Shape: (num_samples, 1024)\n",
    "# y_val = np.concatenate(all_y_val, axis=0)      # Shape: (num_samples, 1024)\n",
    "#\n",
    "# # Since model output is 512 width, resize y to match\n",
    "# y_train = y_train[:, :512]  # Shape: (num_samples, 512)\n",
    "# y_val = y_val[:, :512]      # Shape: (num_samples, 512)\n",
    "#\n",
    "# print(\"Data shapes:\")\n",
    "# print(f\"X_train: {X_train.shape}\")  # (num_samples, 2, 512)\n",
    "# print(f\"y_train: {y_train.shape}\")  # (num_samples, 512)\n",
    "# print(f\"X_val: {X_val.shape}\")      # (num_samples, 2, 512)\n",
    "# print(f\"y_val: {y_val.shape}\")      # (num_samples, 512)\n",
    "\n",
    "\n",
    "# def plot_predictions(model, X_data, y_true, num_samples=5, device='mps'):\n",
    "#     \"\"\"\n",
    "#     Plot predictions vs true outputs along with input data\n",
    "#     \"\"\"\n",
    "#     model.eval()\n",
    "#\n",
    "#     # Select random samples\n",
    "#     indices = np.random.choice(len(X_data), num_samples, replace=False)\n",
    "#\n",
    "#     fig, axes = plt.subplots(num_samples, 3, figsize=(15, 3*num_samples))\n",
    "#\n",
    "#     if num_samples == 1:\n",
    "#         axes = axes.reshape(1, -1)\n",
    "#\n",
    "#     for i, idx in enumerate(indices):\n",
    "#         ### Prepare input - X_data shape: (num_samples, 2, 512)\n",
    "#         x_input = torch.FloatTensor(X_data[idx:idx+1, np.newaxis, :, :]).to(device)  # [1, 1, 2, 512]\n",
    "#\n",
    "#         ### Get prediction\n",
    "#         with torch.no_grad():\n",
    "#             y_pred = model(x_input).cpu().numpy()  # [1, 1, 1, 512]\n",
    "#             y_pred = y_pred.squeeze()  # [512] - remove batch, channel, and height dimensions\n",
    "#\n",
    "#         ### Get true output and input data\n",
    "#         y_true_sample = y_true[idx]  # [512]\n",
    "#         x_input_sample = X_data[idx]  # [2, 512] - two input channels\n",
    "#\n",
    "#         ### Plot input (both channels)\n",
    "#         axes[i, 0].plot(x_input_sample[0], label='Input Channel 1', alpha=0.7, color='blue')\n",
    "#         axes[i, 0].plot(x_input_sample[1], label='Input Channel 2', alpha=0.7, color='green')\n",
    "#         axes[i, 0].set_title(f'Sample {idx}: Input PSDs')\n",
    "#         axes[i, 0].legend()\n",
    "#         axes[i, 0].grid(True)\n",
    "#\n",
    "#         ### Plot true output\n",
    "#         axes[i, 1].plot(y_true_sample, label='True Mask', color='red', linewidth=2)\n",
    "#         axes[i, 1].set_title('True Harmonic Mask')\n",
    "#         axes[i, 1].set_ylim(0, 1)\n",
    "#         axes[i, 1].grid(True)\n",
    "#\n",
    "#         ### Plot prediction vs true\n",
    "#         axes[i, 2].plot(y_true_sample, label='True', color='red', alpha=0.7, linewidth=2)\n",
    "#         axes[i, 2].plot(y_pred, label='Predicted', color='blue', alpha=0.7)\n",
    "#         axes[i, 2].set_title('Prediction vs True')\n",
    "#         axes[i, 2].set_ylim(0, 1)\n",
    "#         axes[i, 2].legend()\n",
    "#         axes[i, 2].grid(True)\n",
    "#\n",
    "#     plt.tight_layout()\n",
    "#     # plt.savefig('predictions_comparison.png', dpi=300, bbox_inches='tight')\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# def make_true_mask(cur_fund_freq, psd_length=1024, sigma=4.0, n_harmonics=100):\n",
    "#\n",
    "#     cur_fund_freq_lst = []\n",
    "#     j = 0\n",
    "#     for i in range(n_harmonics):\n",
    "#         if j + cur_fund_freq >= psd_length - 2:\n",
    "#             break\n",
    "#         j += cur_fund_freq\n",
    "#         cur_fund_freq_lst.append(j)\n",
    "#\n",
    "#     cur_fund_freq_lst = np.array([int(np.round(i)) for i in cur_fund_freq_lst])\n",
    "#\n",
    "#     ### Build mask with Gaussian peaks\n",
    "#     true_mask = np.zeros(psd_length)\n",
    "#     x = np.arange(psd_length)\n",
    "#\n",
    "#     for f in cur_fund_freq_lst:\n",
    "#         gaussian = (1 / np.sqrt(2 * np.pi * sigma**2)) * np.exp(-0.5 * ((x - f)/sigma)**2)\n",
    "#         true_mask = np.maximum(true_mask, gaussian)  #### take max to keep strongest peak at each bin\n",
    "#\n",
    "#     #### Normalize so max = 1\n",
    "#     ### adding this to make sure the sum is always 1 but we don't have any overlaps\n",
    "#     true_mask /= np.max(true_mask)\n",
    "#\n",
    "#     return true_mask\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
